{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SEI Platform","text":"<p>Open Source Software Engineering Intelligence Platform</p>"},{"location":"#overview","title":"Overview","text":"<p>The SEI Platform is an enterprise-grade, open-source solution for building Software Engineering Intelligence capabilities. It provides data-driven insights into engineering operations, team performance, and development lifecycle optimization.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#core-analytics","title":"Core Analytics","text":"<ul> <li>DORA Metrics: Deployment frequency, lead time, change failure rate, recovery time</li> <li>Team Performance: Velocity tracking, bottleneck identification, collaboration metrics</li> <li>Code Quality: Technical debt analysis, security vulnerability tracking</li> <li>Predictive Analytics: Risk prediction, capacity planning, timeline forecasting</li> </ul>"},{"location":"#integrations","title":"Integrations","text":"<ul> <li>Version Control: GitHub, GitLab, Bitbucket, Azure DevOps</li> <li>Project Management: Jira, Azure Boards, Linear, Asana</li> <li>CI/CD: Jenkins, GitHub Actions, GitLab CI, CircleCI, Tekton</li> <li>Communication: Slack, Microsoft Teams, Discord</li> <li>Security: Snyk, SonarQube, Veracode, Checkmarx</li> </ul>"},{"location":"#dashboards","title":"Dashboards","text":"<ul> <li>Executive View: High-level KPIs, ROI metrics, strategic insights</li> <li>Engineering Manager: Team performance, resource allocation, delivery tracking</li> <li>Developer: Personal productivity, code quality, review metrics</li> <li>Product Manager: Feature delivery, user impact, technical health</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>The platform is built on a modern microservices architecture:</p> <ul> <li>Data Collection Layer: API collectors and webhook handlers</li> <li>Processing Layer: Event streaming with Apache Kafka</li> <li>Storage Layer: TimescaleDB for time-series, PostgreSQL for metadata</li> <li>Analytics Engine: DORA metrics, ML models, custom analytics</li> <li>API Gateway: REST and GraphQL interfaces</li> <li>Frontend: React, Vue.js, and Next.js applications</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"Layer Technology Purpose Orchestration Apache Airflow Workflow management &amp; ETL Database TimescaleDB Time-series data storage Analytics Metabase Business Intelligence Processing Apache Spark Big data processing API FastAPI + Hasura REST/GraphQL APIs Frontend React/Vue.js Web applications Container Docker + Kubernetes Orchestration"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Quick Start Guide</li> <li>Installation Instructions</li> <li>Architecture Overview</li> <li>API Reference</li> <li>Contributing Guidelines</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>Current Version: 0.1.0</p> <p>Implementation Progress: Phase 1, Sprint 1.1 Complete</p> <ul> <li>Development environment fully operational</li> <li>Core microservices architecture implemented</li> <li>API service with health checks and endpoints</li> <li>Infrastructure stack running (15+ services)</li> <li>Comprehensive documentation</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>Documentation: Browse this site for comprehensive guides</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to Open Source SEI Platform","text":"<p>We love your input! We want to make contributing to the Open Source SEI Platform as easy and transparent as possible, whether it's:</p> <ul> <li>Reporting a bug</li> <li>Discussing the current state of the code</li> <li>Submitting a fix</li> <li>Proposing new features</li> <li>Becoming a maintainer</li> </ul>"},{"location":"CONTRIBUTING/#development-process","title":"Development Process","text":"<p>We use GitHub to host code, to track issues and feature requests, as well as accept pull requests.</p>"},{"location":"CONTRIBUTING/#quick-start-for-contributors","title":"Quick Start for Contributors","text":"<pre><code># 1. Fork the repository\n# 2. Clone your fork\ngit clone https://github.com/YOUR_USERNAME/open-source-sei-platform.git\ncd open-source-sei-platform\n\n# 3. Set up development environment\nmake quickstart\n\n# 4. Create a feature branch\ngit checkout -b feature/amazing-feature\n\n# 5. Make your changes and test\nmake test\nmake lint\n\n# 6. Commit your changes\ngit commit -m 'Add some amazing feature'\n\n# 7. Push to your fork\ngit push origin feature/amazing-feature\n\n# 8. Open a Pull Request\n</code></pre>"},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation - Ensure any new features are documented</li> <li>Update tests - Add tests for new functionality</li> <li>Follow code style - Run <code>make format</code> and <code>make lint</code></li> <li>Update changelog - Add your changes to CHANGELOG.md</li> <li>Get reviews - Ensure your PR is reviewed by maintainers</li> </ol>"},{"location":"CONTRIBUTING/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"CONTRIBUTING/#python","title":"Python","text":"<ul> <li>Follow PEP 8</li> <li>Use Black for formatting: <code>make format</code></li> <li>Type hints are required for new code</li> <li>Docstrings required for public functions</li> </ul>"},{"location":"CONTRIBUTING/#typescriptjavascript","title":"TypeScript/JavaScript","text":"<ul> <li>Use Prettier for formatting</li> <li>Follow ESLint rules</li> <li>Prefer functional components in React</li> </ul>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<ul> <li>Use Markdown for documentation</li> <li>Include mermaid diagrams where helpful</li> <li>Keep examples up to date</li> </ul>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":""},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nmake test\n\n# Run specific test types\nmake test-unit\nmake test-integration\nmake test-e2e\n</code></pre>"},{"location":"CONTRIBUTING/#writing-tests","title":"Writing Tests","text":"<ul> <li>Unit tests for individual functions</li> <li>Integration tests for API endpoints</li> <li>E2E tests for user workflows</li> <li>Aim for &gt;80% code coverage</li> </ul>"},{"location":"CONTRIBUTING/#issue-reporting","title":"Issue Reporting","text":""},{"location":"CONTRIBUTING/#bug-reports","title":"Bug Reports","text":"<p>Use the bug report template and include:</p> <ul> <li>Steps to reproduce</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Environment details</li> <li>Screenshots (if applicable)</li> </ul>"},{"location":"CONTRIBUTING/#feature-requests","title":"Feature Requests","text":"<p>Use the feature request template and include:</p> <ul> <li>Problem description</li> <li>Proposed solution</li> <li>Alternatives considered</li> <li>Use case scenarios</li> </ul>"},{"location":"CONTRIBUTING/#architecture-guidelines","title":"Architecture Guidelines","text":""},{"location":"CONTRIBUTING/#microservices","title":"Microservices","text":"<ul> <li>Each service should have a single responsibility</li> <li>Use async communication where possible</li> <li>Implement proper error handling and retries</li> <li>Include health checks and metrics</li> </ul>"},{"location":"CONTRIBUTING/#database","title":"Database","text":"<ul> <li>Use migrations for schema changes</li> <li>Follow normalization principles</li> <li>Index frequently queried columns</li> <li>Document schema changes</li> </ul>"},{"location":"CONTRIBUTING/#api-design","title":"API Design","text":"<ul> <li>Follow RESTful principles</li> <li>Use consistent naming conventions</li> <li>Implement proper pagination</li> <li>Version your APIs</li> </ul>"},{"location":"CONTRIBUTING/#security","title":"Security","text":""},{"location":"CONTRIBUTING/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>DO NOT open public issues for security vulnerabilities.</p> <p>Instead, email security@sei-platform.org with:</p> <ul> <li>Description of the vulnerability</li> <li>Steps to reproduce</li> <li>Potential impact</li> <li>Suggested fix (if any)</li> </ul>"},{"location":"CONTRIBUTING/#security-guidelines","title":"Security Guidelines","text":"<ul> <li>Never commit secrets or API keys</li> <li>Use environment variables for configuration</li> <li>Implement proper authentication and authorization</li> <li>Validate all user inputs</li> <li>Use HTTPS for all communications</li> </ul>"},{"location":"CONTRIBUTING/#performance","title":"Performance","text":""},{"location":"CONTRIBUTING/#guidelines","title":"Guidelines","text":"<ul> <li>Profile before optimizing</li> <li>Cache frequently accessed data</li> <li>Use database indexes appropriately</li> <li>Implement proper pagination</li> <li>Monitor resource usage</li> </ul>"},{"location":"CONTRIBUTING/#benchmarks","title":"Benchmarks","text":"<ul> <li>API responses &lt; 200ms (95<sup>th</sup> percentile)</li> <li>Database queries &lt; 100ms</li> <li>Page load times &lt; 3 seconds</li> <li>System uptime &gt; 99.9%</li> </ul>"},{"location":"CONTRIBUTING/#documentation_1","title":"Documentation","text":""},{"location":"CONTRIBUTING/#types-of-documentation","title":"Types of Documentation","text":"<ul> <li>README.md - Project overview and quick start</li> <li>API docs - Generated from code comments</li> <li>Architecture docs - High-level system design</li> <li>User guides - How to use the platform</li> <li>Admin guides - Deployment and configuration</li> </ul>"},{"location":"CONTRIBUTING/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>Keep documentation close to code</li> <li>Update docs with code changes</li> <li>Use examples and diagrams</li> <li>Test documentation regularly</li> </ul>"},{"location":"CONTRIBUTING/#community-guidelines","title":"Community Guidelines","text":""},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inspiring community for all.</p>"},{"location":"CONTRIBUTING/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues - Bug reports and feature requests</li> <li>GitHub Discussions - General questions and ideas</li> <li>Discord - Real-time chat with the community</li> <li>Email - contact@sei-platform.org</li> </ul>"},{"location":"CONTRIBUTING/#release-process","title":"Release Process","text":""},{"location":"CONTRIBUTING/#versioning","title":"Versioning","text":"<p>We use Semantic Versioning:</p> <ul> <li>MAJOR - Breaking changes</li> <li>MINOR - New features (backward compatible)</li> <li>PATCH - Bug fixes (backward compatible)</li> </ul>"},{"location":"CONTRIBUTING/#release-timeline","title":"Release Timeline","text":"<ul> <li>Major releases - Every 6 months</li> <li>Minor releases - Monthly</li> <li>Patch releases - As needed</li> </ul>"},{"location":"CONTRIBUTING/#getting-help","title":"Getting Help","text":""},{"location":"CONTRIBUTING/#before-asking-for-help","title":"Before Asking for Help","text":"<ol> <li>Check existing documentation</li> <li>Search GitHub issues</li> <li>Check GitHub discussions</li> <li>Try the troubleshooting guide</li> </ol>"},{"location":"CONTRIBUTING/#how-to-ask-for-help","title":"How to Ask for Help","text":"<ol> <li>Provide context and background</li> <li>Include relevant code snippets</li> <li>Share error messages</li> <li>Describe what you've already tried</li> </ol>"},{"location":"CONTRIBUTING/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in:</p> <ul> <li>CONTRIBUTORS.md file</li> <li>Release notes</li> <li>Annual contributor spotlight</li> <li>Conference speaking opportunities</li> </ul>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p> <p>Thank you for contributing to the Open Source SEI Platform! \ud83c\udf89</p>"},{"location":"DEVELOPMENT_SETUP/","title":"Development Environment Setup","text":""},{"location":"DEVELOPMENT_SETUP/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Docker (20.10+) and Docker Compose (2.0+)</li> <li>Git (2.30+)</li> <li>Python (3.11+) - for local development</li> <li>Node.js (18+) and npm (9+) - for frontend development</li> <li>Make - for using Makefile commands</li> </ul>"},{"location":"DEVELOPMENT_SETUP/#quick-start","title":"Quick Start","text":""},{"location":"DEVELOPMENT_SETUP/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/rcdelacruz/open-source-sei-platform.git\ncd open-source-sei-platform\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#2-create-environment-file","title":"2. Create Environment File","text":"<pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> and configure your API tokens:</p> <ul> <li><code>GITHUB_TOKEN</code> - Your GitHub Personal Access Token</li> <li><code>GITLAB_TOKEN</code> - Your GitLab Access Token (if using GitLab)</li> <li><code>JIRA_API_TOKEN</code> - Your Jira API Token (if using Jira)</li> </ul>"},{"location":"DEVELOPMENT_SETUP/#3-start-the-development-environment","title":"3. Start the Development Environment","text":"<p>Using Make (recommended): <pre><code>make dev\n</code></pre></p> <p>Or using Docker Compose directly: <pre><code>docker-compose up -d\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#4-verify-services-are-running","title":"4. Verify Services are Running","text":"<p>Check service status: <pre><code>docker-compose ps\n</code></pre></p> <p>All services should show <code>Up</code> or <code>Up (healthy)</code> status.</p>"},{"location":"DEVELOPMENT_SETUP/#5-access-the-services","title":"5. Access the Services","text":"<p>Once all services are running, you can access:</p> Service URL Credentials API Documentation http://localhost:8080/docs N/A API Service http://localhost:8080 N/A Frontend (Dev) http://localhost:3002 N/A Metabase (BI) http://localhost:3000 Setup on first access Grafana http://localhost:3001 admin / admin123 Airflow http://localhost:8082 admin / admin123 Kafka UI http://localhost:8083 N/A PgAdmin http://localhost:8084 admin@sei.com / admin123"},{"location":"DEVELOPMENT_SETUP/#6-check-api-health","title":"6. Check API Health","text":"<p>Test that the API is responding:</p> <pre><code>curl http://localhost:8080/health\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"api-service\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-09-30T10:00:00.000000\"\n}\n</code></pre></p> <p>Check readiness (includes database connectivity): <pre><code>curl http://localhost:8080/ready\n</code></pre></p> <p>Expected response: <pre><code>{\n  \"ready\": true,\n  \"checks\": {\n    \"postgres\": \"healthy\",\n    \"timescaledb\": \"healthy\"\n  }\n}\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#service-architecture","title":"Service Architecture","text":"<p>The development environment includes the following services:</p>"},{"location":"DEVELOPMENT_SETUP/#core-services","title":"Core Services","text":"<ol> <li> <p>API Service (<code>api-service</code>)</p> <ul> <li>Main REST API built with FastAPI</li> <li>Port: 8080</li> <li>Provides CRUD operations for organizations, teams, repositories, developers</li> <li>Serves analytics endpoints for DORA metrics and team performance</li> </ul> </li> <li> <p>Git Collector (<code>git-collector</code>)</p> <ul> <li>Collects data from GitHub, GitLab, Bitbucket</li> <li>Port: 8000</li> <li>Polls repositories for commits, pull requests, and issues</li> </ul> </li> <li> <p>Jira Collector (<code>jira-collector</code>)</p> <ul> <li>Collects data from Jira and other project management tools</li> <li>Port: 8001</li> <li>Syncs issues, sprints, and project data</li> </ul> </li> <li> <p>Data Processor (<code>data-processor</code>)</p> <ul> <li>Processes raw events from Kafka</li> <li>Transforms and stores data in TimescaleDB</li> <li>Port: 8002</li> </ul> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#data-storage","title":"Data Storage","text":"<ol> <li> <p>TimescaleDB (<code>timescaledb</code>)</p> <ul> <li>Time-series database for metrics and events</li> <li>Port: 5432</li> <li>Database: <code>sei_platform</code></li> <li>User: <code>sei_user</code> / Password: <code>sei_password</code></li> </ul> </li> <li> <p>PostgreSQL (<code>postgresql</code>)</p> <ul> <li>Relational database for metadata</li> <li>Port: 5433 (mapped to avoid conflict)</li> <li>Database: <code>sei_metadata</code></li> <li>User: <code>sei_user</code> / Password: <code>sei_password</code></li> </ul> </li> <li> <p>Redis (<code>redis</code>)</p> <ul> <li>Cache and session storage</li> <li>Port: 6379</li> </ul> </li> <li> <p>Kafka + Zookeeper (<code>kafka</code>, <code>zookeeper</code>)</p> <ul> <li>Event streaming and message queue</li> <li>Kafka Port: 9092, 29092</li> <li>Zookeeper Port: 2181</li> </ul> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#analytics-monitoring","title":"Analytics &amp; Monitoring","text":"<ol> <li> <p>Metabase (<code>metabase</code>)</p> <ul> <li>Self-service BI tool</li> <li>Port: 3000</li> </ul> </li> <li> <p>Prometheus (<code>prometheus</code>)</p> <ul> <li>Metrics collection</li> <li>Port: 9090</li> </ul> </li> <li> <p>Grafana (<code>grafana</code>)</p> <ul> <li>Dashboards and visualization</li> <li>Port: 3001</li> </ul> </li> <li> <p>Apache Airflow (<code>airflow-webserver</code>, <code>airflow-scheduler</code>)</p> <ul> <li>Workflow orchestration</li> <li>Port: 8082</li> </ul> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#development-tools","title":"Development Tools","text":"<ol> <li> <p>Kafka UI (<code>kafka-ui</code>)</p> <ul> <li>Web interface for Kafka</li> <li>Port: 8083</li> </ul> </li> <li> <p>PgAdmin (<code>pgadmin</code>)</p> <ul> <li>PostgreSQL administration</li> <li>Port: 8084</li> </ul> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#development-workflow","title":"Development Workflow","text":""},{"location":"DEVELOPMENT_SETUP/#building-services","title":"Building Services","text":"<p>Build all services: <pre><code>make build\n# or\ndocker-compose build\n</code></pre></p> <p>Build a specific service: <pre><code>docker-compose build api-service\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#viewing-logs","title":"Viewing Logs","text":"<p>View logs from all services: <pre><code>make dev-logs\n# or\ndocker-compose logs -f\n</code></pre></p> <p>View logs from a specific service: <pre><code>docker-compose logs -f api-service\n</code></pre></p> <p>View logs from specific service groups: <pre><code>make logs-api          # API service logs\nmake logs-collectors   # Data collector logs\nmake logs-processors   # Data processor logs\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#stopping-services","title":"Stopping Services","text":"<p>Stop all services: <pre><code>make dev-stop\n# or\ndocker-compose down\n</code></pre></p> <p>Stop and remove volumes (WARNING: This deletes all data): <pre><code>docker-compose down -v\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#restarting-services","title":"Restarting Services","text":"<p>Restart all services: <pre><code>make dev-restart\n# or\ndocker-compose restart\n</code></pre></p> <p>Restart a specific service: <pre><code>docker-compose restart api-service\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#database-access","title":"Database Access","text":""},{"location":"DEVELOPMENT_SETUP/#postgresql-metadata","title":"PostgreSQL (Metadata)","text":"<p>Using psql: <pre><code>docker-compose exec postgresql psql -U sei_user -d sei_metadata\n</code></pre></p> <p>Using PgAdmin:</p> <ol> <li>Navigate to http://localhost:8084</li> <li>Login with <code>admin@sei.com</code> / <code>admin123</code></li> <li> <p>Add server:</p> <ul> <li>Host: <code>postgresql</code> (or <code>host.docker.internal</code> from host machine)</li> <li>Port: <code>5432</code></li> <li>Database: <code>sei_metadata</code></li> <li>User: <code>sei_user</code></li> <li>Password: <code>sei_password</code></li> </ul> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#timescaledb-time-series-data","title":"TimescaleDB (Time-series Data)","text":"<p>Using psql: <pre><code>docker-compose exec timescaledb psql -U sei_user -d sei_platform\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#redis","title":"Redis","text":"<p>Using redis-cli: <pre><code>docker-compose exec redis redis-cli\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#running-tests","title":"Running Tests","text":"<p>Run all tests: <pre><code>make test\n</code></pre></p> <p>Run specific test suites: <pre><code>make test-unit          # Unit tests only\nmake test-integration   # Integration tests only\nmake test-e2e          # End-to-end tests\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#code-quality","title":"Code Quality","text":"<p>Run linters: <pre><code>make lint\n</code></pre></p> <p>Format code: <pre><code>make format\n</code></pre></p> <p>Run security scans: <pre><code>make security\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DEVELOPMENT_SETUP/#services-wont-start","title":"Services won't start","text":"<ol> <li> <p>Check if ports are already in use:    <pre><code>lsof -i :8080  # Check API port\nlsof -i :5432  # Check TimescaleDB port\n</code></pre></p> </li> <li> <p>Check Docker resources (ensure you have enough memory):    <pre><code>docker system df\n</code></pre></p> </li> <li> <p>View service logs for errors:    <pre><code>docker-compose logs api-service\n</code></pre></p> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#database-connection-errors","title":"Database connection errors","text":"<ol> <li> <p>Ensure databases are running:    <pre><code>docker-compose ps postgresql timescaledb\n</code></pre></p> </li> <li> <p>Check database logs:    <pre><code>docker-compose logs postgresql\ndocker-compose logs timescaledb\n</code></pre></p> </li> <li> <p>Test database connectivity:    <pre><code>curl http://localhost:8080/ready\n</code></pre></p> </li> </ol>"},{"location":"DEVELOPMENT_SETUP/#port-conflicts","title":"Port conflicts","text":"<p>If you have port conflicts, you can modify the ports in <code>docker-compose.yml</code>. For example, to change the API port from 8080 to 8888:</p> <pre><code>api-service:\n  ports:\n    - \"8888:8080\"  # Change external port\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#clean-slate","title":"Clean slate","text":"<p>To completely reset the environment: <pre><code>make reset\n# or\nmake clean\nmake clean-builds\nmake install\nmake dev\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#next-steps","title":"Next Steps","text":"<p>After setting up the development environment:</p> <ol> <li>Review the API Documentation: http://localhost:8080/docs</li> <li>Set up integrations: Configure GitHub, GitLab, or Jira tokens in <code>.env</code></li> <li>Read the Architecture docs: <code>docs/architecture.md</code></li> <li>Check the Roadmap: <code>docs/ROADMAP.md</code></li> <li>Contributing: Read <code>docs/CONTRIBUTING.md</code></li> </ol>"},{"location":"DEVELOPMENT_SETUP/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcda Documentation: <code>docs/</code></li> <li>\ud83d\udc1b Issues: https://github.com/rcdelacruz/open-source-sei-platform/issues</li> <li>\ud83d\udcac Discussions: https://github.com/rcdelacruz/open-source-sei-platform/discussions</li> </ul> <p>Happy coding! \ud83d\ude80</p>"},{"location":"PROGRESS/","title":"Implementation Progress","text":""},{"location":"PROGRESS/#project-status-phase-1-sprint-11-complete","title":"Project Status: Phase 1, Sprint 1.1 COMPLETE \u2705","text":"<p>Last Updated: September 30, 2025 Current Version: 0.1.0 Implementation Phase: Foundation &amp; Core Infrastructure</p>"},{"location":"PROGRESS/#completed-sprint-11-development-environment-setup-week-1","title":"\u2705 Completed: Sprint 1.1 - Development Environment Setup (Week 1)","text":""},{"location":"PROGRESS/#what-we-built","title":"What We Built","text":""},{"location":"PROGRESS/#1-dockerized-microservices-architecture","title":"1. Dockerized Microservices Architecture","text":"<ul> <li>\u2705 Created 4 production-ready Dockerfiles with multi-stage builds</li> <li>\u2705 All services use non-root users for security</li> <li>\u2705 Implemented health checks for all services</li> <li>\u2705 Proper dependency management with requirements.txt</li> </ul> <p>Services Implemented: - <code>git-collector</code> - GitHub/GitLab data collection service (Port 8000) - <code>jira-collector</code> - Jira/project management integration (Port 8001) - <code>data-processor</code> - Event processing and transformation (Port 8002) - <code>api-service</code> - Main REST API gateway (Port 8080)</p>"},{"location":"PROGRESS/#2-api-service-fastapi-application","title":"2. API Service - FastAPI Application","text":"<p>Created a complete, production-ready API service with:</p> <p>Core Features: - \u2705 FastAPI application with async support - \u2705 Structured logging with structlog (JSON format) - \u2705 Configuration management with Pydantic Settings - \u2705 Database connection pooling (PostgreSQL + TimescaleDB) - \u2705 CORS middleware configured - \u2705 Health check endpoints (<code>/health</code>, <code>/ready</code>) - \u2705 OpenAPI documentation auto-generated (<code>/docs</code>)</p> <p>API Endpoints Implemented:</p> Endpoint Method Purpose Status <code>/</code> GET Root info endpoint \u2705 Working <code>/health</code> GET Service health check \u2705 Working <code>/ready</code> GET Readiness check (DB connectivity) \u2705 Working <code>/api/v1/organizations</code> GET, POST, PUT, DELETE Organization CRUD \u2705 Scaffold <code>/api/v1/teams</code> GET, POST, PUT, DELETE Team CRUD \u2705 Scaffold <code>/api/v1/repositories</code> GET, POST, PUT, DELETE Repository CRUD \u2705 Scaffold <code>/api/v1/developers</code> GET, POST, PUT, DELETE Developer CRUD \u2705 Scaffold <code>/api/v1/analytics/dora/{team_id}</code> GET DORA metrics \u2705 Scaffold <code>/api/v1/analytics/team/{team_id}</code> GET Team performance \u2705 Scaffold <p>Database Layer: - \u2705 SQLAlchemy ORM integration - \u2705 Connection pooling configured - \u2705 Dual database support (PostgreSQL + TimescaleDB) - \u2705 Dependency injection for database sessions</p>"},{"location":"PROGRESS/#3-collector-services","title":"3. Collector Services","text":"<p>Git Collector: - \u2705 FastAPI service structure - \u2705 GitHub/GitLab API client placeholders - \u2705 Manual collection trigger endpoint - \u2705 Collection status tracking endpoint - \u2705 Configuration for rate limiting</p> <p>Jira Collector: - \u2705 FastAPI service structure - \u2705 Jira API integration placeholders - \u2705 Project data collection endpoints - \u2705 Kafka producer integration ready</p>"},{"location":"PROGRESS/#4-data-processor-service","title":"4. Data Processor Service","text":"<ul> <li>\u2705 FastAPI service for monitoring</li> <li>\u2705 Kafka consumer integration (ready for implementation)</li> <li>\u2705 TimescaleDB connection for time-series data</li> <li>\u2705 Health check endpoints</li> </ul>"},{"location":"PROGRESS/#5-infrastructure-services-running","title":"5. Infrastructure Services Running","text":"<p>Successfully deployed complete stack:</p> <ul> <li>\u2705 TimescaleDB (Port 5432)</li> <li>\u2705 PostgreSQL (Port 5433)</li> <li>\u2705 Redis (Port 6379)</li> <li>\u2705 Apache Kafka (Ports 9092, 29092)</li> <li>\u2705 Zookeeper (Port 2181)</li> <li>\u2705 Metabase (Port 3000)</li> <li>\u2705 Grafana (Port 3001)</li> <li>\u2705 Prometheus (Port 9090)</li> <li>\u2705 Apache Airflow (Port 8082)</li> <li>\u2705 Kafka UI (Port 8083)</li> <li>\u2705 PgAdmin (Port 8084)</li> <li>\u2705 Kong API Gateway (Ports 8000, 8001)</li> </ul>"},{"location":"PROGRESS/#6-documentation","title":"6. Documentation","text":"<ul> <li>\u2705 Comprehensive development setup guide (<code>docs/DEVELOPMENT_SETUP.md</code>)</li> <li>\u2705 Service architecture documentation</li> <li>\u2705 API endpoint documentation (auto-generated)</li> <li>\u2705 Troubleshooting guide</li> </ul>"},{"location":"PROGRESS/#verification-results","title":"Verification Results","text":"<pre><code>\u2705 All Docker images build successfully\n\u2705 All services start without errors\n\u2705 API service responds to health checks\n\u2705 Database connections verified\n\u2705 OpenAPI documentation accessible at http://localhost:8080/docs\n</code></pre> <p>API Health Check: <pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"api-service\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-09-30T10:07:31.323514\"\n}\n</code></pre></p> <p>Readiness Check: <pre><code>{\n  \"ready\": true,\n  \"checks\": {\n    \"postgres\": \"healthy\",\n    \"timescaledb\": \"healthy\"\n  }\n}\n</code></pre></p>"},{"location":"PROGRESS/#files-created-total-40-files","title":"Files Created (Total: 40+ files)","text":"<p>Dockerfiles &amp; Configurations: - src/collectors/git/Dockerfile - src/collectors/jira/Dockerfile - src/processors/Dockerfile - src/apis/Dockerfile - .env (from .env.example)</p> <p>API Service (17 files): - src/apis/main.py - src/apis/config.py - src/apis/database.py - src/apis/requirements.txt - src/apis/routes/init.py - src/apis/routes/health.py - src/apis/routes/organizations.py - src/apis/routes/teams.py - src/apis/routes/repositories.py - src/apis/routes/developers.py - src/apis/routes/analytics.py</p> <p>Git Collector (7 files): - src/collectors/git/main.py - src/collectors/git/config.py - src/collectors/git/requirements.txt - src/collectors/git/routes/init.py - src/collectors/git/routes/health.py - src/collectors/git/routes/collector.py</p> <p>Jira Collector (7 files): - src/collectors/jira/main.py - src/collectors/jira/config.py - src/collectors/jira/requirements.txt - src/collectors/jira/routes/init.py - src/collectors/jira/routes/health.py - src/collectors/jira/routes/collector.py</p> <p>Data Processor (6 files): - src/processors/main.py - src/processors/config.py - src/processors/requirements.txt - src/processors/routes/init.py - src/processors/routes/health.py</p> <p>Documentation: - docs/DEVELOPMENT_SETUP.md - docs/PROGRESS.md (this file)</p>"},{"location":"PROGRESS/#next-sprint-12-data-models-database-layer-week-2","title":"\ud83d\udccb Next: Sprint 1.2 - Data Models &amp; Database Layer (Week 2)","text":""},{"location":"PROGRESS/#planned-tasks","title":"Planned Tasks","text":"<ol> <li> <p>SQLAlchemy ORM Models (5 days)</p> <ul> <li> Create Organization model</li> <li> Create Team model</li> <li> Create Developer model</li> <li> Create Repository model</li> <li> Create Commit model</li> <li> Create PullRequest model</li> <li> Create Issue model</li> <li> Create Review model</li> <li> Define relationships between models</li> </ul> </li> <li> <p>Database Migrations (2 days)</p> <ul> <li> Set up Alembic migration environment</li> <li> Create initial migration with all tables</li> <li> Create migration for indexes</li> <li> Create migration for TimescaleDB hypertables</li> </ul> </li> <li> <p>Repository Pattern (2 days)</p> <ul> <li> Create base repository class</li> <li> Implement OrganizationRepository</li> <li> Implement TeamRepository</li> <li> Implement DeveloperRepository</li> <li> Implement RepositoryRepository</li> </ul> </li> <li> <p>Database Seed Scripts (1 day)</p> <ul> <li> Create seed script for sample organizations</li> <li> Create seed script for sample teams</li> <li> Create seed script for sample developers</li> <li> Create seed script for sample repositories</li> </ul> </li> <li> <p>Testing (2 days)</p> <ul> <li> Write unit tests for models</li> <li> Write integration tests for repositories</li> <li> Set up pytest fixtures</li> <li> Achieve 80%+ test coverage</li> </ul> </li> </ol>"},{"location":"PROGRESS/#success-criteria-for-sprint-12","title":"Success Criteria for Sprint 1.2","text":"<ul> <li> All database models created and tested</li> <li> Alembic migrations working</li> <li> Can create, read, update, delete all entities via repository pattern</li> <li> Database properly seeded with test data</li> <li> 80%+ test coverage on data layer</li> </ul>"},{"location":"PROGRESS/#overall-progress","title":"\ud83d\udcca Overall Progress","text":""},{"location":"PROGRESS/#phase-1-foundation-core-infrastructure-months-1-3","title":"Phase 1: Foundation &amp; Core Infrastructure (Months 1-3)","text":"Sprint Status Progress Completion Date 1.1: Development Environment Setup \u2705 Complete 100% 2025-09-30 1.2: Data Models &amp; Database Layer \ud83d\udccb Planned 0% Target: 2025-10-07 1.3: Basic API Layer \ud83d\udccb Planned 0% Target: 2025-10-14 1.4: Git Data Collector - MVP \ud83d\udccb Planned 0% Target: 2025-10-21"},{"location":"PROGRESS/#key-metrics","title":"Key Metrics","text":"Metric Current Target (Phase 1) Services Implemented 4/4 core services 4/4 API Endpoints 12 (scaffolded) 20+ (functional) Test Coverage 0% 80%+ Documentation Pages 3 10+ Lines of Code ~2,500 ~10,000 Docker Images 4/4 building 4/4 tested"},{"location":"PROGRESS/#immediate-next-steps","title":"\ud83c\udfaf Immediate Next Steps","text":"<ol> <li>Start Sprint 1.2 - Begin implementing SQLAlchemy models</li> <li>Set up testing framework - Configure pytest with fixtures</li> <li>Implement Alembic - Database migration tooling</li> <li>Create first real endpoint - Make Organizations CRUD functional</li> <li>Write first integration test - Test full CRUD cycle</li> </ol>"},{"location":"PROGRESS/#how-to-continue-development","title":"\ud83d\ude80 How to Continue Development","text":""},{"location":"PROGRESS/#step-1-verify-current-setup","title":"Step 1: Verify Current Setup","text":"<pre><code># Check all services are running\ndocker-compose ps\n\n# Test API\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"PROGRESS/#step-2-create-your-first-model","title":"Step 2: Create Your First Model","text":"<pre><code># Navigate to the project\ncd src/apis\n\n# Create models directory\nmkdir models\n\n# Start implementing Organization model\n# See: docs/ROADMAP.md for Sprint 1.2 details\n</code></pre>"},{"location":"PROGRESS/#step-3-set-up-alembic","title":"Step 3: Set Up Alembic","text":"<pre><code># Initialize Alembic in api service\ncd src/apis\nalembic init alembic\n\n# Create first migration\nalembic revision --autogenerate -m \"Initial tables\"\n\n# Apply migration\nalembic upgrade head\n</code></pre>"},{"location":"PROGRESS/#notes-learnings","title":"\ud83d\udcdd Notes &amp; Learnings","text":""},{"location":"PROGRESS/#what-went-well","title":"What Went Well","text":"<ul> <li>\u2705 Clean separation of concerns with microservices</li> <li>\u2705 All services build and run successfully on first try</li> <li>\u2705 Health checks working across all services</li> <li>\u2705 Database connectivity verified</li> <li>\u2705 API documentation auto-generated and accessible</li> </ul>"},{"location":"PROGRESS/#challenges-overcome","title":"Challenges Overcome","text":"<ul> <li>\ud83d\udd27 TimescaleDB authentication initially had issues (resolved)</li> <li>\ud83d\udd27 Port conflicts required mapping PostgreSQL to 5433</li> <li>\ud83d\udd27 Docker Compose version warning (cosmetic only)</li> </ul>"},{"location":"PROGRESS/#technical-decisions","title":"Technical Decisions","text":"<ol> <li>Used Pydantic Settings instead of python-decouple for type-safe config</li> <li>Separated PostgreSQL and TimescaleDB for clear data separation</li> <li>Used structlog for JSON structured logging</li> <li>Implemented health checks at container level for better orchestration</li> </ol>"},{"location":"PROGRESS/#architecture-highlights","title":"Architecture Highlights","text":"<ul> <li>Microservices: Each collector is independent</li> <li>Event-driven: Kafka-based architecture for scalability</li> <li>Time-series optimized: TimescaleDB for metrics</li> <li>API-first: OpenAPI documentation built-in</li> </ul>"},{"location":"PROGRESS/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Ready to contribute? Here's how:</p> <ol> <li>Pick a task from Sprint 1.2 (see above)</li> <li>Create a feature branch: <code>git checkout -b feature/organization-model</code></li> <li>Implement the feature with tests</li> <li>Submit a pull request</li> </ol> <p>See <code>docs/CONTRIBUTING.md</code> for detailed guidelines.</p> <p>Project Progress: 8.33% (1/12 sprints complete) Next Milestone: Functional CRUD API by end of Week 3 Target: Working MVP with GitHub integration by Week 4</p> <p>Generated: September 30, 2025 Version: 0.1.0 Status: In Active Development \ud83d\ude80</p>"},{"location":"api/analytics/","title":"Analytics","text":""},{"location":"api/analytics/#overview","title":"Overview","text":"<p>The Analytics API provides access to software engineering metrics and insights in the SEI Platform. This includes DORA metrics, team performance indicators, repository statistics, and developer productivity data. Analytics data is calculated from historical events and aggregated in TimescaleDB for efficient time-series queries.</p>"},{"location":"api/analytics/#endpoints","title":"Endpoints","text":""},{"location":"api/analytics/#get-dora-metrics","title":"Get DORA Metrics","text":"<p>Retrieve DORA (DevOps Research and Assessment) metrics for a team or repository.</p> <pre><code>GET /api/v1/analytics/dora/{team_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for metrics calculation end_date string (ISO 8601) now End date for metrics calculation repository_id string (UUID) - Filter by specific repository <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/dora/770e8400-e29b-41d4-a716-446655440002?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"deployment_frequency\": {\n      \"value\": 2.5,\n      \"unit\": \"per_day\",\n      \"rating\": \"elite\",\n      \"trend\": \"increasing\"\n    },\n    \"lead_time_for_changes\": {\n      \"value\": 18.3,\n      \"unit\": \"hours\",\n      \"rating\": \"elite\",\n      \"trend\": \"decreasing\"\n    },\n    \"change_failure_rate\": {\n      \"value\": 0.12,\n      \"unit\": \"percentage\",\n      \"rating\": \"elite\",\n      \"trend\": \"stable\"\n    },\n    \"time_to_restore_service\": {\n      \"value\": 2.1,\n      \"unit\": \"hours\",\n      \"rating\": \"elite\",\n      \"trend\": \"decreasing\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#get-team-metrics","title":"Get Team Metrics","text":"<p>Get comprehensive performance metrics for a team.</p> <pre><code>GET /api/v1/analytics/team/{team_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for metrics end_date string (ISO 8601) now End date for metrics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/team/770e8400-e29b-41d4-a716-446655440002?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"velocity\": {\n      \"story_points_completed\": 145,\n      \"stories_completed\": 23,\n      \"avg_velocity_per_sprint\": 72.5\n    },\n    \"cycle_time\": {\n      \"avg_hours\": 42.3,\n      \"median_hours\": 38.5,\n      \"p95_hours\": 96.2\n    },\n    \"code_quality\": {\n      \"pr_review_coverage\": 0.98,\n      \"avg_review_comments\": 4.2,\n      \"code_churn_rate\": 0.15\n    },\n    \"activity\": {\n      \"commits\": 342,\n      \"pull_requests\": 67,\n      \"code_reviews\": 145,\n      \"deployments\": 78\n    },\n    \"team_health\": {\n      \"member_count\": 8,\n      \"active_members\": 8,\n      \"avg_utilization\": 0.82\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc124\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#get-repository-analytics","title":"Get Repository Analytics","text":"<p>Get analytics for a specific repository.</p> <pre><code>GET /api/v1/analytics/repository/{repository_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description repository_id string (UUID) Yes Repository identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for metrics end_date string (ISO 8601) now End date for metrics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/repository/bb0e8400-e29b-41d4-a716-446655440006?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"repository_id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"commits\": {\n      \"total\": 156,\n      \"avg_per_day\": 5.0,\n      \"lines_added\": 8432,\n      \"lines_removed\": 4231,\n      \"unique_authors\": 8\n    },\n    \"pull_requests\": {\n      \"opened\": 34,\n      \"merged\": 31,\n      \"closed_without_merge\": 2,\n      \"avg_time_to_merge_hours\": 16.8,\n      \"median_time_to_merge_hours\": 12.5\n    },\n    \"code_reviews\": {\n      \"total_reviews\": 87,\n      \"avg_reviews_per_pr\": 2.8,\n      \"avg_comments_per_pr\": 5.2,\n      \"avg_response_time_hours\": 4.1\n    },\n    \"deployments\": {\n      \"total\": 28,\n      \"successful\": 26,\n      \"failed\": 2,\n      \"avg_per_day\": 0.9\n    },\n    \"health\": {\n      \"test_coverage\": 0.78,\n      \"build_success_rate\": 0.93,\n      \"deployment_success_rate\": 0.93\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc125\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#get-developer-analytics","title":"Get Developer Analytics","text":"<p>Get performance metrics for a specific developer.</p> <pre><code>GET /api/v1/analytics/developer/{developer_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description developer_id string (UUID) Yes Developer identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for metrics end_date string (ISO 8601) now End date for metrics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/developer/990e8400-e29b-41d4-a716-446655440004?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"contributions\": {\n      \"commits\": 87,\n      \"pull_requests_opened\": 12,\n      \"pull_requests_merged\": 11,\n      \"code_reviews_given\": 24,\n      \"lines_added\": 3245,\n      \"lines_removed\": 1832\n    },\n    \"quality\": {\n      \"pr_acceptance_rate\": 0.92,\n      \"avg_pr_size_lines\": 245,\n      \"code_review_participation\": 0.85,\n      \"avg_comments_per_review\": 3.8\n    },\n    \"velocity\": {\n      \"avg_cycle_time_hours\": 38.2,\n      \"avg_commits_per_day\": 2.8,\n      \"active_days\": 18,\n      \"activity_rate\": 0.58\n    },\n    \"collaboration\": {\n      \"repositories_contributed\": 5,\n      \"teammates_collaborated\": 7,\n      \"avg_review_response_time_hours\": 4.2\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc126\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#get-deployment-metrics","title":"Get Deployment Metrics","text":"<p>Get deployment frequency and success metrics.</p> <pre><code>GET /api/v1/analytics/deployments\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description team_id string (UUID) - Filter by team repository_id string (UUID) - Filter by repository environment string - Filter by environment (production, staging, etc.) start_date string (ISO 8601) 30 days ago Start date for metrics end_date string (ISO 8601) now End date for metrics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/deployments?team_id=770e8400-e29b-41d4-a716-446655440002&amp;environment=production&amp;start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"filters\": {\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"environment\": \"production\"\n    },\n    \"summary\": {\n      \"total_deployments\": 78,\n      \"successful_deployments\": 74,\n      \"failed_deployments\": 4,\n      \"success_rate\": 0.95,\n      \"avg_per_day\": 2.5\n    },\n    \"frequency\": {\n      \"daily_avg\": 2.5,\n      \"weekly_avg\": 17.5,\n      \"rating\": \"elite\"\n    },\n    \"duration\": {\n      \"avg_minutes\": 8.3,\n      \"median_minutes\": 7.2,\n      \"p95_minutes\": 15.6\n    },\n    \"by_repository\": [\n      {\n        \"repository_id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n        \"repository_name\": \"api-service\",\n        \"deployments\": 45,\n        \"success_rate\": 0.96\n      },\n      {\n        \"repository_id\": \"cc0e8400-e29b-41d4-a716-446655440007\",\n        \"repository_name\": \"web-frontend\",\n        \"deployments\": 33,\n        \"success_rate\": 0.94\n      }\n    ]\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc127\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#get-trend-data","title":"Get Trend Data","text":"<p>Get time-series trend data for metrics over a period.</p> <pre><code>GET /api/v1/analytics/trends\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description metric string - Metric type (deployment_frequency, lead_time, cycle_time, etc.) team_id string (UUID) - Filter by team repository_id string (UUID) - Filter by repository granularity string daily Time granularity (hourly, daily, weekly, monthly) start_date string (ISO 8601) 30 days ago Start date end_date string (ISO 8601) now End date <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/analytics/trends?metric=deployment_frequency&amp;team_id=770e8400-e29b-41d4-a716-446655440002&amp;granularity=daily&amp;start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"metric\": \"deployment_frequency\",\n    \"granularity\": \"daily\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"data_points\": [\n      {\n        \"timestamp\": \"2024-01-01T00:00:00Z\",\n        \"value\": 2.0\n      },\n      {\n        \"timestamp\": \"2024-01-02T00:00:00Z\",\n        \"value\": 3.0\n      },\n      {\n        \"timestamp\": \"2024-01-03T00:00:00Z\",\n        \"value\": 2.0\n      }\n    ],\n    \"statistics\": {\n      \"min\": 0.0,\n      \"max\": 5.0,\n      \"avg\": 2.5,\n      \"median\": 2.0\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc128\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#error-responses","title":"Error Responses","text":""},{"location":"api/analytics/#400-bad-request","title":"400 Bad Request","text":"<p>Invalid Date Range:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid date range\",\n    \"details\": {\n      \"issue\": \"start_date must be before end_date\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc129\"\n  }\n}\n</code></pre> <p>Invalid Metric Type:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid metric type\",\n    \"details\": {\n      \"field\": \"metric\",\n      \"issue\": \"Must be one of: deployment_frequency, lead_time, cycle_time, change_failure_rate\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc130\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#404-not-found","title":"404 Not Found","text":"<p>Resource Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Team not found\",\n    \"details\": {\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc131\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#422-unprocessable-entity","title":"422 Unprocessable Entity","text":"<p>Insufficient Data:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"INSUFFICIENT_DATA\",\n    \"message\": \"Not enough data to calculate metrics\",\n    \"details\": {\n      \"reason\": \"No deployments found in specified period\",\n      \"minimum_required\": 3\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc132\"\n  }\n}\n</code></pre>"},{"location":"api/analytics/#data-model","title":"Data Model","text":""},{"location":"api/analytics/#dora-metrics-ratings","title":"DORA Metrics Ratings","text":"<p>DORA metrics are rated according to the DevOps Research and Assessment benchmarks:</p> Metric Elite High Medium Low Deployment Frequency Multiple per day Weekly to monthly Monthly to biannually Less than biannually Lead Time for Changes &lt; 1 hour 1 day to 1 week 1 week to 1 month &gt; 1 month Change Failure Rate &lt; 15% 16-30% 31-45% &gt; 45% Time to Restore Service &lt; 1 hour &lt; 1 day 1 day to 1 week &gt; 1 week"},{"location":"api/analytics/#metric-types","title":"Metric Types","text":"<p>Available metrics for trend analysis:</p> <ul> <li><code>deployment_frequency</code> - Number of deployments per time period</li> <li><code>lead_time</code> - Time from commit to production deployment</li> <li><code>cycle_time</code> - Time from start to completion of work items</li> <li><code>change_failure_rate</code> - Percentage of deployments causing failures</li> <li><code>mttr</code> - Mean time to restore service</li> <li><code>pr_merge_time</code> - Time to merge pull requests</li> <li><code>code_review_time</code> - Time to complete code reviews</li> </ul>"},{"location":"api/analytics/#granularity-options","title":"Granularity Options","text":"<p>Time granularity for trend data:</p> <ul> <li><code>hourly</code> - Data points every hour</li> <li><code>daily</code> - Data points every day</li> <li><code>weekly</code> - Data points every week</li> <li><code>monthly</code> - Data points every month</li> </ul>"},{"location":"api/analytics/#code-examples","title":"Code Examples","text":""},{"location":"api/analytics/#python","title":"Python","text":"<pre><code>import requests\nimport os\nfrom datetime import datetime, timedelta\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\n# Get DORA metrics\ndef get_dora_metrics(team_id, start_date=None, end_date=None, repository_id=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n    if repository_id:\n        params[\"repository_id\"] = repository_id\n\n    response = requests.get(\n        f\"{API_URL}/analytics/dora/{team_id}\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get team metrics\ndef get_team_metrics(team_id, start_date=None, end_date=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/analytics/team/{team_id}\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get repository analytics\ndef get_repository_analytics(repository_id, start_date=None, end_date=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/analytics/repository/{repository_id}\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get developer analytics\ndef get_developer_analytics(developer_id, start_date=None, end_date=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/analytics/developer/{developer_id}\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get deployment metrics\ndef get_deployment_metrics(\n    team_id=None,\n    repository_id=None,\n    environment=None,\n    start_date=None,\n    end_date=None\n):\n    params = {}\n    if team_id:\n        params[\"team_id\"] = team_id\n    if repository_id:\n        params[\"repository_id\"] = repository_id\n    if environment:\n        params[\"environment\"] = environment\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/analytics/deployments\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get trend data\ndef get_trend_data(\n    metric,\n    team_id=None,\n    repository_id=None,\n    granularity=\"daily\",\n    start_date=None,\n    end_date=None\n):\n    params = {\"metric\": metric, \"granularity\": granularity}\n    if team_id:\n        params[\"team_id\"] = team_id\n    if repository_id:\n        params[\"repository_id\"] = repository_id\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/analytics/trends\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Usage examples\nif __name__ == \"__main__\":\n    team_id = \"770e8400-e29b-41d4-a716-446655440002\"\n    end_date = datetime.utcnow()\n    start_date = end_date - timedelta(days=30)\n\n    # Get DORA metrics for team\n    dora = get_dora_metrics(team_id, start_date, end_date)\n    print(f\"Deployment Frequency: {dora['deployment_frequency']['value']} {dora['deployment_frequency']['unit']}\")\n    print(f\"Rating: {dora['deployment_frequency']['rating']}\")\n\n    # Get team metrics\n    team_metrics = get_team_metrics(team_id, start_date, end_date)\n    print(f\"Team Velocity: {team_metrics['velocity']['story_points_completed']} points\")\n\n    # Get deployment trends\n    trends = get_trend_data(\n        metric=\"deployment_frequency\",\n        team_id=team_id,\n        granularity=\"daily\",\n        start_date=start_date,\n        end_date=end_date\n    )\n    print(f\"Average deployment frequency: {trends['statistics']['avg']}\")\n</code></pre>"},{"location":"api/analytics/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>const API_URL = 'https://api.sei-platform.com/api/v1';\nconst API_KEY = process.env.SEI_API_KEY;\n\ninterface DORAMetrics {\n  team_id: string;\n  period: {\n    start: string;\n    end: string;\n  };\n  deployment_frequency: MetricValue;\n  lead_time_for_changes: MetricValue;\n  change_failure_rate: MetricValue;\n  time_to_restore_service: MetricValue;\n}\n\ninterface MetricValue {\n  value: number;\n  unit: string;\n  rating: 'elite' | 'high' | 'medium' | 'low';\n  trend: 'increasing' | 'decreasing' | 'stable';\n}\n\ninterface TrendData {\n  metric: string;\n  granularity: string;\n  period: {\n    start: string;\n    end: string;\n  };\n  data_points: Array&lt;{\n    timestamp: string;\n    value: number;\n  }&gt;;\n  statistics: {\n    min: number;\n    max: number;\n    avg: number;\n    median: number;\n  };\n}\n\nclass AnalyticsAPI {\n  private headers: HeadersInit;\n\n  constructor(apiKey: string) {\n    this.headers = {\n      'X-API-Key': apiKey,\n      'Content-Type': 'application/json'\n    };\n  }\n\n  async getDORAMetrics(\n    teamId: string,\n    startDate?: Date,\n    endDate?: Date,\n    repositoryId?: string\n  ): Promise&lt;DORAMetrics&gt; {\n    const url = new URL(`${API_URL}/analytics/dora/${teamId}`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n    if (repositoryId) url.searchParams.set('repository_id', repositoryId);\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getTeamMetrics(\n    teamId: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;any&gt; {\n    const url = new URL(`${API_URL}/analytics/team/${teamId}`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getRepositoryAnalytics(\n    repositoryId: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;any&gt; {\n    const url = new URL(`${API_URL}/analytics/repository/${repositoryId}`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getDeveloperAnalytics(\n    developerId: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;any&gt; {\n    const url = new URL(`${API_URL}/analytics/developer/${developerId}`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getDeploymentMetrics(\n    teamId?: string,\n    repositoryId?: string,\n    environment?: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;any&gt; {\n    const url = new URL(`${API_URL}/analytics/deployments`);\n    if (teamId) url.searchParams.set('team_id', teamId);\n    if (repositoryId) url.searchParams.set('repository_id', repositoryId);\n    if (environment) url.searchParams.set('environment', environment);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getTrendData(\n    metric: string,\n    teamId?: string,\n    repositoryId?: string,\n    granularity: string = 'daily',\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;TrendData&gt; {\n    const url = new URL(`${API_URL}/analytics/trends`);\n    url.searchParams.set('metric', metric);\n    url.searchParams.set('granularity', granularity);\n    if (teamId) url.searchParams.set('team_id', teamId);\n    if (repositoryId) url.searchParams.set('repository_id', repositoryId);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n}\n\n// Usage examples\nasync function main() {\n  const api = new AnalyticsAPI(API_KEY!);\n  const teamId = '770e8400-e29b-41d4-a716-446655440002';\n  const endDate = new Date();\n  const startDate = new Date(endDate.getTime() - 30 * 24 * 60 * 60 * 1000);\n\n  // Get DORA metrics\n  const dora = await api.getDORAMetrics(teamId, startDate, endDate);\n  console.log(`Deployment Frequency: ${dora.deployment_frequency.value} ${dora.deployment_frequency.unit}`);\n  console.log(`Rating: ${dora.deployment_frequency.rating}`);\n\n  // Get team metrics\n  const teamMetrics = await api.getTeamMetrics(teamId, startDate, endDate);\n  console.log(`Team Velocity: ${teamMetrics.velocity.story_points_completed} points`);\n\n  // Get deployment trends\n  const trends = await api.getTrendData(\n    'deployment_frequency',\n    teamId,\n    undefined,\n    'daily',\n    startDate,\n    endDate\n  );\n  console.log(`Average deployment frequency: ${trends.statistics.avg}`);\n}\n</code></pre>"},{"location":"api/analytics/#curl","title":"cURL","text":"<pre><code># Get DORA metrics\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/dora/770e8400-e29b-41d4-a716-446655440002?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get team metrics\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/team/770e8400-e29b-41d4-a716-446655440002?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get repository analytics\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/repository/bb0e8400-e29b-41d4-a716-446655440006?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get developer analytics\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/developer/990e8400-e29b-41d4-a716-446655440004?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get deployment metrics\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/deployments?team_id=770e8400-e29b-41d4-a716-446655440002&amp;environment=production&amp;start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get trend data\ncurl -X GET \"https://api.sei-platform.com/api/v1/analytics/trends?metric=deployment_frequency&amp;team_id=770e8400-e29b-41d4-a716-446655440002&amp;granularity=daily&amp;start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"api/analytics/#best-practices","title":"Best Practices","text":""},{"location":"api/analytics/#date-range-selection","title":"Date Range Selection","text":"<ol> <li>Use appropriate date ranges for metrics calculation</li> <li>Align date ranges with sprint cycles or reporting periods</li> <li>Consider data freshness and calculation costs for large ranges</li> <li>Use consistent time zones (UTC recommended) across all requests</li> </ol>"},{"location":"api/analytics/#metric-interpretation","title":"Metric Interpretation","text":"<ol> <li>Always consider rating context when interpreting metrics</li> <li>Focus on trends rather than absolute values</li> <li>Compare metrics against baselines and industry benchmarks</li> <li>Account for team size and project complexity</li> </ol>"},{"location":"api/analytics/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Cache analytics results for frequently accessed metrics</li> <li>Use appropriate granularity for trend data</li> <li>Filter by specific entities to reduce calculation time</li> <li>Schedule heavy analytics queries during off-peak hours</li> </ol>"},{"location":"api/analytics/#data-quality","title":"Data Quality","text":"<ol> <li>Ensure complete data collection from all platforms</li> <li>Validate identity mappings for accurate attribution</li> <li>Handle missing data gracefully in calculations</li> <li>Monitor data pipeline health and freshness</li> </ol>"},{"location":"api/analytics/#rate-limiting","title":"Rate Limiting","text":"<p>Analytics endpoints are subject to more restrictive rate limits due to computational costs:</p> <ul> <li>100 requests per hour per API key</li> <li>10 requests per minute (burst limit)</li> </ul> <p>See Authentication for details on rate limit headers and handling.</p>"},{"location":"api/analytics/#next-steps","title":"Next Steps","text":"<ul> <li>Teams API - Manage teams for metrics calculation</li> <li>Repositories API - Configure repositories for tracking</li> <li>Developers API - Manage developer identity mappings</li> <li>Organizations API - View organization-level metrics</li> </ul>"},{"location":"api/authentication/","title":"Authentication","text":""},{"location":"api/authentication/#overview","title":"Overview","text":"<p>The SEI Platform API uses JWT (JSON Web Token) authentication and API keys to authenticate requests. All API requests must include authentication credentials.</p>"},{"location":"api/authentication/#authentication-methods","title":"Authentication Methods","text":""},{"location":"api/authentication/#jwt-token-authentication","title":"JWT Token Authentication","text":"<p>JWT tokens are used for user-based authentication and provide short-lived access tokens.</p> <p>Request Header:</p> <pre><code>Authorization: Bearer &lt;jwt_token&gt;\n</code></pre> <p>Token Structure:</p> <pre><code>{\n  \"sub\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"email\": \"user@example.com\",\n  \"org_id\": \"660e8400-e29b-41d4-a716-446655440001\",\n  \"role\": \"admin\",\n  \"exp\": 1705392000,\n  \"iat\": 1705305600\n}\n</code></pre>"},{"location":"api/authentication/#api-key-authentication","title":"API Key Authentication","text":"<p>API keys are used for service-to-service authentication and long-lived integrations.</p> <p>Request Header:</p> <pre><code>X-API-Key: sei_live_&lt;your_api_key&gt;\n</code></pre> <p>API Key Format: <code>sei_live_</code> prefix followed by 32 random characters</p>"},{"location":"api/authentication/#obtaining-authentication-credentials","title":"Obtaining Authentication Credentials","text":""},{"location":"api/authentication/#get-jwt-token","title":"Get JWT Token","text":"<pre><code>POST /api/v1/auth/login\nContent-Type: application/json\n\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"secure_password\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    \"token_type\": \"bearer\",\n    \"expires_in\": 86400\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/authentication/#refresh-jwt-token","title":"Refresh JWT Token","text":"<pre><code>POST /api/v1/auth/refresh\nAuthorization: Bearer &lt;expired_token&gt;\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    \"token_type\": \"bearer\",\n    \"expires_in\": 86400\n  }\n}\n</code></pre>"},{"location":"api/authentication/#create-api-key","title":"Create API Key","text":"<pre><code>POST /api/v1/api-keys\nAuthorization: Bearer &lt;jwt_token&gt;\nContent-Type: application/json\n\n{\n  \"name\": \"Production Integration\",\n  \"expires_at\": \"2025-12-31T23:59:59Z\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"key\": \"sei_live_abcdef1234567890abcdef1234567890\",\n    \"name\": \"Production Integration\",\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"expires_at\": \"2025-12-31T23:59:59Z\"\n  }\n}\n</code></pre> <p>IMPORTANT: The API key is only shown once. Store it securely.</p>"},{"location":"api/authentication/#list-api-keys","title":"List API Keys","text":"<pre><code>GET /api/v1/api-keys\nAuthorization: Bearer &lt;jwt_token&gt;\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"name\": \"Production Integration\",\n      \"last_used_at\": \"2024-01-15T09:45:00Z\",\n      \"created_at\": \"2024-01-15T10:30:00Z\",\n      \"expires_at\": \"2025-12-31T23:59:59Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 1\n  }\n}\n</code></pre>"},{"location":"api/authentication/#revoke-api-key","title":"Revoke API Key","text":"<pre><code>DELETE /api/v1/api-keys/{key_id}\nAuthorization: Bearer &lt;jwt_token&gt;\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/authentication/#authentication-errors","title":"Authentication Errors","text":""},{"location":"api/authentication/#401-unauthorized","title":"401 Unauthorized","text":"<p>Missing Token:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"UNAUTHORIZED\",\n    \"message\": \"No authentication credentials provided\"\n  }\n}\n</code></pre> <p>Invalid Token:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"INVALID_TOKEN\",\n    \"message\": \"Invalid or malformed authentication token\"\n  }\n}\n</code></pre> <p>Expired Token:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"TOKEN_EXPIRED\",\n    \"message\": \"Authentication token has expired\"\n  }\n}\n</code></pre>"},{"location":"api/authentication/#403-forbidden","title":"403 Forbidden","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"INSUFFICIENT_PERMISSIONS\",\n    \"message\": \"You do not have permission to access this resource\"\n  }\n}\n</code></pre>"},{"location":"api/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"api/authentication/#token-security","title":"Token Security","text":"<ol> <li>Never expose tokens in client-side code or logs</li> <li>Use HTTPS for all API requests</li> <li>Store tokens securely using secure storage mechanisms</li> <li>Rotate API keys regularly (every 90 days recommended)</li> <li>Use short-lived tokens and refresh them as needed</li> </ol>"},{"location":"api/authentication/#api-key-management","title":"API Key Management","text":"<ol> <li>Create separate API keys for each integration</li> <li>Use descriptive names to identify API key purpose</li> <li>Set expiration dates for API keys</li> <li>Monitor API key usage via last_used_at field</li> <li>Revoke unused keys immediately</li> </ol>"},{"location":"api/authentication/#request-security","title":"Request Security","text":"<p>Example: Secure API Request</p> <pre><code>import requests\nimport os\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")  # Never hardcode\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\nresponse = requests.get(f\"{API_URL}/organizations\", headers=headers)\nresponse.raise_for_status()\ndata = response.json()\n</code></pre>"},{"location":"api/authentication/#rate-limiting","title":"Rate Limiting","text":"<p>All authenticated endpoints are subject to rate limiting:</p> <ul> <li>1000 requests per hour per API key/token</li> <li>100 requests per minute (burst limit)</li> </ul> <p>Rate Limit Headers:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1705392000\n</code></pre> <p>Rate Limit Exceeded:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RATE_LIMIT_EXCEEDED\",\n    \"message\": \"API rate limit exceeded\",\n    \"details\": {\n      \"limit\": 1000,\n      \"reset_at\": \"2024-01-15T11:00:00Z\"\n    }\n  }\n}\n</code></pre>"},{"location":"api/authentication/#authentication-flow","title":"Authentication Flow","text":""},{"location":"api/authentication/#web-application-flow","title":"Web Application Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant WebApp\n    participant API\n\n    User-&gt;&gt;WebApp: Enter credentials\n    WebApp-&gt;&gt;API: POST /api/v1/auth/login\n    API--&gt;&gt;WebApp: JWT token\n    WebApp-&gt;&gt;WebApp: Store token\n    WebApp-&gt;&gt;API: API request with token\n    API--&gt;&gt;WebApp: Response\n    WebApp--&gt;&gt;User: Display data</code></pre>"},{"location":"api/authentication/#service-integration-flow","title":"Service Integration Flow","text":"<pre><code>sequenceDiagram\n    participant Admin\n    participant WebUI\n    participant API\n    participant Service\n\n    Admin-&gt;&gt;WebUI: Create API key\n    WebUI-&gt;&gt;API: POST /api/v1/api-keys\n    API--&gt;&gt;WebUI: API key\n    WebUI--&gt;&gt;Admin: Display key (once)\n    Admin-&gt;&gt;Service: Configure API key\n    Service-&gt;&gt;API: Request with API key\n    API--&gt;&gt;Service: Response</code></pre>"},{"location":"api/authentication/#code-examples","title":"Code Examples","text":""},{"location":"api/authentication/#python","title":"Python","text":"<pre><code>import requests\n\nclass SEIClient:\n    def __init__(self, api_key: str):\n        self.base_url = \"https://api.sei-platform.com/api/v1\"\n        self.headers = {\n            \"X-API-Key\": api_key,\n            \"Content-Type\": \"application/json\"\n        }\n\n    def get_organizations(self):\n        response = requests.get(\n            f\"{self.base_url}/organizations\",\n            headers=self.headers\n        )\n        response.raise_for_status()\n        return response.json()[\"data\"]\n\n# Usage\nclient = SEIClient(api_key=\"sei_live_...\")\norgs = client.get_organizations()\n</code></pre>"},{"location":"api/authentication/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>class SEIClient {\n    private baseUrl = 'https://api.sei-platform.com/api/v1';\n    private apiKey: string;\n\n    constructor(apiKey: string) {\n        this.apiKey = apiKey;\n    }\n\n    async getOrganizations() {\n        const response = await fetch(`${this.baseUrl}/organizations`, {\n            headers: {\n                'X-API-Key': this.apiKey,\n                'Content-Type': 'application/json'\n            }\n        });\n\n        if (!response.ok) {\n            throw new Error(`API error: ${response.statusText}`);\n        }\n\n        const data = await response.json();\n        return data.data;\n    }\n}\n\n// Usage\nconst client = new SEIClient('sei_live_...');\nconst orgs = await client.getOrganizations();\n</code></pre>"},{"location":"api/authentication/#curl","title":"cURL","text":"<pre><code># Using API Key\ncurl -X GET \"https://api.sei-platform.com/api/v1/organizations\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Using JWT Token\ncurl -X GET \"https://api.sei-platform.com/api/v1/organizations\" \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\" \\\n  -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"api/authentication/#testing-authentication","title":"Testing Authentication","text":""},{"location":"api/authentication/#test-api-key","title":"Test API Key","text":"<pre><code>GET /api/v1/auth/verify\nX-API-Key: &lt;your_api_key&gt;\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"authenticated\": true,\n    \"auth_type\": \"api_key\",\n    \"organization_id\": \"660e8400-e29b-41d4-a716-446655440001\",\n    \"permissions\": [\"read\", \"write\"]\n  }\n}\n</code></pre>"},{"location":"api/authentication/#test-jwt-token","title":"Test JWT Token","text":"<pre><code>GET /api/v1/auth/verify\nAuthorization: Bearer &lt;jwt_token&gt;\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"authenticated\": true,\n    \"auth_type\": \"jwt\",\n    \"user_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"organization_id\": \"660e8400-e29b-41d4-a716-446655440001\",\n    \"role\": \"admin\",\n    \"expires_at\": \"2024-01-16T10:30:00Z\"\n  }\n}\n</code></pre>"},{"location":"api/authentication/#next-steps","title":"Next Steps","text":"<ul> <li>Organizations API - Manage organizations</li> <li>Teams API - Manage teams</li> <li>API Introduction - API overview and getting started</li> </ul>"},{"location":"api/developers/","title":"Developers","text":""},{"location":"api/developers/#overview","title":"Overview","text":"<p>Developers represent individual engineers and contributors in the SEI Platform. Developer entities track personal metrics, code contributions, and team affiliations. Each developer can be associated with multiple teams and have identity mappings to various platforms (GitHub, GitLab, JIRA).</p>"},{"location":"api/developers/#endpoints","title":"Endpoints","text":""},{"location":"api/developers/#list-developers","title":"List Developers","text":"<p>Retrieve a paginated list of all developers, optionally filtered by team.</p> <pre><code>GET /api/v1/developers\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description team_id string (UUID) - Filter developers by team ID is_active boolean - Filter by active status skip integer 0 Number of records to skip for pagination limit integer 100 Maximum number of records to return (max: 1000) sort string created_at Field to sort by (name, email, created_at) order string desc Sort order (asc, desc) <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/developers?team_id=770e8400-e29b-41d4-a716-446655440002&amp;is_active=true&amp;skip=0&amp;limit=50\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"990e8400-e29b-41d4-a716-446655440004\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"email\": \"alice@acme.com\",\n      \"name\": \"Alice Johnson\",\n      \"github_username\": \"alicej\",\n      \"gitlab_username\": null,\n      \"jira_username\": \"alice.johnson\",\n      \"is_active\": true,\n      \"joined_at\": \"2024-01-05T10:00:00Z\",\n      \"created_at\": \"2024-01-05T10:00:00Z\"\n    },\n    {\n      \"id\": \"aa0e8400-e29b-41d4-a716-446655440005\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"email\": \"bob@acme.com\",\n      \"name\": \"Bob Smith\",\n      \"github_username\": \"bobsmith\",\n      \"gitlab_username\": \"bob.smith\",\n      \"jira_username\": \"bsmith\",\n      \"is_active\": true,\n      \"joined_at\": \"2024-01-08T14:30:00Z\",\n      \"created_at\": \"2024-01-08T14:30:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 2,\n    \"skip\": 0,\n    \"limit\": 50,\n    \"has_more\": false,\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#get-developer","title":"Get Developer","text":"<p>Retrieve a specific developer by ID.</p> <pre><code>GET /api/v1/developers/{developer_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description developer_id string (UUID) Yes Developer identifier <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"email\": \"alice@acme.com\",\n    \"name\": \"Alice Johnson\",\n    \"github_username\": \"alicej\",\n    \"gitlab_username\": null,\n    \"jira_username\": \"alice.johnson\",\n    \"is_active\": true,\n    \"joined_at\": \"2024-01-05T10:00:00Z\",\n    \"created_at\": \"2024-01-05T10:00:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc124\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#create-developer","title":"Create Developer","text":"<p>Add a new developer to the SEI Platform.</p> <pre><code>POST /api/v1/developers\n</code></pre> <p>Request Body:</p> Field Type Required Description email string Yes Developer email address (unique) name string No Full name of the developer team_id string (UUID) No Team ID to assign developer to github_username string No GitHub username for identity mapping gitlab_username string No GitLab username for identity mapping jira_username string No JIRA username for identity mapping <p>Request Example:</p> <pre><code>curl -X POST \"https://api.sei-platform.com/api/v1/developers\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"alice@acme.com\",\n    \"name\": \"Alice Johnson\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"github_username\": \"alicej\",\n    \"jira_username\": \"alice.johnson\"\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"email\": \"alice@acme.com\",\n  \"name\": \"Alice Johnson\",\n  \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"github_username\": \"alicej\",\n  \"jira_username\": \"alice.johnson\"\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"email\": \"alice@acme.com\",\n    \"name\": \"Alice Johnson\",\n    \"github_username\": \"alicej\",\n    \"gitlab_username\": null,\n    \"jira_username\": \"alice.johnson\",\n    \"is_active\": true,\n    \"joined_at\": \"2024-01-15T10:30:00Z\",\n    \"created_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc125\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#update-developer","title":"Update Developer","text":"<p>Update an existing developer's information.</p> <pre><code>PUT /api/v1/developers/{developer_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description developer_id string (UUID) Yes Developer identifier <p>Request Body (all fields optional):</p> Field Type Description email string Updated email address name string Updated full name team_id string (UUID) Transfer developer to different team github_username string Updated GitHub username gitlab_username string Updated GitLab username jira_username string Updated JIRA username is_active boolean Set developer active/inactive status <p>Request Example:</p> <pre><code>curl -X PUT \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Alice J. Johnson\",\n    \"gitlab_username\": \"alice.johnson\",\n    \"is_active\": true\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Alice J. Johnson\",\n  \"gitlab_username\": \"alice.johnson\",\n  \"is_active\": true\n}\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"email\": \"alice@acme.com\",\n    \"name\": \"Alice J. Johnson\",\n    \"github_username\": \"alicej\",\n    \"gitlab_username\": \"alice.johnson\",\n    \"jira_username\": \"alice.johnson\",\n    \"is_active\": true,\n    \"joined_at\": \"2024-01-05T10:00:00Z\",\n    \"created_at\": \"2024-01-05T10:00:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T11:45:00Z\",\n    \"request_id\": \"req_abc126\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#delete-developer","title":"Delete Developer","text":"<p>Remove a developer from the SEI Platform. This will not delete historical metrics data.</p> <pre><code>DELETE /api/v1/developers/{developer_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description developer_id string (UUID) Yes Developer identifier <p>Request Example:</p> <pre><code>curl -X DELETE \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\"\n</code></pre> <p>Response (204 No Content):</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/developers/#developer-metrics","title":"Developer Metrics","text":""},{"location":"api/developers/#get-developer-metrics","title":"Get Developer Metrics","text":"<p>Get performance metrics for a specific developer.</p> <pre><code>GET /api/v1/developers/{developer_id}/metrics\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description developer_id string (UUID) Yes Developer identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for metrics end_date string (ISO 8601) now End date for metrics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004/metrics?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"commits\": {\n      \"total\": 87,\n      \"lines_added\": 3245,\n      \"lines_removed\": 1832,\n      \"repositories\": 5\n    },\n    \"pull_requests\": {\n      \"opened\": 12,\n      \"merged\": 11,\n      \"reviewed\": 24,\n      \"avg_time_to_merge_hours\": 16.3\n    },\n    \"code_reviews\": {\n      \"comments_made\": 45,\n      \"avg_response_time_hours\": 4.2\n    },\n    \"activity\": {\n      \"active_days\": 18,\n      \"total_days\": 31,\n      \"activity_rate\": 0.58\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc127\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#error-responses","title":"Error Responses","text":""},{"location":"api/developers/#400-bad-request","title":"400 Bad Request","text":"<p>Validation Error:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request data\",\n    \"details\": {\n      \"field\": \"email\",\n      \"issue\": \"Email address is required\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc128\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#404-not-found","title":"404 Not Found","text":"<p>Developer Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Developer not found\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc129\"\n  }\n}\n</code></pre> <p>Team Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Team not found\",\n    \"details\": {\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc130\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#409-conflict","title":"409 Conflict","text":"<p>Duplicate Email:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"Developer with this email already exists\",\n    \"details\": {\n      \"field\": \"email\",\n      \"value\": \"alice@acme.com\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc131\"\n  }\n}\n</code></pre> <p>Duplicate Username:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"GitHub username already assigned to another developer\",\n    \"details\": {\n      \"field\": \"github_username\",\n      \"value\": \"alicej\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc132\"\n  }\n}\n</code></pre>"},{"location":"api/developers/#data-model","title":"Data Model","text":""},{"location":"api/developers/#developer-object","title":"Developer Object","text":"Field Type Description id string (UUID) Unique developer identifier team_id string (UUID) or null Team this developer belongs to email string Developer email address (unique) name string or null Full name of the developer github_username string or null GitHub username for identity mapping gitlab_username string or null GitLab username for identity mapping jira_username string or null JIRA username for identity mapping is_active boolean Whether developer is currently active joined_at string (ISO 8601) Date developer joined the team created_at string (ISO 8601) Record creation timestamp"},{"location":"api/developers/#code-examples","title":"Code Examples","text":""},{"location":"api/developers/#python","title":"Python","text":"<pre><code>import requests\nimport os\nfrom datetime import datetime, timedelta\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\n# List developers\ndef list_developers(team_id=None, is_active=None, skip=0, limit=100):\n    params = {\"skip\": skip, \"limit\": limit}\n    if team_id:\n        params[\"team_id\"] = team_id\n    if is_active is not None:\n        params[\"is_active\"] = is_active\n\n    response = requests.get(\n        f\"{API_URL}/developers\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get developer\ndef get_developer(developer_id):\n    response = requests.get(\n        f\"{API_URL}/developers/{developer_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Create developer\ndef create_developer(\n    email,\n    name=None,\n    team_id=None,\n    github_username=None,\n    gitlab_username=None,\n    jira_username=None\n):\n    data = {\n        \"email\": email,\n        \"name\": name,\n        \"team_id\": team_id,\n        \"github_username\": github_username,\n        \"gitlab_username\": gitlab_username,\n        \"jira_username\": jira_username\n    }\n    # Remove None values\n    data = {k: v for k, v in data.items() if v is not None}\n\n    response = requests.post(\n        f\"{API_URL}/developers\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Update developer\ndef update_developer(developer_id, **kwargs):\n    response = requests.put(\n        f\"{API_URL}/developers/{developer_id}\",\n        headers=headers,\n        json=kwargs\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Delete developer\ndef delete_developer(developer_id):\n    response = requests.delete(\n        f\"{API_URL}/developers/{developer_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return True\n\n# Get developer metrics\ndef get_developer_metrics(developer_id, start_date=None, end_date=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/developers/{developer_id}/metrics\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Usage examples\nif __name__ == \"__main__\":\n    team_id = \"770e8400-e29b-41d4-a716-446655440002\"\n\n    # Create a new developer\n    new_dev = create_developer(\n        email=\"alice@acme.com\",\n        name=\"Alice Johnson\",\n        team_id=team_id,\n        github_username=\"alicej\",\n        jira_username=\"alice.johnson\"\n    )\n    print(f\"Created developer: {new_dev['id']}\")\n\n    # List developers for team\n    developers = list_developers(team_id=team_id, is_active=True)\n    print(f\"Found {len(developers)} active developers\")\n\n    # Get developer metrics\n    end_date = datetime.utcnow()\n    start_date = end_date - timedelta(days=30)\n    metrics = get_developer_metrics(\n        new_dev[\"id\"],\n        start_date=start_date,\n        end_date=end_date\n    )\n    print(f\"Developer metrics: {metrics['commits']['total']} commits\")\n\n    # Update developer\n    updated_dev = update_developer(\n        new_dev[\"id\"],\n        name=\"Alice J. Johnson\",\n        gitlab_username=\"alice.johnson\"\n    )\n    print(f\"Updated developer: {updated_dev['name']}\")\n</code></pre>"},{"location":"api/developers/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>const API_URL = 'https://api.sei-platform.com/api/v1';\nconst API_KEY = process.env.SEI_API_KEY;\n\ninterface Developer {\n  id: string;\n  team_id?: string;\n  email: string;\n  name?: string;\n  github_username?: string;\n  gitlab_username?: string;\n  jira_username?: string;\n  is_active: boolean;\n  joined_at: string;\n  created_at: string;\n}\n\ninterface CreateDeveloperRequest {\n  email: string;\n  name?: string;\n  team_id?: string;\n  github_username?: string;\n  gitlab_username?: string;\n  jira_username?: string;\n}\n\ninterface UpdateDeveloperRequest {\n  email?: string;\n  name?: string;\n  team_id?: string;\n  github_username?: string;\n  gitlab_username?: string;\n  jira_username?: string;\n  is_active?: boolean;\n}\n\ninterface DeveloperMetrics {\n  developer_id: string;\n  period: {\n    start: string;\n    end: string;\n  };\n  commits: {\n    total: number;\n    lines_added: number;\n    lines_removed: number;\n    repositories: number;\n  };\n  pull_requests: {\n    opened: number;\n    merged: number;\n    reviewed: number;\n    avg_time_to_merge_hours: number;\n  };\n  code_reviews: {\n    comments_made: number;\n    avg_response_time_hours: number;\n  };\n  activity: {\n    active_days: number;\n    total_days: number;\n    activity_rate: number;\n  };\n}\n\nclass DevelopersAPI {\n  private headers: HeadersInit;\n\n  constructor(apiKey: string) {\n    this.headers = {\n      'X-API-Key': apiKey,\n      'Content-Type': 'application/json'\n    };\n  }\n\n  async listDevelopers(\n    teamId?: string,\n    isActive?: boolean,\n    skip = 0,\n    limit = 100\n  ): Promise&lt;Developer[]&gt; {\n    const url = new URL(`${API_URL}/developers`);\n    if (teamId) url.searchParams.set('team_id', teamId);\n    if (isActive !== undefined) url.searchParams.set('is_active', isActive.toString());\n    url.searchParams.set('skip', skip.toString());\n    url.searchParams.set('limit', limit.toString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getDeveloper(developerId: string): Promise&lt;Developer&gt; {\n    const response = await fetch(`${API_URL}/developers/${developerId}`, {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async createDeveloper(request: CreateDeveloperRequest): Promise&lt;Developer&gt; {\n    const response = await fetch(`${API_URL}/developers`, {\n      method: 'POST',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async updateDeveloper(\n    developerId: string,\n    request: UpdateDeveloperRequest\n  ): Promise&lt;Developer&gt; {\n    const response = await fetch(`${API_URL}/developers/${developerId}`, {\n      method: 'PUT',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async deleteDeveloper(developerId: string): Promise&lt;void&gt; {\n    const response = await fetch(`${API_URL}/developers/${developerId}`, {\n      method: 'DELETE',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n  }\n\n  async getDeveloperMetrics(\n    developerId: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;DeveloperMetrics&gt; {\n    const url = new URL(`${API_URL}/developers/${developerId}/metrics`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n}\n\n// Usage examples\nasync function main() {\n  const api = new DevelopersAPI(API_KEY!);\n  const teamId = '770e8400-e29b-41d4-a716-446655440002';\n\n  // Create developer\n  const newDev = await api.createDeveloper({\n    email: 'alice@acme.com',\n    name: 'Alice Johnson',\n    team_id: teamId,\n    github_username: 'alicej',\n    jira_username: 'alice.johnson'\n  });\n  console.log(`Created developer: ${newDev.id}`);\n\n  // List developers\n  const developers = await api.listDevelopers(teamId, true);\n  console.log(`Found ${developers.length} active developers`);\n\n  // Get developer metrics\n  const endDate = new Date();\n  const startDate = new Date(endDate.getTime() - 30 * 24 * 60 * 60 * 1000);\n  const metrics = await api.getDeveloperMetrics(newDev.id, startDate, endDate);\n  console.log(`Developer has ${metrics.commits.total} commits`);\n\n  // Update developer\n  const updatedDev = await api.updateDeveloper(newDev.id, {\n    name: 'Alice J. Johnson',\n    gitlab_username: 'alice.johnson'\n  });\n  console.log(`Updated developer: ${updatedDev.name}`);\n}\n</code></pre>"},{"location":"api/developers/#curl","title":"cURL","text":"<pre><code># List developers\ncurl -X GET \"https://api.sei-platform.com/api/v1/developers?team_id=770e8400-e29b-41d4-a716-446655440002&amp;is_active=true\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get developer\ncurl -X GET \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Create developer\ncurl -X POST \"https://api.sei-platform.com/api/v1/developers\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"alice@acme.com\",\n    \"name\": \"Alice Johnson\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"github_username\": \"alicej\",\n    \"jira_username\": \"alice.johnson\"\n  }'\n\n# Update developer\ncurl -X PUT \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Alice J. Johnson\",\n    \"gitlab_username\": \"alice.johnson\",\n    \"is_active\": true\n  }'\n\n# Delete developer\ncurl -X DELETE \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"X-API-Key: sei_live_...\"\n\n# Get developer metrics\ncurl -X GET \"https://api.sei-platform.com/api/v1/developers/990e8400-e29b-41d4-a716-446655440004/metrics?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"api/developers/#best-practices","title":"Best Practices","text":""},{"location":"api/developers/#identity-mapping","title":"Identity Mapping","text":"<ol> <li>Link all relevant platform usernames (GitHub, GitLab, JIRA) to each developer</li> <li>Verify username mappings to ensure accurate attribution</li> <li>Update mappings promptly when developers change usernames</li> <li>Use consistent username formats across platforms</li> </ol>"},{"location":"api/developers/#email-management","title":"Email Management","text":"<ol> <li>Use corporate email addresses for accurate identity management</li> <li>Keep email addresses up to date when developers change</li> <li>Ensure email uniqueness across the platform</li> <li>Handle email changes carefully to maintain historical data</li> </ol>"},{"location":"api/developers/#team-assignment","title":"Team Assignment","text":"<ol> <li>Assign developers to their primary team</li> <li>Update team assignments when developers change roles</li> <li>Use is_active flag for developers who leave the organization</li> <li>Consider maintaining inactive developers for historical metrics</li> </ol>"},{"location":"api/developers/#privacy-considerations","title":"Privacy Considerations","text":"<ol> <li>Only collect necessary developer information</li> <li>Respect privacy settings for individual metrics</li> <li>Anonymize data when sharing aggregate metrics</li> <li>Follow GDPR and other privacy regulations</li> </ol>"},{"location":"api/developers/#rate-limiting","title":"Rate Limiting","text":"<p>Developer endpoints are subject to the standard rate limits:</p> <ul> <li>1000 requests per hour per API key</li> <li>100 requests per minute (burst limit)</li> </ul> <p>See Authentication for details on rate limit headers and handling.</p>"},{"location":"api/developers/#next-steps","title":"Next Steps","text":"<ul> <li>Teams API - Manage teams that developers belong to</li> <li>Repositories API - View repositories developers contribute to</li> <li>Analytics API - View detailed developer metrics</li> <li>Organizations API - Manage parent organizations</li> </ul>"},{"location":"api/introduction/","title":"API Introduction","text":"<p>The SEI Platform provides a comprehensive REST API for accessing all platform features programmatically.</p>"},{"location":"api/introduction/#api-overview","title":"API Overview","text":"<p>The API follows REST principles and returns JSON responses. All endpoints are versioned and documented with OpenAPI/Swagger.</p>"},{"location":"api/introduction/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8080/api/v1\n</code></pre> <p>Production: <pre><code>https://your-domain.com/api/v1\n</code></pre></p>"},{"location":"api/introduction/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication for development. In production, JWT-based authentication will be required.</p> <p>Future authentication header: <pre><code>Authorization: Bearer &lt;your_jwt_token&gt;\n</code></pre></p>"},{"location":"api/introduction/#response-format","title":"Response Format","text":"<p>All API responses follow a consistent structure:</p>"},{"location":"api/introduction/#success-response","title":"Success Response","text":"<pre><code>{\n  \"id\": \"uuid\",\n  \"name\": \"Example\",\n  \"created_at\": \"2025-09-30T10:00:00.000000\",\n  \"updated_at\": \"2025-09-30T10:00:00.000000\"\n}\n</code></pre>"},{"location":"api/introduction/#error-response","title":"Error Response","text":"<pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre>"},{"location":"api/introduction/#http-status-codes","title":"HTTP Status Codes","text":"Code Description 200 OK - Request successful 201 Created - Resource created successfully 204 No Content - Request successful, no content returned 400 Bad Request - Invalid request parameters 401 Unauthorized - Authentication required 403 Forbidden - Insufficient permissions 404 Not Found - Resource does not exist 422 Unprocessable Entity - Validation error 500 Internal Server Error - Server error"},{"location":"api/introduction/#rate-limiting","title":"Rate Limiting","text":"<p>Default rate limits:</p> <ul> <li>1000 requests per hour per IP address</li> <li>Burst limit: 100 requests per minute</li> </ul> <p>Rate limit headers: <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1696089600\n</code></pre></p>"},{"location":"api/introduction/#pagination","title":"Pagination","text":"<p>List endpoints support pagination:</p> <p>Query parameters:</p> <ul> <li><code>skip</code>: Number of records to skip (default: 0)</li> <li><code>limit</code>: Maximum number of records to return (default: 100, max: 1000)</li> </ul> <p>Example: <pre><code>GET /api/v1/organizations?skip=0&amp;limit=50\n</code></pre></p>"},{"location":"api/introduction/#filtering","title":"Filtering","text":"<p>Many endpoints support filtering through query parameters:</p> <pre><code>GET /api/v1/repositories?team_id=&lt;uuid&gt;&amp;platform=github\n</code></pre>"},{"location":"api/introduction/#interactive-documentation","title":"Interactive Documentation","text":"<p>Access the interactive API documentation:</p> <ul> <li>Swagger UI: http://localhost:8080/docs</li> <li>ReDoc: http://localhost:8080/redoc</li> </ul>"},{"location":"api/introduction/#api-endpoints","title":"API Endpoints","text":""},{"location":"api/introduction/#core-resources","title":"Core Resources","text":"<ul> <li>Organizations - Organization management</li> <li>Teams - Team management</li> <li>Repositories - Repository tracking</li> <li>Developers - Developer profiles</li> </ul>"},{"location":"api/introduction/#analytics","title":"Analytics","text":"<ul> <li>Analytics - DORA metrics and team performance</li> </ul>"},{"location":"api/introduction/#example-request","title":"Example Request","text":"<pre><code>curl -X GET \"http://localhost:8080/api/v1/organizations\" \\\n  -H \"Accept: application/json\"\n</code></pre>"},{"location":"api/introduction/#client-libraries","title":"Client Libraries","text":""},{"location":"api/introduction/#python","title":"Python","text":"<pre><code>import httpx\n\nclient = httpx.Client(base_url=\"http://localhost:8080\")\nresponse = client.get(\"/api/v1/organizations\")\norganizations = response.json()\n</code></pre>"},{"location":"api/introduction/#javascript","title":"JavaScript","text":"<pre><code>fetch('http://localhost:8080/api/v1/organizations')\n  .then(response =&gt; response.json())\n  .then(data =&gt; console.log(data));\n</code></pre>"},{"location":"api/introduction/#curl","title":"cURL","text":"<pre><code>curl -X GET \"http://localhost:8080/api/v1/organizations\" \\\n  -H \"Accept: application/json\"\n</code></pre>"},{"location":"api/introduction/#versioning","title":"Versioning","text":"<p>The API is versioned through the URL path:</p> <ul> <li>Current version: <code>v1</code></li> <li>Base path: <code>/api/v1</code></li> </ul> <p>Breaking changes will result in a new API version.</p>"},{"location":"api/introduction/#next-steps","title":"Next Steps","text":"<ul> <li>Explore Organizations API</li> <li>Learn about Teams API</li> <li>Check Analytics API</li> </ul>"},{"location":"api/organizations/","title":"Organizations","text":""},{"location":"api/organizations/#overview","title":"Overview","text":"<p>Organizations are the top-level entities in the SEI Platform that represent companies or business units. All teams, repositories, and developers are associated with an organization. Organizations provide isolation and access control for multi-tenant environments.</p>"},{"location":"api/organizations/#endpoints","title":"Endpoints","text":""},{"location":"api/organizations/#list-organizations","title":"List Organizations","text":"<p>Retrieve a paginated list of all organizations.</p> <pre><code>GET /api/v1/organizations\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description skip integer 0 Number of records to skip for pagination limit integer 100 Maximum number of records to return (max: 1000) sort string created_at Field to sort by (name, created_at, updated_at) order string desc Sort order (asc, desc) <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/organizations?skip=0&amp;limit=50\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"name\": \"Acme Corporation\",\n      \"domain\": \"acme.com\",\n      \"settings\": {\n        \"timezone\": \"America/New_York\",\n        \"default_branch\": \"main\"\n      },\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"updated_at\": \"2024-01-15T10:30:00Z\"\n    },\n    {\n      \"id\": \"660e8400-e29b-41d4-a716-446655440001\",\n      \"name\": \"Tech Innovations Inc\",\n      \"domain\": \"techinnovations.io\",\n      \"settings\": {\n        \"timezone\": \"UTC\",\n        \"default_branch\": \"main\"\n      },\n      \"created_at\": \"2024-01-05T14:20:00Z\",\n      \"updated_at\": \"2024-01-10T09:15:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 2,\n    \"skip\": 0,\n    \"limit\": 50,\n    \"has_more\": false,\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#get-organization","title":"Get Organization","text":"<p>Retrieve a specific organization by ID.</p> <pre><code>GET /api/v1/organizations/{organization_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description organization_id string (UUID) Yes Organization identifier <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Acme Corporation\",\n    \"domain\": \"acme.com\",\n    \"settings\": {\n      \"timezone\": \"America/New_York\",\n      \"default_branch\": \"main\",\n      \"notifications_enabled\": true\n    },\n    \"created_at\": \"2024-01-01T00:00:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc124\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#create-organization","title":"Create Organization","text":"<p>Create a new organization.</p> <pre><code>POST /api/v1/organizations\n</code></pre> <p>Request Body:</p> Field Type Required Description name string Yes Organization name (min: 3, max: 100 characters) domain string No Organization domain (e.g., company.com) settings object No Organization-specific settings (default: {}) <p>Request Example:</p> <pre><code>curl -X POST \"https://api.sei-platform.com/api/v1/organizations\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Acme Corporation\",\n    \"domain\": \"acme.com\",\n    \"settings\": {\n      \"timezone\": \"America/New_York\",\n      \"default_branch\": \"main\"\n    }\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Acme Corporation\",\n  \"domain\": \"acme.com\",\n  \"settings\": {\n    \"timezone\": \"America/New_York\",\n    \"default_branch\": \"main\"\n  }\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Acme Corporation\",\n    \"domain\": \"acme.com\",\n    \"settings\": {\n      \"timezone\": \"America/New_York\",\n      \"default_branch\": \"main\"\n    },\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc125\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#update-organization","title":"Update Organization","text":"<p>Update an existing organization.</p> <pre><code>PUT /api/v1/organizations/{organization_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description organization_id string (UUID) Yes Organization identifier <p>Request Body (all fields optional):</p> Field Type Description name string Updated organization name domain string Updated organization domain settings object Updated organization settings <p>Request Example:</p> <pre><code>curl -X PUT \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Acme Corporation Ltd\",\n    \"settings\": {\n      \"timezone\": \"America/Los_Angeles\",\n      \"default_branch\": \"main\",\n      \"notifications_enabled\": true\n    }\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Acme Corporation Ltd\",\n  \"settings\": {\n    \"timezone\": \"America/Los_Angeles\",\n    \"default_branch\": \"main\",\n    \"notifications_enabled\": true\n  }\n}\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Acme Corporation Ltd\",\n    \"domain\": \"acme.com\",\n    \"settings\": {\n      \"timezone\": \"America/Los_Angeles\",\n      \"default_branch\": \"main\",\n      \"notifications_enabled\": true\n    },\n    \"created_at\": \"2024-01-01T00:00:00Z\",\n    \"updated_at\": \"2024-01-15T11:45:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T11:45:00Z\",\n    \"request_id\": \"req_abc126\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#delete-organization","title":"Delete Organization","text":"<p>Delete an organization. This operation is irreversible and will cascade delete all associated teams, repositories, and data.</p> <pre><code>DELETE /api/v1/organizations/{organization_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description organization_id string (UUID) Yes Organization identifier <p>Request Example:</p> <pre><code>curl -X DELETE \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\"\n</code></pre> <p>Response (204 No Content):</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/organizations/#error-responses","title":"Error Responses","text":""},{"location":"api/organizations/#400-bad-request","title":"400 Bad Request","text":"<p>Validation Error:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request data\",\n    \"details\": {\n      \"field\": \"name\",\n      \"issue\": \"Organization name must be at least 3 characters\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc127\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#404-not-found","title":"404 Not Found","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Organization not found\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc128\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#409-conflict","title":"409 Conflict","text":"<p>Duplicate Organization:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"Organization with this domain already exists\",\n    \"details\": {\n      \"field\": \"domain\",\n      \"value\": \"acme.com\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc129\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#422-unprocessable-entity","title":"422 Unprocessable Entity","text":"<p>Invalid Data:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"INVALID_REQUEST\",\n    \"message\": \"Request body validation failed\",\n    \"details\": {\n      \"errors\": [\n        {\n          \"field\": \"settings.timezone\",\n          \"message\": \"Invalid timezone format\"\n        }\n      ]\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc130\"\n  }\n}\n</code></pre>"},{"location":"api/organizations/#data-model","title":"Data Model","text":""},{"location":"api/organizations/#organization-object","title":"Organization Object","text":"Field Type Description id string (UUID) Unique organization identifier name string Organization name domain string or null Organization domain settings object Organization-specific configuration created_at string (ISO 8601) Creation timestamp updated_at string (ISO 8601) Last update timestamp"},{"location":"api/organizations/#settings-object","title":"Settings Object","text":"<p>Common settings fields:</p> Field Type Description timezone string IANA timezone (e.g., \"America/New_York\") default_branch string Default git branch name (e.g., \"main\") notifications_enabled boolean Enable email notifications"},{"location":"api/organizations/#code-examples","title":"Code Examples","text":""},{"location":"api/organizations/#python","title":"Python","text":"<pre><code>import requests\nimport os\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\n# List organizations\ndef list_organizations(skip=0, limit=100):\n    response = requests.get(\n        f\"{API_URL}/organizations\",\n        headers=headers,\n        params={\"skip\": skip, \"limit\": limit}\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get organization\ndef get_organization(org_id):\n    response = requests.get(\n        f\"{API_URL}/organizations/{org_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Create organization\ndef create_organization(name, domain=None, settings=None):\n    data = {\n        \"name\": name,\n        \"domain\": domain,\n        \"settings\": settings or {}\n    }\n    response = requests.post(\n        f\"{API_URL}/organizations\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Update organization\ndef update_organization(org_id, name=None, domain=None, settings=None):\n    data = {}\n    if name:\n        data[\"name\"] = name\n    if domain:\n        data[\"domain\"] = domain\n    if settings:\n        data[\"settings\"] = settings\n\n    response = requests.put(\n        f\"{API_URL}/organizations/{org_id}\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Delete organization\ndef delete_organization(org_id):\n    response = requests.delete(\n        f\"{API_URL}/organizations/{org_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return True\n\n# Usage examples\nif __name__ == \"__main__\":\n    # List all organizations\n    orgs = list_organizations()\n    print(f\"Found {len(orgs)} organizations\")\n\n    # Create a new organization\n    new_org = create_organization(\n        name=\"Tech Innovations Inc\",\n        domain=\"techinnovations.io\",\n        settings={\n            \"timezone\": \"UTC\",\n            \"default_branch\": \"main\"\n        }\n    )\n    print(f\"Created organization: {new_org['id']}\")\n\n    # Get organization details\n    org = get_organization(new_org[\"id\"])\n    print(f\"Organization: {org['name']}\")\n\n    # Update organization\n    updated_org = update_organization(\n        org_id=new_org[\"id\"],\n        name=\"Tech Innovations Limited\",\n        settings={\n            \"timezone\": \"America/New_York\",\n            \"default_branch\": \"main\",\n            \"notifications_enabled\": True\n        }\n    )\n    print(f\"Updated organization: {updated_org['name']}\")\n</code></pre>"},{"location":"api/organizations/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>const API_URL = 'https://api.sei-platform.com/api/v1';\nconst API_KEY = process.env.SEI_API_KEY;\n\ninterface Organization {\n  id: string;\n  name: string;\n  domain?: string;\n  settings: Record&lt;string, any&gt;;\n  created_at: string;\n  updated_at: string;\n}\n\ninterface CreateOrganizationRequest {\n  name: string;\n  domain?: string;\n  settings?: Record&lt;string, any&gt;;\n}\n\ninterface UpdateOrganizationRequest {\n  name?: string;\n  domain?: string;\n  settings?: Record&lt;string, any&gt;;\n}\n\nclass OrganizationsAPI {\n  private headers: HeadersInit;\n\n  constructor(apiKey: string) {\n    this.headers = {\n      'X-API-Key': apiKey,\n      'Content-Type': 'application/json'\n    };\n  }\n\n  async listOrganizations(skip = 0, limit = 100): Promise&lt;Organization[]&gt; {\n    const url = new URL(`${API_URL}/organizations`);\n    url.searchParams.set('skip', skip.toString());\n    url.searchParams.set('limit', limit.toString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getOrganization(orgId: string): Promise&lt;Organization&gt; {\n    const response = await fetch(`${API_URL}/organizations/${orgId}`, {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async createOrganization(request: CreateOrganizationRequest): Promise&lt;Organization&gt; {\n    const response = await fetch(`${API_URL}/organizations`, {\n      method: 'POST',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async updateOrganization(\n    orgId: string,\n    request: UpdateOrganizationRequest\n  ): Promise&lt;Organization&gt; {\n    const response = await fetch(`${API_URL}/organizations/${orgId}`, {\n      method: 'PUT',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async deleteOrganization(orgId: string): Promise&lt;void&gt; {\n    const response = await fetch(`${API_URL}/organizations/${orgId}`, {\n      method: 'DELETE',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n  }\n}\n\n// Usage examples\nasync function main() {\n  const api = new OrganizationsAPI(API_KEY!);\n\n  // List organizations\n  const orgs = await api.listOrganizations();\n  console.log(`Found ${orgs.length} organizations`);\n\n  // Create organization\n  const newOrg = await api.createOrganization({\n    name: 'Tech Innovations Inc',\n    domain: 'techinnovations.io',\n    settings: {\n      timezone: 'UTC',\n      default_branch: 'main'\n    }\n  });\n  console.log(`Created organization: ${newOrg.id}`);\n\n  // Get organization\n  const org = await api.getOrganization(newOrg.id);\n  console.log(`Organization: ${org.name}`);\n\n  // Update organization\n  const updatedOrg = await api.updateOrganization(newOrg.id, {\n    name: 'Tech Innovations Limited',\n    settings: {\n      timezone: 'America/New_York',\n      default_branch: 'main',\n      notifications_enabled: true\n    }\n  });\n  console.log(`Updated organization: ${updatedOrg.name}`);\n\n  // Delete organization\n  await api.deleteOrganization(newOrg.id);\n  console.log('Organization deleted');\n}\n</code></pre>"},{"location":"api/organizations/#curl","title":"cURL","text":"<pre><code># List organizations\ncurl -X GET \"https://api.sei-platform.com/api/v1/organizations?skip=0&amp;limit=50\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get organization\ncurl -X GET \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Create organization\ncurl -X POST \"https://api.sei-platform.com/api/v1/organizations\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Acme Corporation\",\n    \"domain\": \"acme.com\",\n    \"settings\": {\n      \"timezone\": \"America/New_York\",\n      \"default_branch\": \"main\"\n    }\n  }'\n\n# Update organization\ncurl -X PUT \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Acme Corporation Ltd\",\n    \"settings\": {\n      \"timezone\": \"America/Los_Angeles\",\n      \"notifications_enabled\": true\n    }\n  }'\n\n# Delete organization\ncurl -X DELETE \"https://api.sei-platform.com/api/v1/organizations/550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"X-API-Key: sei_live_...\"\n</code></pre>"},{"location":"api/organizations/#best-practices","title":"Best Practices","text":""},{"location":"api/organizations/#organization-naming","title":"Organization Naming","text":"<ol> <li>Use descriptive names that clearly identify the business entity</li> <li>Avoid special characters in organization names</li> <li>Keep names between 3-100 characters</li> </ol>"},{"location":"api/organizations/#domain-configuration","title":"Domain Configuration","text":"<ol> <li>Use the primary company domain for the organization</li> <li>Ensure domain uniqueness across organizations</li> <li>Domain can be left null for internal or testing organizations</li> </ol>"},{"location":"api/organizations/#settings-management","title":"Settings Management","text":"<ol> <li>Store organization-specific configurations in the settings object</li> <li>Keep settings flat when possible for easier querying</li> <li>Document custom settings in your application</li> </ol>"},{"location":"api/organizations/#deletion-safety","title":"Deletion Safety","text":"<ol> <li>Always backup data before deleting an organization</li> <li>Implement soft deletes in production environments</li> <li>Notify all organization members before deletion</li> <li>Consider archiving instead of deletion for audit trails</li> </ol>"},{"location":"api/organizations/#rate-limiting","title":"Rate Limiting","text":"<p>Organization endpoints are subject to the standard rate limits:</p> <ul> <li>1000 requests per hour per API key</li> <li>100 requests per minute (burst limit)</li> </ul> <p>See Authentication for details on rate limit headers and handling.</p>"},{"location":"api/organizations/#next-steps","title":"Next Steps","text":"<ul> <li>Teams API - Manage teams within organizations</li> <li>Repositories API - Manage repositories</li> <li>Developers API - Manage developers</li> <li>Analytics API - View organization metrics</li> </ul>"},{"location":"api/repositories/","title":"Repositories","text":""},{"location":"api/repositories/#overview","title":"Overview","text":"<p>Repositories represent code repositories from various source control platforms (GitHub, GitLab, Bitbucket) in the SEI Platform. Repository entities track code commits, pull requests, deployments, and other software engineering metrics. Each repository belongs to a team and organization.</p>"},{"location":"api/repositories/#endpoints","title":"Endpoints","text":""},{"location":"api/repositories/#list-repositories","title":"List Repositories","text":"<p>Retrieve a paginated list of all repositories, optionally filtered by team or platform.</p> <pre><code>GET /api/v1/repositories\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description team_id string (UUID) - Filter repositories by team ID platform string - Filter by platform (github, gitlab, bitbucket) is_active boolean - Filter by active status skip integer 0 Number of records to skip for pagination limit integer 100 Maximum number of records to return (max: 1000) sort string created_at Field to sort by (name, created_at, updated_at) order string desc Sort order (asc, desc) <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/repositories?team_id=770e8400-e29b-41d4-a716-446655440002&amp;platform=github&amp;skip=0&amp;limit=50\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"name\": \"api-service\",\n      \"platform\": \"github\",\n      \"external_id\": \"12345678\",\n      \"url\": \"https://github.com/acme-corp/api-service\",\n      \"default_branch\": \"main\",\n      \"is_private\": true,\n      \"is_active\": true,\n      \"created_at\": \"2024-01-05T10:00:00Z\",\n      \"updated_at\": \"2024-01-15T10:30:00Z\"\n    },\n    {\n      \"id\": \"cc0e8400-e29b-41d4-a716-446655440007\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"name\": \"web-frontend\",\n      \"platform\": \"github\",\n      \"external_id\": \"23456789\",\n      \"url\": \"https://github.com/acme-corp/web-frontend\",\n      \"default_branch\": \"main\",\n      \"is_private\": false,\n      \"is_active\": true,\n      \"created_at\": \"2024-01-08T14:30:00Z\",\n      \"updated_at\": \"2024-01-12T09:15:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 2,\n    \"skip\": 0,\n    \"limit\": 50,\n    \"has_more\": false,\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#get-repository","title":"Get Repository","text":"<p>Retrieve a specific repository by ID.</p> <pre><code>GET /api/v1/repositories/{repository_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description repository_id string (UUID) Yes Repository identifier <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"name\": \"api-service\",\n    \"platform\": \"github\",\n    \"external_id\": \"12345678\",\n    \"url\": \"https://github.com/acme-corp/api-service\",\n    \"default_branch\": \"main\",\n    \"is_private\": true,\n    \"is_active\": true,\n    \"created_at\": \"2024-01-05T10:00:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc124\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#create-repository","title":"Create Repository","text":"<p>Add a new repository to track in the SEI Platform.</p> <pre><code>POST /api/v1/repositories\n</code></pre> <p>Request Body:</p> Field Type Required Description team_id string (UUID) Yes Team ID this repository belongs to name string Yes Repository name (e.g., \"api-service\") platform string Yes Source control platform (github, gitlab, bitbucket) external_id string Yes Platform-specific repository ID url string No Full URL to repository default_branch string No Default branch name (default: \"main\") is_private boolean No Whether repository is private (default: false) is_active boolean No Whether to actively track metrics (default: true) <p>Request Example:</p> <pre><code>curl -X POST \"https://api.sei-platform.com/api/v1/repositories\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"name\": \"api-service\",\n    \"platform\": \"github\",\n    \"external_id\": \"12345678\",\n    \"url\": \"https://github.com/acme-corp/api-service\",\n    \"default_branch\": \"main\",\n    \"is_private\": true,\n    \"is_active\": true\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"name\": \"api-service\",\n  \"platform\": \"github\",\n  \"external_id\": \"12345678\",\n  \"url\": \"https://github.com/acme-corp/api-service\",\n  \"default_branch\": \"main\",\n  \"is_private\": true,\n  \"is_active\": true\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"name\": \"api-service\",\n    \"platform\": \"github\",\n    \"external_id\": \"12345678\",\n    \"url\": \"https://github.com/acme-corp/api-service\",\n    \"default_branch\": \"main\",\n    \"is_private\": true,\n    \"is_active\": true,\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc125\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#update-repository","title":"Update Repository","text":"<p>Update an existing repository.</p> <pre><code>PUT /api/v1/repositories/{repository_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description repository_id string (UUID) Yes Repository identifier <p>Request Body (all fields optional):</p> Field Type Description team_id string (UUID) Transfer repository to different team name string Updated repository name default_branch string Updated default branch url string Updated repository URL is_private boolean Updated privacy status is_active boolean Enable or disable metric tracking <p>Request Example:</p> <pre><code>curl -X PUT \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"default_branch\": \"develop\",\n    \"is_active\": true\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"default_branch\": \"develop\",\n  \"is_active\": true\n}\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"name\": \"api-service\",\n    \"platform\": \"github\",\n    \"external_id\": \"12345678\",\n    \"url\": \"https://github.com/acme-corp/api-service\",\n    \"default_branch\": \"develop\",\n    \"is_private\": true,\n    \"is_active\": true,\n    \"created_at\": \"2024-01-05T10:00:00Z\",\n    \"updated_at\": \"2024-01-15T11:45:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T11:45:00Z\",\n    \"request_id\": \"req_abc126\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#delete-repository","title":"Delete Repository","text":"<p>Remove a repository from tracking. This will stop collecting metrics but will not delete historical data.</p> <pre><code>DELETE /api/v1/repositories/{repository_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description repository_id string (UUID) Yes Repository identifier <p>Request Example:</p> <pre><code>curl -X DELETE \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\"\n</code></pre> <p>Response (204 No Content):</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/repositories/#repository-statistics","title":"Repository Statistics","text":""},{"location":"api/repositories/#get-repository-stats","title":"Get Repository Stats","text":"<p>Get aggregated statistics for a repository.</p> <pre><code>GET /api/v1/repositories/{repository_id}/stats\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description repository_id string (UUID) Yes Repository identifier <p>Query Parameters:</p> Parameter Type Default Description start_date string (ISO 8601) 30 days ago Start date for statistics end_date string (ISO 8601) now End date for statistics <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006/stats?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"repository_id\": \"bb0e8400-e29b-41d4-a716-446655440006\",\n    \"period\": {\n      \"start\": \"2024-01-01T00:00:00Z\",\n      \"end\": \"2024-01-31T23:59:59Z\"\n    },\n    \"commits\": {\n      \"total\": 342,\n      \"by_author\": 12\n    },\n    \"pull_requests\": {\n      \"opened\": 45,\n      \"merged\": 40,\n      \"closed\": 3,\n      \"avg_time_to_merge_hours\": 18.5\n    },\n    \"deployments\": {\n      \"total\": 28,\n      \"successful\": 26,\n      \"failed\": 2\n    },\n    \"contributors\": {\n      \"active\": 8,\n      \"total\": 12\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc127\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#error-responses","title":"Error Responses","text":""},{"location":"api/repositories/#400-bad-request","title":"400 Bad Request","text":"<p>Validation Error:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request data\",\n    \"details\": {\n      \"field\": \"platform\",\n      \"issue\": \"Platform must be one of: github, gitlab, bitbucket\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc128\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#404-not-found","title":"404 Not Found","text":"<p>Repository Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Repository not found\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc129\"\n  }\n}\n</code></pre> <p>Team Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Team not found\",\n    \"details\": {\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc130\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#409-conflict","title":"409 Conflict","text":"<p>Duplicate Repository:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"Repository already exists\",\n    \"details\": {\n      \"field\": \"external_id\",\n      \"value\": \"12345678\",\n      \"platform\": \"github\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc131\"\n  }\n}\n</code></pre>"},{"location":"api/repositories/#data-model","title":"Data Model","text":""},{"location":"api/repositories/#repository-object","title":"Repository Object","text":"Field Type Description id string (UUID) Unique repository identifier team_id string (UUID) Team this repository belongs to name string Repository name platform string Source control platform (github, gitlab, bitbucket) external_id string Platform-specific repository ID url string or null Full URL to repository default_branch string Default branch name (e.g., \"main\", \"master\") is_private boolean Whether repository is private is_active boolean Whether metrics are actively tracked created_at string (ISO 8601) Creation timestamp updated_at string (ISO 8601) Last update timestamp"},{"location":"api/repositories/#platform-values","title":"Platform Values","text":"<p>Supported platform values:</p> <ul> <li><code>github</code> - GitHub repositories</li> <li><code>gitlab</code> - GitLab repositories</li> <li><code>bitbucket</code> - Bitbucket repositories</li> </ul>"},{"location":"api/repositories/#code-examples","title":"Code Examples","text":""},{"location":"api/repositories/#python","title":"Python","text":"<pre><code>import requests\nimport os\nfrom datetime import datetime, timedelta\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\n# List repositories\ndef list_repositories(team_id=None, platform=None, is_active=None, skip=0, limit=100):\n    params = {\"skip\": skip, \"limit\": limit}\n    if team_id:\n        params[\"team_id\"] = team_id\n    if platform:\n        params[\"platform\"] = platform\n    if is_active is not None:\n        params[\"is_active\"] = is_active\n\n    response = requests.get(\n        f\"{API_URL}/repositories\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get repository\ndef get_repository(repository_id):\n    response = requests.get(\n        f\"{API_URL}/repositories/{repository_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Create repository\ndef create_repository(\n    team_id,\n    name,\n    platform,\n    external_id,\n    url=None,\n    default_branch=\"main\",\n    is_private=False,\n    is_active=True\n):\n    data = {\n        \"team_id\": team_id,\n        \"name\": name,\n        \"platform\": platform,\n        \"external_id\": external_id,\n        \"url\": url,\n        \"default_branch\": default_branch,\n        \"is_private\": is_private,\n        \"is_active\": is_active\n    }\n    response = requests.post(\n        f\"{API_URL}/repositories\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Update repository\ndef update_repository(repository_id, **kwargs):\n    response = requests.put(\n        f\"{API_URL}/repositories/{repository_id}\",\n        headers=headers,\n        json=kwargs\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Delete repository\ndef delete_repository(repository_id):\n    response = requests.delete(\n        f\"{API_URL}/repositories/{repository_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return True\n\n# Get repository stats\ndef get_repository_stats(repository_id, start_date=None, end_date=None):\n    params = {}\n    if start_date:\n        params[\"start_date\"] = start_date.isoformat()\n    if end_date:\n        params[\"end_date\"] = end_date.isoformat()\n\n    response = requests.get(\n        f\"{API_URL}/repositories/{repository_id}/stats\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Usage examples\nif __name__ == \"__main__\":\n    team_id = \"770e8400-e29b-41d4-a716-446655440002\"\n\n    # Create a new repository\n    new_repo = create_repository(\n        team_id=team_id,\n        name=\"api-service\",\n        platform=\"github\",\n        external_id=\"12345678\",\n        url=\"https://github.com/acme-corp/api-service\",\n        default_branch=\"main\",\n        is_private=True\n    )\n    print(f\"Created repository: {new_repo['id']}\")\n\n    # List repositories for team\n    repos = list_repositories(team_id=team_id, platform=\"github\")\n    print(f\"Found {len(repos)} GitHub repositories\")\n\n    # Get repository stats\n    end_date = datetime.utcnow()\n    start_date = end_date - timedelta(days=30)\n    stats = get_repository_stats(\n        new_repo[\"id\"],\n        start_date=start_date,\n        end_date=end_date\n    )\n    print(f\"Repository stats: {stats['commits']['total']} commits\")\n\n    # Update repository\n    updated_repo = update_repository(\n        new_repo[\"id\"],\n        default_branch=\"develop\",\n        is_active=True\n    )\n    print(f\"Updated repository: {updated_repo['name']}\")\n</code></pre>"},{"location":"api/repositories/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>const API_URL = 'https://api.sei-platform.com/api/v1';\nconst API_KEY = process.env.SEI_API_KEY;\n\ninterface Repository {\n  id: string;\n  team_id: string;\n  name: string;\n  platform: 'github' | 'gitlab' | 'bitbucket';\n  external_id: string;\n  url?: string;\n  default_branch: string;\n  is_private: boolean;\n  is_active: boolean;\n  created_at: string;\n  updated_at: string;\n}\n\ninterface CreateRepositoryRequest {\n  team_id: string;\n  name: string;\n  platform: 'github' | 'gitlab' | 'bitbucket';\n  external_id: string;\n  url?: string;\n  default_branch?: string;\n  is_private?: boolean;\n  is_active?: boolean;\n}\n\ninterface UpdateRepositoryRequest {\n  team_id?: string;\n  name?: string;\n  default_branch?: string;\n  url?: string;\n  is_private?: boolean;\n  is_active?: boolean;\n}\n\ninterface RepositoryStats {\n  repository_id: string;\n  period: {\n    start: string;\n    end: string;\n  };\n  commits: {\n    total: number;\n    by_author: number;\n  };\n  pull_requests: {\n    opened: number;\n    merged: number;\n    closed: number;\n    avg_time_to_merge_hours: number;\n  };\n  deployments: {\n    total: number;\n    successful: number;\n    failed: number;\n  };\n  contributors: {\n    active: number;\n    total: number;\n  };\n}\n\nclass RepositoriesAPI {\n  private headers: HeadersInit;\n\n  constructor(apiKey: string) {\n    this.headers = {\n      'X-API-Key': apiKey,\n      'Content-Type': 'application/json'\n    };\n  }\n\n  async listRepositories(\n    teamId?: string,\n    platform?: string,\n    isActive?: boolean,\n    skip = 0,\n    limit = 100\n  ): Promise&lt;Repository[]&gt; {\n    const url = new URL(`${API_URL}/repositories`);\n    if (teamId) url.searchParams.set('team_id', teamId);\n    if (platform) url.searchParams.set('platform', platform);\n    if (isActive !== undefined) url.searchParams.set('is_active', isActive.toString());\n    url.searchParams.set('skip', skip.toString());\n    url.searchParams.set('limit', limit.toString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getRepository(repositoryId: string): Promise&lt;Repository&gt; {\n    const response = await fetch(`${API_URL}/repositories/${repositoryId}`, {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async createRepository(request: CreateRepositoryRequest): Promise&lt;Repository&gt; {\n    const response = await fetch(`${API_URL}/repositories`, {\n      method: 'POST',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async updateRepository(\n    repositoryId: string,\n    request: UpdateRepositoryRequest\n  ): Promise&lt;Repository&gt; {\n    const response = await fetch(`${API_URL}/repositories/${repositoryId}`, {\n      method: 'PUT',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async deleteRepository(repositoryId: string): Promise&lt;void&gt; {\n    const response = await fetch(`${API_URL}/repositories/${repositoryId}`, {\n      method: 'DELETE',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n  }\n\n  async getRepositoryStats(\n    repositoryId: string,\n    startDate?: Date,\n    endDate?: Date\n  ): Promise&lt;RepositoryStats&gt; {\n    const url = new URL(`${API_URL}/repositories/${repositoryId}/stats`);\n    if (startDate) url.searchParams.set('start_date', startDate.toISOString());\n    if (endDate) url.searchParams.set('end_date', endDate.toISOString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n}\n\n// Usage examples\nasync function main() {\n  const api = new RepositoriesAPI(API_KEY!);\n  const teamId = '770e8400-e29b-41d4-a716-446655440002';\n\n  // Create repository\n  const newRepo = await api.createRepository({\n    team_id: teamId,\n    name: 'api-service',\n    platform: 'github',\n    external_id: '12345678',\n    url: 'https://github.com/acme-corp/api-service',\n    default_branch: 'main',\n    is_private: true\n  });\n  console.log(`Created repository: ${newRepo.id}`);\n\n  // List repositories\n  const repos = await api.listRepositories(teamId, 'github');\n  console.log(`Found ${repos.length} GitHub repositories`);\n\n  // Get repository stats\n  const endDate = new Date();\n  const startDate = new Date(endDate.getTime() - 30 * 24 * 60 * 60 * 1000);\n  const stats = await api.getRepositoryStats(newRepo.id, startDate, endDate);\n  console.log(`Repository has ${stats.commits.total} commits`);\n\n  // Update repository\n  const updatedRepo = await api.updateRepository(newRepo.id, {\n    default_branch: 'develop'\n  });\n  console.log(`Updated repository: ${updatedRepo.name}`);\n}\n</code></pre>"},{"location":"api/repositories/#curl","title":"cURL","text":"<pre><code># List repositories\ncurl -X GET \"https://api.sei-platform.com/api/v1/repositories?team_id=770e8400-e29b-41d4-a716-446655440002&amp;platform=github\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get repository\ncurl -X GET \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Create repository\ncurl -X POST \"https://api.sei-platform.com/api/v1/repositories\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"name\": \"api-service\",\n    \"platform\": \"github\",\n    \"external_id\": \"12345678\",\n    \"url\": \"https://github.com/acme-corp/api-service\",\n    \"default_branch\": \"main\",\n    \"is_private\": true,\n    \"is_active\": true\n  }'\n\n# Update repository\ncurl -X PUT \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"default_branch\": \"develop\",\n    \"is_active\": true\n  }'\n\n# Delete repository\ncurl -X DELETE \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006\" \\\n  -H \"X-API-Key: sei_live_...\"\n\n# Get repository stats\ncurl -X GET \"https://api.sei-platform.com/api/v1/repositories/bb0e8400-e29b-41d4-a716-446655440006/stats?start_date=2024-01-01T00:00:00Z&amp;end_date=2024-01-31T23:59:59Z\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"api/repositories/#best-practices","title":"Best Practices","text":""},{"location":"api/repositories/#repository-setup","title":"Repository Setup","text":"<ol> <li>Use the platform's repository ID as the external_id</li> <li>Keep repository names consistent with the source platform</li> <li>Set is_private accurately to respect access controls</li> <li>Use is_active to control which repositories are tracked</li> </ol>"},{"location":"api/repositories/#platform-integration","title":"Platform Integration","text":"<ol> <li>Verify external_id matches the platform's repository ID format</li> <li>Use webhooks to keep repository data synchronized</li> <li>Handle platform-specific differences in branch naming</li> <li>Store full repository URLs for easy access</li> </ol>"},{"location":"api/repositories/#metric-tracking","title":"Metric Tracking","text":"<ol> <li>Set is_active=false for archived repositories</li> <li>Review inactive repositories regularly</li> <li>Use the stats endpoint for periodic reporting</li> <li>Consider time zones when analyzing time-based metrics</li> </ol>"},{"location":"api/repositories/#team-assignment","title":"Team Assignment","text":"<ol> <li>Assign repositories to teams based on ownership</li> <li>Update team assignments when ownership changes</li> <li>Keep repository-team relationships up to date</li> <li>Document repository ownership in team descriptions</li> </ol>"},{"location":"api/repositories/#rate-limiting","title":"Rate Limiting","text":"<p>Repository endpoints are subject to the standard rate limits:</p> <ul> <li>1000 requests per hour per API key</li> <li>100 requests per minute (burst limit)</li> </ul> <p>See Authentication for details on rate limit headers and handling.</p>"},{"location":"api/repositories/#next-steps","title":"Next Steps","text":"<ul> <li>Teams API - Manage teams that own repositories</li> <li>Developers API - Manage repository contributors</li> <li>Analytics API - View repository metrics and DORA metrics</li> <li>Organizations API - Manage parent organizations</li> </ul>"},{"location":"api/teams/","title":"Teams","text":""},{"location":"api/teams/#overview","title":"Overview","text":"<p>Teams represent groups of developers within an organization in the SEI Platform. Teams are used to organize developers, manage repositories, and track engineering metrics. Each team belongs to a single organization and can have multiple developers and repositories assigned to it.</p>"},{"location":"api/teams/#endpoints","title":"Endpoints","text":""},{"location":"api/teams/#list-teams","title":"List Teams","text":"<p>Retrieve a paginated list of all teams, optionally filtered by organization.</p> <pre><code>GET /api/v1/teams\n</code></pre> <p>Query Parameters:</p> Parameter Type Default Description organization_id string (UUID) - Filter teams by organization ID skip integer 0 Number of records to skip for pagination limit integer 100 Maximum number of records to return (max: 1000) sort string created_at Field to sort by (name, created_at, updated_at) order string desc Sort order (asc, desc) <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/teams?organization_id=550e8400-e29b-41d4-a716-446655440000&amp;skip=0&amp;limit=50\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"name\": \"Platform Team\",\n      \"description\": \"Core platform development team\",\n      \"settings\": {\n        \"sprint_length\": 14,\n        \"code_review_required\": true\n      },\n      \"created_at\": \"2024-01-05T10:00:00Z\",\n      \"updated_at\": \"2024-01-15T10:30:00Z\"\n    },\n    {\n      \"id\": \"880e8400-e29b-41d4-a716-446655440003\",\n      \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"name\": \"Mobile Team\",\n      \"description\": \"iOS and Android development\",\n      \"settings\": {\n        \"sprint_length\": 14,\n        \"code_review_required\": true\n      },\n      \"created_at\": \"2024-01-08T14:30:00Z\",\n      \"updated_at\": \"2024-01-12T09:15:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 2,\n    \"skip\": 0,\n    \"limit\": 50,\n    \"has_more\": false,\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#get-team","title":"Get Team","text":"<p>Retrieve a specific team by ID.</p> <pre><code>GET /api/v1/teams/{team_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Platform Team\",\n    \"description\": \"Core platform development team\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true,\n      \"deployment_frequency_target\": \"daily\"\n    },\n    \"created_at\": \"2024-01-05T10:00:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc124\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#create-team","title":"Create Team","text":"<p>Create a new team within an organization.</p> <pre><code>POST /api/v1/teams\n</code></pre> <p>Request Body:</p> Field Type Required Description organization_id string (UUID) Yes Organization ID this team belongs to name string Yes Team name (min: 2, max: 100 characters) description string No Team description (max: 500 characters) settings object No Team-specific settings (default: {}) <p>Request Example:</p> <pre><code>curl -X POST \"https://api.sei-platform.com/api/v1/teams\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Platform Team\",\n    \"description\": \"Core platform development team\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true\n    }\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"name\": \"Platform Team\",\n  \"description\": \"Core platform development team\",\n  \"settings\": {\n    \"sprint_length\": 14,\n    \"code_review_required\": true\n  }\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Platform Team\",\n    \"description\": \"Core platform development team\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true\n    },\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"updated_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc125\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#update-team","title":"Update Team","text":"<p>Update an existing team.</p> <pre><code>PUT /api/v1/teams/{team_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Request Body (all fields optional):</p> Field Type Description name string Updated team name description string Updated team description settings object Updated team settings <p>Request Example:</p> <pre><code>curl -X PUT \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Core Platform Team\",\n    \"description\": \"Core platform infrastructure and API development\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true,\n      \"deployment_frequency_target\": \"daily\"\n    }\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Core Platform Team\",\n  \"description\": \"Core platform infrastructure and API development\",\n  \"settings\": {\n    \"sprint_length\": 14,\n    \"code_review_required\": true,\n    \"deployment_frequency_target\": \"daily\"\n  }\n}\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": {\n    \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Core Platform Team\",\n    \"description\": \"Core platform infrastructure and API development\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true,\n      \"deployment_frequency_target\": \"daily\"\n    },\n    \"created_at\": \"2024-01-05T10:00:00Z\",\n    \"updated_at\": \"2024-01-15T11:45:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T11:45:00Z\",\n    \"request_id\": \"req_abc126\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#delete-team","title":"Delete Team","text":"<p>Delete a team. This operation will unassign all developers and repositories but will not delete them.</p> <pre><code>DELETE /api/v1/teams/{team_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Request Example:</p> <pre><code>curl -X DELETE \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\"\n</code></pre> <p>Response (204 No Content):</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/teams/#team-members","title":"Team Members","text":""},{"location":"api/teams/#list-team-members","title":"List Team Members","text":"<p>Get all developers assigned to a team.</p> <pre><code>GET /api/v1/teams/{team_id}/members\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Query Parameters:</p> Parameter Type Default Description skip integer 0 Number of records to skip for pagination limit integer 100 Maximum number of records to return <p>Request Example:</p> <pre><code>curl -X GET \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\"\n</code></pre> <p>Response (200 OK):</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"990e8400-e29b-41d4-a716-446655440004\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"email\": \"alice@acme.com\",\n      \"name\": \"Alice Johnson\",\n      \"github_username\": \"alicej\",\n      \"is_active\": true,\n      \"joined_at\": \"2024-01-05T10:00:00Z\",\n      \"created_at\": \"2024-01-05T10:00:00Z\"\n    },\n    {\n      \"id\": \"aa0e8400-e29b-41d4-a716-446655440005\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n      \"email\": \"bob@acme.com\",\n      \"name\": \"Bob Smith\",\n      \"github_username\": \"bobsmith\",\n      \"is_active\": true,\n      \"joined_at\": \"2024-01-08T14:30:00Z\",\n      \"created_at\": \"2024-01-08T14:30:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 2,\n    \"skip\": 0,\n    \"limit\": 100,\n    \"has_more\": false\n  }\n}\n</code></pre>"},{"location":"api/teams/#add-team-member","title":"Add Team Member","text":"<p>Add a developer to a team.</p> <pre><code>POST /api/v1/teams/{team_id}/members\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier <p>Request Body:</p> Field Type Required Description developer_id string (UUID) Yes Developer ID to add to team <p>Request Example:</p> <pre><code>curl -X POST \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\"\n  }'\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\"\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"data\": {\n    \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\",\n    \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\",\n    \"joined_at\": \"2024-01-15T10:30:00Z\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc127\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#remove-team-member","title":"Remove Team Member","text":"<p>Remove a developer from a team.</p> <pre><code>DELETE /api/v1/teams/{team_id}/members/{developer_id}\n</code></pre> <p>Path Parameters:</p> Parameter Type Required Description team_id string (UUID) Yes Team identifier developer_id string (UUID) Yes Developer identifier to remove <p>Request Example:</p> <pre><code>curl -X DELETE \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"Authorization: Bearer &lt;jwt_token&gt;\"\n</code></pre> <p>Response (204 No Content):</p> <pre><code>HTTP/1.1 204 No Content\n</code></pre>"},{"location":"api/teams/#error-responses","title":"Error Responses","text":""},{"location":"api/teams/#400-bad-request","title":"400 Bad Request","text":"<p>Validation Error:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request data\",\n    \"details\": {\n      \"field\": \"name\",\n      \"issue\": \"Team name must be at least 2 characters\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc128\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#404-not-found","title":"404 Not Found","text":"<p>Team Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Team not found\"\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc129\"\n  }\n}\n</code></pre> <p>Organization Not Found:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Organization not found\",\n    \"details\": {\n      \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc130\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#409-conflict","title":"409 Conflict","text":"<p>Duplicate Team Name:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"Team with this name already exists in organization\",\n    \"details\": {\n      \"field\": \"name\",\n      \"value\": \"Platform Team\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc131\"\n  }\n}\n</code></pre> <p>Developer Already in Team:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_CONFLICT\",\n    \"message\": \"Developer is already a member of this team\",\n    \"details\": {\n      \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\",\n      \"team_id\": \"770e8400-e29b-41d4-a716-446655440002\"\n    }\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc132\"\n  }\n}\n</code></pre>"},{"location":"api/teams/#data-model","title":"Data Model","text":""},{"location":"api/teams/#team-object","title":"Team Object","text":"Field Type Description id string (UUID) Unique team identifier organization_id string (UUID) Organization this team belongs to name string Team name description string or null Team description settings object Team-specific configuration created_at string (ISO 8601) Creation timestamp updated_at string (ISO 8601) Last update timestamp"},{"location":"api/teams/#settings-object","title":"Settings Object","text":"<p>Common settings fields:</p> Field Type Description sprint_length integer Sprint duration in days (e.g., 14) code_review_required boolean Require code reviews for merges deployment_frequency_target string Target deployment frequency (daily, weekly, etc.)"},{"location":"api/teams/#code-examples","title":"Code Examples","text":""},{"location":"api/teams/#python","title":"Python","text":"<pre><code>import requests\nimport os\n\nAPI_URL = \"https://api.sei-platform.com/api/v1\"\nAPI_KEY = os.getenv(\"SEI_API_KEY\")\n\nheaders = {\n    \"X-API-Key\": API_KEY,\n    \"Content-Type\": \"application/json\"\n}\n\n# List teams\ndef list_teams(organization_id=None, skip=0, limit=100):\n    params = {\"skip\": skip, \"limit\": limit}\n    if organization_id:\n        params[\"organization_id\"] = organization_id\n\n    response = requests.get(\n        f\"{API_URL}/teams\",\n        headers=headers,\n        params=params\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Get team\ndef get_team(team_id):\n    response = requests.get(\n        f\"{API_URL}/teams/{team_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Create team\ndef create_team(organization_id, name, description=None, settings=None):\n    data = {\n        \"organization_id\": organization_id,\n        \"name\": name,\n        \"description\": description,\n        \"settings\": settings or {}\n    }\n    response = requests.post(\n        f\"{API_URL}/teams\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Update team\ndef update_team(team_id, name=None, description=None, settings=None):\n    data = {}\n    if name:\n        data[\"name\"] = name\n    if description is not None:\n        data[\"description\"] = description\n    if settings:\n        data[\"settings\"] = settings\n\n    response = requests.put(\n        f\"{API_URL}/teams/{team_id}\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Delete team\ndef delete_team(team_id):\n    response = requests.delete(\n        f\"{API_URL}/teams/{team_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return True\n\n# List team members\ndef list_team_members(team_id):\n    response = requests.get(\n        f\"{API_URL}/teams/{team_id}/members\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Add team member\ndef add_team_member(team_id, developer_id):\n    data = {\"developer_id\": developer_id}\n    response = requests.post(\n        f\"{API_URL}/teams/{team_id}/members\",\n        headers=headers,\n        json=data\n    )\n    response.raise_for_status()\n    return response.json()[\"data\"]\n\n# Remove team member\ndef remove_team_member(team_id, developer_id):\n    response = requests.delete(\n        f\"{API_URL}/teams/{team_id}/members/{developer_id}\",\n        headers=headers\n    )\n    response.raise_for_status()\n    return True\n\n# Usage examples\nif __name__ == \"__main__\":\n    org_id = \"550e8400-e29b-41d4-a716-446655440000\"\n\n    # Create a new team\n    new_team = create_team(\n        organization_id=org_id,\n        name=\"Platform Team\",\n        description=\"Core platform development team\",\n        settings={\n            \"sprint_length\": 14,\n            \"code_review_required\": True\n        }\n    )\n    print(f\"Created team: {new_team['id']}\")\n\n    # List teams for organization\n    teams = list_teams(organization_id=org_id)\n    print(f\"Found {len(teams)} teams\")\n\n    # Add member to team\n    developer_id = \"990e8400-e29b-41d4-a716-446655440004\"\n    add_team_member(new_team[\"id\"], developer_id)\n    print(f\"Added developer {developer_id} to team\")\n\n    # List team members\n    members = list_team_members(new_team[\"id\"])\n    print(f\"Team has {len(members)} members\")\n</code></pre>"},{"location":"api/teams/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>const API_URL = 'https://api.sei-platform.com/api/v1';\nconst API_KEY = process.env.SEI_API_KEY;\n\ninterface Team {\n  id: string;\n  organization_id: string;\n  name: string;\n  description?: string;\n  settings: Record&lt;string, any&gt;;\n  created_at: string;\n  updated_at: string;\n}\n\ninterface CreateTeamRequest {\n  organization_id: string;\n  name: string;\n  description?: string;\n  settings?: Record&lt;string, any&gt;;\n}\n\ninterface UpdateTeamRequest {\n  name?: string;\n  description?: string;\n  settings?: Record&lt;string, any&gt;;\n}\n\ninterface TeamMember {\n  id: string;\n  team_id: string;\n  email: string;\n  name?: string;\n  github_username?: string;\n  is_active: boolean;\n  joined_at: string;\n  created_at: string;\n}\n\nclass TeamsAPI {\n  private headers: HeadersInit;\n\n  constructor(apiKey: string) {\n    this.headers = {\n      'X-API-Key': apiKey,\n      'Content-Type': 'application/json'\n    };\n  }\n\n  async listTeams(\n    organizationId?: string,\n    skip = 0,\n    limit = 100\n  ): Promise&lt;Team[]&gt; {\n    const url = new URL(`${API_URL}/teams`);\n    if (organizationId) {\n      url.searchParams.set('organization_id', organizationId);\n    }\n    url.searchParams.set('skip', skip.toString());\n    url.searchParams.set('limit', limit.toString());\n\n    const response = await fetch(url.toString(), {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async getTeam(teamId: string): Promise&lt;Team&gt; {\n    const response = await fetch(`${API_URL}/teams/${teamId}`, {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async createTeam(request: CreateTeamRequest): Promise&lt;Team&gt; {\n    const response = await fetch(`${API_URL}/teams`, {\n      method: 'POST',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async updateTeam(teamId: string, request: UpdateTeamRequest): Promise&lt;Team&gt; {\n    const response = await fetch(`${API_URL}/teams/${teamId}`, {\n      method: 'PUT',\n      headers: this.headers,\n      body: JSON.stringify(request)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async deleteTeam(teamId: string): Promise&lt;void&gt; {\n    const response = await fetch(`${API_URL}/teams/${teamId}`, {\n      method: 'DELETE',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n  }\n\n  async listTeamMembers(teamId: string): Promise&lt;TeamMember[]&gt; {\n    const response = await fetch(`${API_URL}/teams/${teamId}/members`, {\n      method: 'GET',\n      headers: this.headers\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async addTeamMember(teamId: string, developerId: string): Promise&lt;any&gt; {\n    const response = await fetch(`${API_URL}/teams/${teamId}/members`, {\n      method: 'POST',\n      headers: this.headers,\n      body: JSON.stringify({ developer_id: developerId })\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    return data.data;\n  }\n\n  async removeTeamMember(teamId: string, developerId: string): Promise&lt;void&gt; {\n    const response = await fetch(\n      `${API_URL}/teams/${teamId}/members/${developerId}`,\n      {\n        method: 'DELETE',\n        headers: this.headers\n      }\n    );\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.statusText}`);\n    }\n  }\n}\n\n// Usage examples\nasync function main() {\n  const api = new TeamsAPI(API_KEY!);\n  const orgId = '550e8400-e29b-41d4-a716-446655440000';\n\n  // Create team\n  const newTeam = await api.createTeam({\n    organization_id: orgId,\n    name: 'Platform Team',\n    description: 'Core platform development team',\n    settings: {\n      sprint_length: 14,\n      code_review_required: true\n    }\n  });\n  console.log(`Created team: ${newTeam.id}`);\n\n  // List teams\n  const teams = await api.listTeams(orgId);\n  console.log(`Found ${teams.length} teams`);\n\n  // Add team member\n  const developerId = '990e8400-e29b-41d4-a716-446655440004';\n  await api.addTeamMember(newTeam.id, developerId);\n  console.log(`Added developer to team`);\n\n  // List team members\n  const members = await api.listTeamMembers(newTeam.id);\n  console.log(`Team has ${members.length} members`);\n}\n</code></pre>"},{"location":"api/teams/#curl","title":"cURL","text":"<pre><code># List teams\ncurl -X GET \"https://api.sei-platform.com/api/v1/teams?organization_id=550e8400-e29b-41d4-a716-446655440000\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Get team\ncurl -X GET \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Create team\ncurl -X POST \"https://api.sei-platform.com/api/v1/teams\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"name\": \"Platform Team\",\n    \"description\": \"Core platform development team\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true\n    }\n  }'\n\n# Update team\ncurl -X PUT \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Core Platform Team\",\n    \"settings\": {\n      \"sprint_length\": 14,\n      \"code_review_required\": true,\n      \"deployment_frequency_target\": \"daily\"\n    }\n  }'\n\n# Delete team\ncurl -X DELETE \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002\" \\\n  -H \"X-API-Key: sei_live_...\"\n\n# List team members\ncurl -X GET \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\"\n\n# Add team member\ncurl -X POST \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members\" \\\n  -H \"X-API-Key: sei_live_...\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"developer_id\": \"990e8400-e29b-41d4-a716-446655440004\"\n  }'\n\n# Remove team member\ncurl -X DELETE \"https://api.sei-platform.com/api/v1/teams/770e8400-e29b-41d4-a716-446655440002/members/990e8400-e29b-41d4-a716-446655440004\" \\\n  -H \"X-API-Key: sei_live_...\"\n</code></pre>"},{"location":"api/teams/#best-practices","title":"Best Practices","text":""},{"location":"api/teams/#team-organization","title":"Team Organization","text":"<ol> <li>Create teams based on functional areas or product ownership</li> <li>Keep team sizes manageable (5-10 developers recommended)</li> <li>Use descriptive team names that reflect their purpose</li> <li>Document team responsibilities in the description field</li> </ol>"},{"location":"api/teams/#settings-management","title":"Settings Management","text":"<ol> <li>Define standard settings across teams for consistency</li> <li>Use settings for team-specific configurations</li> <li>Document custom settings in your application</li> <li>Review and update settings regularly as processes evolve</li> </ol>"},{"location":"api/teams/#member-management","title":"Member Management","text":"<ol> <li>Assign developers to teams based on their primary responsibilities</li> <li>Update team memberships when roles change</li> <li>Remove inactive members to keep metrics accurate</li> <li>Consider multi-team assignments for cross-functional work</li> </ol>"},{"location":"api/teams/#deletion-considerations","title":"Deletion Considerations","text":"<ol> <li>Review team dependencies before deletion</li> <li>Reassign repositories and developers before deleting teams</li> <li>Export team metrics and historical data for archival</li> <li>Consider deactivating teams instead of deletion</li> </ol>"},{"location":"api/teams/#rate-limiting","title":"Rate Limiting","text":"<p>Team endpoints are subject to the standard rate limits:</p> <ul> <li>1000 requests per hour per API key</li> <li>100 requests per minute (burst limit)</li> </ul> <p>See Authentication for details on rate limit headers and handling.</p>"},{"location":"api/teams/#next-steps","title":"Next Steps","text":"<ul> <li>Organizations API - Manage organizations</li> <li>Developers API - Manage team members</li> <li>Repositories API - Assign repositories to teams</li> <li>Analytics API - View team metrics</li> </ul>"},{"location":"architecture/api-design/","title":"API Design","text":""},{"location":"architecture/api-design/#api-architecture","title":"API Architecture","text":"<pre><code>graph LR\n    Client[Client Application] --&gt; Gateway[API Gateway]\n    Gateway --&gt; Auth[Authentication]\n    Gateway --&gt; RateLimit[Rate Limiter]\n    Gateway --&gt; Router[API Router]\n\n    Router --&gt; OrgAPI[Organizations API]\n    Router --&gt; TeamAPI[Teams API]\n    Router --&gt; RepoAPI[Repositories API]\n    Router --&gt; DevAPI[Developers API]\n    Router --&gt; AnalyticsAPI[Analytics API]\n\n    OrgAPI --&gt; DB[(Database)]\n    TeamAPI --&gt; DB\n    RepoAPI --&gt; DB\n    DevAPI --&gt; DB\n    AnalyticsAPI --&gt; DB\n    AnalyticsAPI --&gt; Cache[(Redis Cache)]</code></pre>"},{"location":"architecture/api-design/#rest-api-principles","title":"REST API Principles","text":""},{"location":"architecture/api-design/#base-url","title":"Base URL","text":"<pre><code>https://api.sei-platform.com/api/v1\n</code></pre>"},{"location":"architecture/api-design/#versioning","title":"Versioning","text":"<ul> <li>API versioned through URL path: <code>/api/v1</code>, <code>/api/v2</code></li> <li>Breaking changes require new version</li> <li>Maintain backward compatibility for at least 6 months</li> </ul>"},{"location":"architecture/api-design/#authentication","title":"Authentication","text":"<p>All requests require Bearer token:</p> <pre><code>Authorization: Bearer &lt;jwt_token&gt;\n</code></pre>"},{"location":"architecture/api-design/#response-format","title":"Response Format","text":"<p>Standard JSON response structure:</p> <pre><code>{\n  \"data\": {},\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre> <p>Error response:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Organization not found\",\n    \"details\": {}\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"architecture/api-design/#api-endpoints","title":"API Endpoints","text":""},{"location":"architecture/api-design/#organizations","title":"Organizations","text":""},{"location":"architecture/api-design/#list-organizations","title":"List Organizations","text":"<pre><code>GET /api/v1/organizations\n</code></pre> <p>Query Parameters:</p> <ul> <li><code>skip</code> (integer): Offset for pagination (default: 0)</li> <li><code>limit</code> (integer): Number of results (default: 100, max: 1000)</li> <li><code>sort</code> (string): Sort field (default: created_at)</li> <li><code>order</code> (string): Sort order: asc, desc (default: desc)</li> </ul> <p>Response:</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"name\": \"Acme Corporation\",\n      \"slug\": \"acme-corp\",\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"updated_at\": \"2024-01-01T00:00:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"total\": 1,\n    \"skip\": 0,\n    \"limit\": 100\n  }\n}\n</code></pre>"},{"location":"architecture/api-design/#create-organization","title":"Create Organization","text":"<pre><code>POST /api/v1/organizations\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Acme Corporation\",\n  \"slug\": \"acme-corp\"\n}\n</code></pre>"},{"location":"architecture/api-design/#get-organization","title":"Get Organization","text":"<pre><code>GET /api/v1/organizations/{org_id}\n</code></pre>"},{"location":"architecture/api-design/#update-organization","title":"Update Organization","text":"<pre><code>PUT /api/v1/organizations/{org_id}\n</code></pre>"},{"location":"architecture/api-design/#delete-organization","title":"Delete Organization","text":"<pre><code>DELETE /api/v1/organizations/{org_id}\n</code></pre>"},{"location":"architecture/api-design/#teams","title":"Teams","text":""},{"location":"architecture/api-design/#list-teams","title":"List Teams","text":"<pre><code>GET /api/v1/organizations/{org_id}/teams\n</code></pre>"},{"location":"architecture/api-design/#create-team","title":"Create Team","text":"<pre><code>POST /api/v1/organizations/{org_id}/teams\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"Platform Team\",\n  \"slug\": \"platform\"\n}\n</code></pre>"},{"location":"architecture/api-design/#get-team","title":"Get Team","text":"<pre><code>GET /api/v1/teams/{team_id}\n</code></pre>"},{"location":"architecture/api-design/#update-team","title":"Update Team","text":"<pre><code>PUT /api/v1/teams/{team_id}\n</code></pre>"},{"location":"architecture/api-design/#delete-team","title":"Delete Team","text":"<pre><code>DELETE /api/v1/teams/{team_id}\n</code></pre>"},{"location":"architecture/api-design/#team-members","title":"Team Members","text":"<pre><code>GET /api/v1/teams/{team_id}/members\nPOST /api/v1/teams/{team_id}/members\nDELETE /api/v1/teams/{team_id}/members/{developer_id}\n</code></pre>"},{"location":"architecture/api-design/#repositories","title":"Repositories","text":""},{"location":"architecture/api-design/#list-repositories","title":"List Repositories","text":"<pre><code>GET /api/v1/organizations/{org_id}/repositories\n</code></pre>"},{"location":"architecture/api-design/#create-repository","title":"Create Repository","text":"<pre><code>POST /api/v1/organizations/{org_id}/repositories\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"name\": \"api-service\",\n  \"provider\": \"github\",\n  \"provider_id\": \"12345678\",\n  \"url\": \"https://github.com/acme-corp/api-service\",\n  \"default_branch\": \"main\"\n}\n</code></pre>"},{"location":"architecture/api-design/#developers","title":"Developers","text":""},{"location":"architecture/api-design/#list-developers","title":"List Developers","text":"<pre><code>GET /api/v1/developers\n</code></pre>"},{"location":"architecture/api-design/#create-developer","title":"Create Developer","text":"<pre><code>POST /api/v1/developers\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"email\": \"developer@acme.com\",\n  \"name\": \"Jane Developer\",\n  \"github_username\": \"janedev\"\n}\n</code></pre>"},{"location":"architecture/api-design/#analytics","title":"Analytics","text":""},{"location":"architecture/api-design/#get-dora-metrics","title":"Get DORA Metrics","text":"<pre><code>GET /api/v1/analytics/dora\n</code></pre> <p>Query Parameters:</p> <ul> <li><code>repository_id</code> (uuid): Repository ID</li> <li><code>team_id</code> (uuid): Team ID</li> <li><code>start_date</code> (date): Start date (ISO 8601)</li> <li><code>end_date</code> (date): End date (ISO 8601)</li> <li><code>period</code> (string): daily, weekly, monthly</li> </ul> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"deployment_frequency\": {\n      \"value\": 2.5,\n      \"unit\": \"per_day\",\n      \"trend\": \"increasing\"\n    },\n    \"lead_time_for_changes\": {\n      \"value\": 24.5,\n      \"unit\": \"hours\",\n      \"trend\": \"decreasing\"\n    },\n    \"change_failure_rate\": {\n      \"value\": 0.15,\n      \"unit\": \"percentage\",\n      \"trend\": \"stable\"\n    },\n    \"time_to_restore\": {\n      \"value\": 2.3,\n      \"unit\": \"hours\",\n      \"trend\": \"decreasing\"\n    }\n  }\n}\n</code></pre>"},{"location":"architecture/api-design/#get-team-metrics","title":"Get Team Metrics","text":"<pre><code>GET /api/v1/analytics/teams/{team_id}\n</code></pre>"},{"location":"architecture/api-design/#get-developer-metrics","title":"Get Developer Metrics","text":"<pre><code>GET /api/v1/analytics/developers/{developer_id}\n</code></pre>"},{"location":"architecture/api-design/#requestresponse-flow","title":"Request/Response Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Gateway\n    participant Auth\n    participant API\n    participant Cache\n    participant DB\n\n    Client-&gt;&gt;Gateway: GET /api/v1/organizations\n    Gateway-&gt;&gt;Auth: Validate JWT\n    Auth--&gt;&gt;Gateway: Token valid\n    Gateway-&gt;&gt;API: Route request\n    API-&gt;&gt;Cache: Check cache\n\n    alt Cache hit\n        Cache--&gt;&gt;API: Cached data\n    else Cache miss\n        API-&gt;&gt;DB: Query database\n        DB--&gt;&gt;API: Data\n        API-&gt;&gt;Cache: Store in cache\n    end\n\n    API--&gt;&gt;Gateway: Response\n    Gateway--&gt;&gt;Client: JSON response</code></pre>"},{"location":"architecture/api-design/#error-codes","title":"Error Codes","text":"Code HTTP Status Description UNAUTHORIZED 401 Invalid or missing authentication FORBIDDEN 403 Insufficient permissions NOT_FOUND 404 Resource not found VALIDATION_ERROR 422 Invalid request data RATE_LIMIT_EXCEEDED 429 Too many requests INTERNAL_ERROR 500 Server error"},{"location":"architecture/api-design/#rate-limiting","title":"Rate Limiting","text":"<p>Default Limits:</p> <ul> <li>1000 requests per hour per IP</li> <li>100 requests per minute (burst)</li> </ul> <p>Headers:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1705392000\n</code></pre>"},{"location":"architecture/api-design/#pagination","title":"Pagination","text":"<p>Request:</p> <pre><code>GET /api/v1/organizations?skip=0&amp;limit=50\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": [...],\n  \"meta\": {\n    \"total\": 150,\n    \"skip\": 0,\n    \"limit\": 50,\n    \"has_more\": true\n  }\n}\n</code></pre>"},{"location":"architecture/api-design/#filtering","title":"Filtering","text":"<p>Query String Filters:</p> <pre><code>GET /api/v1/repositories?provider=github&amp;status=active\n</code></pre>"},{"location":"architecture/api-design/#sorting","title":"Sorting","text":"<p>Syntax:</p> <pre><code>GET /api/v1/organizations?sort=name&amp;order=asc\n</code></pre>"},{"location":"architecture/api-design/#field-selection","title":"Field Selection","text":"<p>Sparse Fieldsets:</p> <pre><code>GET /api/v1/organizations?fields=id,name,slug\n</code></pre>"},{"location":"architecture/api-design/#webhooks","title":"Webhooks","text":"<p>Webhook Events:</p> <ul> <li><code>organization.created</code></li> <li><code>team.created</code></li> <li><code>repository.created</code></li> <li><code>deployment.completed</code></li> </ul> <p>Webhook Payload:</p> <pre><code>{\n  \"event\": \"deployment.completed\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"data\": {\n    \"repository_id\": \"uuid\",\n    \"environment\": \"production\",\n    \"status\": \"success\"\n  }\n}\n</code></pre>"},{"location":"architecture/api-design/#api-clients","title":"API Clients","text":""},{"location":"architecture/api-design/#python-example","title":"Python Example","text":"<pre><code>import requests\n\nBASE_URL = \"https://api.sei-platform.com/api/v1\"\nTOKEN = \"your_jwt_token\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Get organizations\nresponse = requests.get(f\"{BASE_URL}/organizations\", headers=headers)\norganizations = response.json()[\"data\"]\n\n# Create team\nteam_data = {\n    \"name\": \"Platform Team\",\n    \"slug\": \"platform\"\n}\nresponse = requests.post(\n    f\"{BASE_URL}/organizations/{org_id}/teams\",\n    headers=headers,\n    json=team_data\n)\n</code></pre>"},{"location":"architecture/api-design/#javascript-example","title":"JavaScript Example","text":"<pre><code>const BASE_URL = 'https://api.sei-platform.com/api/v1';\nconst TOKEN = 'your_jwt_token';\n\nconst headers = {\n  'Authorization': `Bearer ${TOKEN}`,\n  'Content-Type': 'application/json'\n};\n\n// Get organizations\nconst response = await fetch(`${BASE_URL}/organizations`, { headers });\nconst { data } = await response.json();\n\n// Create team\nconst teamData = {\n  name: 'Platform Team',\n  slug: 'platform'\n};\nawait fetch(`${BASE_URL}/organizations/${orgId}/teams`, {\n  method: 'POST',\n  headers,\n  body: JSON.stringify(teamData)\n});\n</code></pre>"},{"location":"architecture/api-design/#next-steps","title":"Next Steps","text":"<ul> <li>API Authentication - Authentication details</li> <li>API Reference - Complete API documentation</li> <li>Security - API security implementation</li> </ul>"},{"location":"architecture/data-models/","title":"Data Models","text":""},{"location":"architecture/data-models/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>erDiagram\n    ORGANIZATIONS ||--o{ TEAMS : has\n    ORGANIZATIONS ||--o{ REPOSITORIES : owns\n    TEAMS ||--o{ TEAM_MEMBERS : contains\n    DEVELOPERS ||--o{ TEAM_MEMBERS : joins\n    REPOSITORIES ||--o{ COMMITS : contains\n    REPOSITORIES ||--o{ PULL_REQUESTS : contains\n    REPOSITORIES ||--o{ DEPLOYMENTS : deploys\n    DEVELOPERS ||--o{ COMMITS : authors\n    DEVELOPERS ||--o{ PULL_REQUESTS : creates\n\n    ORGANIZATIONS {\n        uuid id PK\n        varchar name\n        varchar slug UK\n        timestamptz created_at\n        timestamptz updated_at\n    }\n\n    TEAMS {\n        uuid id PK\n        uuid organization_id FK\n        varchar name\n        varchar slug\n        timestamptz created_at\n    }\n\n    DEVELOPERS {\n        uuid id PK\n        varchar email UK\n        varchar name\n        varchar github_username\n        varchar gitlab_username\n        timestamptz created_at\n    }\n\n    REPOSITORIES {\n        uuid id PK\n        uuid organization_id FK\n        varchar name\n        varchar provider\n        varchar provider_id\n        text url\n        varchar default_branch\n        timestamptz created_at\n    }\n\n    TEAM_MEMBERS {\n        uuid team_id FK\n        uuid developer_id FK\n        varchar role\n        timestamptz joined_at\n    }\n\n    COMMITS {\n        timestamptz time\n        uuid repository_id FK\n        varchar commit_sha\n        uuid author_id FK\n        int lines_added\n        int lines_deleted\n        int files_changed\n        text message\n    }\n\n    PULL_REQUESTS {\n        timestamptz time\n        uuid repository_id FK\n        int pr_number\n        uuid author_id FK\n        varchar state\n        timestamptz merged_at\n        int lines_added\n        int lines_deleted\n        int review_comments\n    }\n\n    DEPLOYMENTS {\n        timestamptz time\n        uuid repository_id FK\n        varchar environment\n        varchar status\n        int duration_seconds\n        uuid deployed_by FK\n    }</code></pre>"},{"location":"architecture/data-models/#core-entity-models","title":"Core Entity Models","text":""},{"location":"architecture/data-models/#organization","title":"Organization","text":"<p>Represents a company or organization using the platform.</p> <p>Fields:</p> <ul> <li><code>id</code> (UUID): Primary key</li> <li><code>name</code> (String): Organization name</li> <li><code>slug</code> (String): URL-friendly identifier (unique)</li> <li><code>created_at</code> (Timestamp): Creation timestamp</li> <li><code>updated_at</code> (Timestamp): Last update timestamp</li> </ul> <p>Relationships:</p> <ul> <li>Has many Teams</li> <li>Has many Repositories</li> </ul> <p>Example:</p> <pre><code>{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"name\": \"Acme Corporation\",\n  \"slug\": \"acme-corp\",\n  \"created_at\": \"2024-01-01T00:00:00Z\",\n  \"updated_at\": \"2024-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"architecture/data-models/#team","title":"Team","text":"<p>Represents a development team within an organization.</p> <p>Fields:</p> <ul> <li><code>id</code> (UUID): Primary key</li> <li><code>organization_id</code> (UUID): Foreign key to organization</li> <li><code>name</code> (String): Team name</li> <li><code>slug</code> (String): URL-friendly identifier (unique within org)</li> <li><code>created_at</code> (Timestamp): Creation timestamp</li> </ul> <p>Relationships:</p> <ul> <li>Belongs to Organization</li> <li>Has many Developers (through team_members)</li> </ul> <p>Example:</p> <pre><code>{\n  \"id\": \"660e8400-e29b-41d4-a716-446655440001\",\n  \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"name\": \"Platform Team\",\n  \"slug\": \"platform\",\n  \"created_at\": \"2024-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"architecture/data-models/#developer","title":"Developer","text":"<p>Represents an individual developer across the platform.</p> <p>Fields:</p> <ul> <li><code>id</code> (UUID): Primary key</li> <li><code>email</code> (String): Email address (unique)</li> <li><code>name</code> (String): Full name</li> <li><code>github_username</code> (String): GitHub username</li> <li><code>gitlab_username</code> (String): GitLab username</li> <li><code>created_at</code> (Timestamp): Creation timestamp</li> </ul> <p>Relationships:</p> <ul> <li>Belongs to many Teams (through team_members)</li> <li>Has many Commits</li> <li>Has many Pull Requests</li> </ul> <p>Example:</p> <pre><code>{\n  \"id\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"email\": \"developer@acme.com\",\n  \"name\": \"Jane Developer\",\n  \"github_username\": \"janedev\",\n  \"gitlab_username\": \"janedev\",\n  \"created_at\": \"2024-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"architecture/data-models/#repository","title":"Repository","text":"<p>Represents a Git repository tracked by the platform.</p> <p>Fields:</p> <ul> <li><code>id</code> (UUID): Primary key</li> <li><code>organization_id</code> (UUID): Foreign key to organization</li> <li><code>name</code> (String): Repository name</li> <li><code>provider</code> (String): Git provider (github, gitlab, bitbucket)</li> <li><code>provider_id</code> (String): Provider-specific ID</li> <li><code>url</code> (String): Repository URL</li> <li><code>default_branch</code> (String): Default branch name</li> <li><code>created_at</code> (Timestamp): Creation timestamp</li> </ul> <p>Relationships:</p> <ul> <li>Belongs to Organization</li> <li>Has many Commits</li> <li>Has many Pull Requests</li> <li>Has many Deployments</li> </ul> <p>Example:</p> <pre><code>{\n  \"id\": \"880e8400-e29b-41d4-a716-446655440003\",\n  \"organization_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"name\": \"api-service\",\n  \"provider\": \"github\",\n  \"provider_id\": \"12345678\",\n  \"url\": \"https://github.com/acme-corp/api-service\",\n  \"default_branch\": \"main\",\n  \"created_at\": \"2024-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"architecture/data-models/#time-series-models","title":"Time-Series Models","text":""},{"location":"architecture/data-models/#commit","title":"Commit","text":"<p>Represents a Git commit event (stored in TimescaleDB).</p> <p>Fields:</p> <ul> <li><code>time</code> (Timestamp): Commit timestamp (partition key)</li> <li><code>repository_id</code> (UUID): Repository reference</li> <li><code>commit_sha</code> (String): Git commit SHA</li> <li><code>author_id</code> (UUID): Developer reference</li> <li><code>lines_added</code> (Integer): Lines of code added</li> <li><code>lines_deleted</code> (Integer): Lines of code deleted</li> <li><code>files_changed</code> (Integer): Number of files modified</li> <li><code>message</code> (Text): Commit message</li> </ul> <p>Indexes:</p> <ul> <li>Hypertable partitioned by time</li> <li>Index on repository_id</li> <li>Index on author_id</li> </ul>"},{"location":"architecture/data-models/#pull-request","title":"Pull Request","text":"<p>Represents a pull request event.</p> <p>Fields:</p> <ul> <li><code>time</code> (Timestamp): PR creation time (partition key)</li> <li><code>repository_id</code> (UUID): Repository reference</li> <li><code>pr_number</code> (Integer): PR number</li> <li><code>author_id</code> (UUID): Developer reference</li> <li><code>state</code> (String): open, closed, merged</li> <li><code>merged_at</code> (Timestamp): Merge timestamp</li> <li><code>lines_added</code> (Integer): Lines added</li> <li><code>lines_deleted</code> (Integer): Lines deleted</li> <li><code>review_comments</code> (Integer): Number of review comments</li> </ul>"},{"location":"architecture/data-models/#deployment","title":"Deployment","text":"<p>Represents a deployment event.</p> <p>Fields:</p> <ul> <li><code>time</code> (Timestamp): Deployment time (partition key)</li> <li><code>repository_id</code> (UUID): Repository reference</li> <li><code>environment</code> (String): production, staging, development</li> <li><code>status</code> (String): success, failed, in_progress</li> <li><code>duration_seconds</code> (Integer): Deployment duration</li> <li><code>deployed_by</code> (UUID): Developer reference</li> </ul>"},{"location":"architecture/data-models/#aggregate-models","title":"Aggregate Models","text":""},{"location":"architecture/data-models/#dailycommitstats","title":"DailyCommitStats","text":"<p>Continuous aggregate for daily commit statistics.</p> <p>Fields:</p> <ul> <li><code>day</code> (Date): Day bucket</li> <li><code>repository_id</code> (UUID): Repository reference</li> <li><code>commit_count</code> (Integer): Total commits</li> <li><code>total_lines_added</code> (Integer): Sum of lines added</li> <li><code>total_lines_deleted</code> (Integer): Sum of lines deleted</li> </ul> <p>Refresh Policy: Every hour</p>"},{"location":"architecture/data-models/#weeklydorametrics","title":"WeeklyDORAMetrics","text":"<p>Continuous aggregate for weekly DORA metrics.</p> <p>Fields:</p> <ul> <li><code>week</code> (Date): Week bucket</li> <li><code>repository_id</code> (UUID): Repository reference</li> <li><code>deployment_count</code> (Integer): Number of deployments</li> <li><code>avg_duration</code> (Float): Average deployment duration</li> <li><code>failed_count</code> (Integer): Number of failed deployments</li> </ul> <p>Calculated Metrics:</p> <ul> <li>Deployment Frequency = deployment_count / 7</li> <li>Change Failure Rate = failed_count / deployment_count</li> </ul>"},{"location":"architecture/data-models/#data-flow","title":"Data Flow","text":"<pre><code>sequenceDiagram\n    participant Collector\n    participant Kafka\n    participant Processor\n    participant TimescaleDB\n    participant PostgreSQL\n    participant Redis\n\n    Collector-&gt;&gt;Kafka: Publish commit event\n    Kafka-&gt;&gt;Processor: Consume event\n    Processor-&gt;&gt;Processor: Validate &amp; transform\n    Processor-&gt;&gt;PostgreSQL: Upsert developer\n    Processor-&gt;&gt;TimescaleDB: Insert commit\n    Processor-&gt;&gt;Redis: Invalidate cache\n    Processor-&gt;&gt;TimescaleDB: Trigger aggregates</code></pre>"},{"location":"architecture/data-models/#schema-evolution","title":"Schema Evolution","text":""},{"location":"architecture/data-models/#migration-strategy","title":"Migration Strategy","text":"<ol> <li>Backward Compatible Changes: Add new columns with defaults</li> <li>Breaking Changes: Versioned schemas with migration period</li> <li>Data Transformations: Background jobs for large datasets</li> </ol>"},{"location":"architecture/data-models/#example-migration","title":"Example Migration","text":"<pre><code># Alembic migration\ndef upgrade():\n    op.add_column('developers',\n        sa.Column('bitbucket_username', sa.String(255), nullable=True)\n    )\n    op.create_index('ix_developers_bitbucket', 'developers', ['bitbucket_username'])\n\ndef downgrade():\n    op.drop_index('ix_developers_bitbucket')\n    op.drop_column('developers', 'bitbucket_username')\n</code></pre>"},{"location":"architecture/data-models/#data-retention-policies","title":"Data Retention Policies","text":""},{"location":"architecture/data-models/#time-series-data","title":"Time-Series Data","text":"<ul> <li>Raw Events: 90 days</li> <li>Daily Aggregates: 2 years</li> <li>Weekly Aggregates: 5 years</li> <li>Monthly Aggregates: Indefinite</li> </ul>"},{"location":"architecture/data-models/#relational-data","title":"Relational Data","text":"<ul> <li>Active Records: Indefinite</li> <li>Soft Deleted: 1 year</li> <li>Audit Logs: 3 years</li> </ul>"},{"location":"architecture/data-models/#query-patterns","title":"Query Patterns","text":""},{"location":"architecture/data-models/#common-queries","title":"Common Queries","text":"<p>Get team metrics:</p> <pre><code>SELECT\n    d.day,\n    SUM(d.commit_count) as total_commits,\n    SUM(d.total_lines_added) as total_additions\nFROM daily_commit_stats d\nJOIN repositories r ON d.repository_id = r.id\nJOIN teams t ON r.organization_id = t.organization_id\nWHERE t.id = $team_id\n  AND d.day &gt;= NOW() - INTERVAL '30 days'\nGROUP BY d.day\nORDER BY d.day;\n</code></pre> <p>Calculate deployment frequency:</p> <pre><code>SELECT\n    w.week,\n    w.deployment_count::float / 7 as deployments_per_day\nFROM weekly_dora_metrics w\nWHERE w.repository_id = $repo_id\n  AND w.week &gt;= NOW() - INTERVAL '12 weeks'\nORDER BY w.week;\n</code></pre>"},{"location":"architecture/data-models/#next-steps","title":"Next Steps","text":"<ul> <li>Database Schema - Complete schema DDL</li> <li>API Design - API endpoints for data access</li> <li>Security - Data security and access control</li> </ul>"},{"location":"architecture/database-schema/","title":"Database Schema","text":""},{"location":"architecture/database-schema/#overview","title":"Overview","text":"<p>The SEI Platform uses two primary databases:</p> <ul> <li>PostgreSQL: Relational data (organizations, teams, developers, repositories)</li> <li>TimescaleDB: Time-series data (commits, pull requests, deployments)</li> </ul>"},{"location":"architecture/database-schema/#postgresql-schema","title":"PostgreSQL Schema","text":""},{"location":"architecture/database-schema/#organizations-table","title":"Organizations Table","text":"<pre><code>CREATE TABLE organizations (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    slug VARCHAR(255) NOT NULL UNIQUE,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_organizations_slug ON organizations(slug);\nCREATE INDEX idx_organizations_created_at ON organizations(created_at);\n</code></pre>"},{"location":"architecture/database-schema/#teams-table","title":"Teams Table","text":"<pre><code>CREATE TABLE teams (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,\n    name VARCHAR(255) NOT NULL,\n    slug VARCHAR(255) NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    UNIQUE(organization_id, slug)\n);\n\nCREATE INDEX idx_teams_organization_id ON teams(organization_id);\nCREATE INDEX idx_teams_slug ON teams(organization_id, slug);\n</code></pre>"},{"location":"architecture/database-schema/#developers-table","title":"Developers Table","text":"<pre><code>CREATE TABLE developers (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) NOT NULL UNIQUE,\n    name VARCHAR(255) NOT NULL,\n    github_username VARCHAR(255),\n    gitlab_username VARCHAR(255),\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_developers_email ON developers(email);\nCREATE INDEX idx_developers_github_username ON developers(github_username);\nCREATE INDEX idx_developers_gitlab_username ON developers(gitlab_username);\n</code></pre>"},{"location":"architecture/database-schema/#team-members-table","title":"Team Members Table","text":"<pre><code>CREATE TABLE team_members (\n    team_id UUID NOT NULL REFERENCES teams(id) ON DELETE CASCADE,\n    developer_id UUID NOT NULL REFERENCES developers(id) ON DELETE CASCADE,\n    role VARCHAR(50) NOT NULL DEFAULT 'member',\n    joined_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    PRIMARY KEY (team_id, developer_id)\n);\n\nCREATE INDEX idx_team_members_team_id ON team_members(team_id);\nCREATE INDEX idx_team_members_developer_id ON team_members(developer_id);\n</code></pre>"},{"location":"architecture/database-schema/#repositories-table","title":"Repositories Table","text":"<pre><code>CREATE TABLE repositories (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,\n    name VARCHAR(255) NOT NULL,\n    provider VARCHAR(50) NOT NULL,\n    provider_id VARCHAR(255) NOT NULL,\n    url TEXT NOT NULL,\n    default_branch VARCHAR(255) NOT NULL DEFAULT 'main',\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    UNIQUE(provider, provider_id)\n);\n\nCREATE INDEX idx_repositories_organization_id ON repositories(organization_id);\nCREATE INDEX idx_repositories_provider ON repositories(provider, provider_id);\nCREATE INDEX idx_repositories_name ON repositories(name);\n</code></pre>"},{"location":"architecture/database-schema/#timescaledb-schema","title":"TimescaleDB Schema","text":""},{"location":"architecture/database-schema/#commits-hypertable","title":"Commits Hypertable","text":"<pre><code>CREATE TABLE commits (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    commit_sha VARCHAR(40) NOT NULL,\n    author_id UUID NOT NULL REFERENCES developers(id),\n    lines_added INTEGER NOT NULL DEFAULT 0,\n    lines_deleted INTEGER NOT NULL DEFAULT 0,\n    files_changed INTEGER NOT NULL DEFAULT 0,\n    message TEXT,\n    UNIQUE(repository_id, commit_sha)\n);\n\n-- Convert to hypertable\nSELECT create_hypertable('commits', 'time');\n\n-- Create indexes\nCREATE INDEX idx_commits_repository_id ON commits(repository_id, time DESC);\nCREATE INDEX idx_commits_author_id ON commits(author_id, time DESC);\nCREATE INDEX idx_commits_sha ON commits(commit_sha);\n</code></pre>"},{"location":"architecture/database-schema/#pull-requests-hypertable","title":"Pull Requests Hypertable","text":"<pre><code>CREATE TABLE pull_requests (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    pr_number INTEGER NOT NULL,\n    author_id UUID NOT NULL REFERENCES developers(id),\n    state VARCHAR(20) NOT NULL,\n    merged_at TIMESTAMPTZ,\n    lines_added INTEGER NOT NULL DEFAULT 0,\n    lines_deleted INTEGER NOT NULL DEFAULT 0,\n    review_comments INTEGER NOT NULL DEFAULT 0,\n    UNIQUE(repository_id, pr_number)\n);\n\n-- Convert to hypertable\nSELECT create_hypertable('pull_requests', 'time');\n\n-- Create indexes\nCREATE INDEX idx_pull_requests_repository_id ON pull_requests(repository_id, time DESC);\nCREATE INDEX idx_pull_requests_author_id ON pull_requests(author_id, time DESC);\nCREATE INDEX idx_pull_requests_state ON pull_requests(state);\n</code></pre>"},{"location":"architecture/database-schema/#deployments-hypertable","title":"Deployments Hypertable","text":"<pre><code>CREATE TABLE deployments (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    environment VARCHAR(50) NOT NULL,\n    status VARCHAR(20) NOT NULL,\n    duration_seconds INTEGER,\n    deployed_by UUID REFERENCES developers(id)\n);\n\n-- Convert to hypertable\nSELECT create_hypertable('deployments', 'time');\n\n-- Create indexes\nCREATE INDEX idx_deployments_repository_id ON deployments(repository_id, time DESC);\nCREATE INDEX idx_deployments_environment ON deployments(environment, time DESC);\nCREATE INDEX idx_deployments_status ON deployments(status);\n</code></pre>"},{"location":"architecture/database-schema/#continuous-aggregates","title":"Continuous Aggregates","text":""},{"location":"architecture/database-schema/#daily-commit-statistics","title":"Daily Commit Statistics","text":"<pre><code>CREATE MATERIALIZED VIEW daily_commit_stats\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 day', time) AS day,\n    repository_id,\n    COUNT(*) AS commit_count,\n    SUM(lines_added) AS total_lines_added,\n    SUM(lines_deleted) AS total_lines_deleted,\n    SUM(files_changed) AS total_files_changed,\n    COUNT(DISTINCT author_id) AS unique_authors\nFROM commits\nGROUP BY day, repository_id;\n\n-- Refresh policy\nSELECT add_continuous_aggregate_policy('daily_commit_stats',\n    start_offset =&gt; INTERVAL '3 days',\n    end_offset =&gt; INTERVAL '1 hour',\n    schedule_interval =&gt; INTERVAL '1 hour'\n);\n</code></pre>"},{"location":"architecture/database-schema/#weekly-dora-metrics","title":"Weekly DORA Metrics","text":"<pre><code>CREATE MATERIALIZED VIEW weekly_dora_metrics\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 week', time) AS week,\n    repository_id,\n    COUNT(*) AS deployment_count,\n    AVG(duration_seconds) AS avg_duration_seconds,\n    SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) AS failed_count,\n    SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) AS success_count\nFROM deployments\nGROUP BY week, repository_id;\n\n-- Refresh policy\nSELECT add_continuous_aggregate_policy('weekly_dora_metrics',\n    start_offset =&gt; INTERVAL '2 weeks',\n    end_offset =&gt; INTERVAL '1 hour',\n    schedule_interval =&gt; INTERVAL '1 hour'\n);\n</code></pre>"},{"location":"architecture/database-schema/#monthly-developer-activity","title":"Monthly Developer Activity","text":"<pre><code>CREATE MATERIALIZED VIEW monthly_developer_activity\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 month', time) AS month,\n    author_id,\n    repository_id,\n    COUNT(*) AS commit_count,\n    SUM(lines_added) AS total_lines_added,\n    SUM(lines_deleted) AS total_lines_deleted\nFROM commits\nGROUP BY month, author_id, repository_id;\n\n-- Refresh policy\nSELECT add_continuous_aggregate_policy('monthly_developer_activity',\n    start_offset =&gt; INTERVAL '3 months',\n    end_offset =&gt; INTERVAL '1 day',\n    schedule_interval =&gt; INTERVAL '1 day'\n);\n</code></pre>"},{"location":"architecture/database-schema/#data-retention-policies","title":"Data Retention Policies","text":""},{"location":"architecture/database-schema/#compress-old-data","title":"Compress Old Data","text":"<pre><code>-- Compress commits older than 90 days\nSELECT add_compression_policy('commits', INTERVAL '90 days');\n\n-- Compress pull requests older than 90 days\nSELECT add_compression_policy('pull_requests', INTERVAL '90 days');\n\n-- Compress deployments older than 90 days\nSELECT add_compression_policy('deployments', INTERVAL '90 days');\n</code></pre>"},{"location":"architecture/database-schema/#drop-old-raw-data","title":"Drop Old Raw Data","text":"<pre><code>-- Drop raw commits older than 2 years\nSELECT add_retention_policy('commits', INTERVAL '2 years');\n\n-- Drop raw pull requests older than 2 years\nSELECT add_retention_policy('pull_requests', INTERVAL '2 years');\n\n-- Drop raw deployments older than 2 years\nSELECT add_retention_policy('deployments', INTERVAL '2 years');\n</code></pre>"},{"location":"architecture/database-schema/#migrations","title":"Migrations","text":""},{"location":"architecture/database-schema/#alembic-configuration","title":"Alembic Configuration","text":"<p>alembic.ini:</p> <pre><code>[alembic]\nscript_location = alembic\nsqlalchemy.url = postgresql://user:pass@localhost/sei_platform\n\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n</code></pre>"},{"location":"architecture/database-schema/#example-migration","title":"Example Migration","text":"<p>alembic/versions/001_initial_schema.py:</p> <pre><code>\"\"\"Initial schema\n\nRevision ID: 001\nCreate Date: 2024-01-01 00:00:00\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects.postgresql import UUID\n\n# revision identifiers\nrevision = '001'\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    # Create organizations table\n    op.create_table(\n        'organizations',\n        sa.Column('id', UUID(as_uuid=True), primary_key=True),\n        sa.Column('name', sa.String(255), nullable=False),\n        sa.Column('slug', sa.String(255), nullable=False, unique=True),\n        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),\n        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), nullable=False)\n    )\n\n    # Create indexes\n    op.create_index('idx_organizations_slug', 'organizations', ['slug'])\n    op.create_index('idx_organizations_created_at', 'organizations', ['created_at'])\n\n\ndef downgrade():\n    op.drop_table('organizations')\n</code></pre>"},{"location":"architecture/database-schema/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture/database-schema/#connection-pooling","title":"Connection Pooling","text":"<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    'postgresql://user:pass@localhost/sei_platform',\n    poolclass=QueuePool,\n    pool_size=20,\n    max_overflow=40,\n    pool_pre_ping=True,\n    pool_recycle=3600\n)\n</code></pre>"},{"location":"architecture/database-schema/#query-optimization-tips","title":"Query Optimization Tips","text":"<ol> <li>Use appropriate indexes for frequently queried columns</li> <li>Partition hypertables by time for better performance</li> <li>Use continuous aggregates instead of real-time aggregation</li> <li>Enable compression for old data to save space</li> <li>Use connection pooling to reduce connection overhead</li> </ol>"},{"location":"architecture/database-schema/#monitoring-queries","title":"Monitoring Queries","text":"<pre><code>-- Check hypertable statistics\nSELECT * FROM timescaledb_information.hypertables;\n\n-- Check chunk information\nSELECT * FROM timescaledb_information.chunks\nWHERE hypertable_name = 'commits'\nORDER BY range_start DESC;\n\n-- Check compression stats\nSELECT * FROM timescaledb_information.compression_settings;\n\n-- Check continuous aggregate stats\nSELECT * FROM timescaledb_information.continuous_aggregates;\n</code></pre>"},{"location":"architecture/database-schema/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"architecture/database-schema/#postgresql-backup","title":"PostgreSQL Backup","text":"<pre><code># Full backup\npg_dump -h localhost -U postgres -d sei_platform -F c -f backup.dump\n\n# Restore\npg_restore -h localhost -U postgres -d sei_platform backup.dump\n</code></pre>"},{"location":"architecture/database-schema/#timescaledb-backup","title":"TimescaleDB Backup","text":"<pre><code># Backup with TimescaleDB extension\npg_dump -h localhost -U postgres -d sei_platform \\\n    --format=custom \\\n    --file=timescale_backup.dump\n\n# Restore\npg_restore -h localhost -U postgres -d sei_platform \\\n    --clean \\\n    timescale_backup.dump\n</code></pre>"},{"location":"architecture/database-schema/#next-steps","title":"Next Steps","text":"<ul> <li>Data Models - Entity relationships and models</li> <li>API Design - API endpoints and data access</li> <li>Security - Database security and access control</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":""},{"location":"architecture/overview/#introduction","title":"Introduction","text":"<p>The SEI Platform is built using a microservices architecture designed for scalability, maintainability, and extensibility. The platform collects, processes, and analyzes software engineering data from multiple sources to provide actionable insights through DORA metrics and team analytics.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Data Sources\"\n        GH[GitHub]\n        GL[GitLab]\n        BB[Bitbucket]\n        JIRA[Jira]\n        LINEAR[Linear]\n        ASANA[Asana]\n    end\n\n    subgraph \"Collectors\"\n        GC[Git Collector&lt;br/&gt;:8000]\n        JC[Jira Collector&lt;br/&gt;:8001]\n    end\n\n    subgraph \"Processing\"\n        DP[Data Processor&lt;br/&gt;:8002]\n        KAFKA[(Apache Kafka)]\n    end\n\n    subgraph \"Data Storage\"\n        TS[(TimescaleDB&lt;br/&gt;Time-series)]\n        PG[(PostgreSQL&lt;br/&gt;Metadata)]\n        REDIS[(Redis&lt;br/&gt;Cache)]\n    end\n\n    subgraph \"API Layer\"\n        API[API Service&lt;br/&gt;:8080&lt;br/&gt;FastAPI]\n    end\n\n    subgraph \"Presentation\"\n        WEB[Web Dashboard]\n        MB[Metabase]\n        GF[Grafana]\n    end\n\n    GH --&gt; GC\n    GL --&gt; GC\n    BB --&gt; GC\n    JIRA --&gt; JC\n    LINEAR --&gt; JC\n    ASANA --&gt; JC\n\n    GC --&gt; KAFKA\n    JC --&gt; KAFKA\n    KAFKA --&gt; DP\n\n    DP --&gt; TS\n    DP --&gt; PG\n    DP --&gt; REDIS\n\n    API --&gt; TS\n    API --&gt; PG\n    API --&gt; REDIS\n\n    WEB --&gt; API\n    MB --&gt; API\n    MB -.-&gt; TS\n    MB -.-&gt; PG\n    GF --&gt; API\n    GF -.-&gt; TS</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-data-collectors","title":"1. Data Collectors","text":"<p>Purpose: Integrate with external data sources and collect software engineering metrics</p> <ul> <li>Git Collector: Collects commits, pull requests, code reviews from GitHub, GitLab, Bitbucket</li> <li>Jira Collector: Collects issues, sprints, story points from project management tools</li> <li>Designed as independent microservices for parallel data collection</li> <li>Support multiple authentication methods (OAuth, API tokens, SSH keys)</li> </ul>"},{"location":"architecture/overview/#2-data-processing-layer","title":"2. Data Processing Layer","text":"<p>Purpose: Transform raw data into actionable metrics</p> <ul> <li>Data Processor: Consumes events from Kafka, calculates metrics, stores in database</li> <li>Real-time event processing using Apache Kafka</li> <li>Batch processing for historical data analysis</li> <li>Metric calculation engines for DORA metrics</li> </ul>"},{"location":"architecture/overview/#3-api-layer","title":"3. API Layer","text":"<p>Purpose: Provide REST API for frontend and external integrations</p> <ul> <li>API Service: FastAPI-based REST API</li> <li>Authentication and authorization</li> <li>Rate limiting and request validation</li> <li>OpenAPI/Swagger documentation</li> <li>Versioned endpoints (/api/v1)</li> </ul>"},{"location":"architecture/overview/#4-data-storage","title":"4. Data Storage","text":"<p>Purpose: Persist and query software engineering data</p> <ul> <li>TimescaleDB: Time-series data for metrics, events, and analytics</li> <li>PostgreSQL: Relational data for organizations, teams, repositories</li> <li>Redis: Caching layer for frequently accessed data</li> <li>Kafka: Event streaming and message queue</li> </ul>"},{"location":"architecture/overview/#5-analytics-visualization","title":"5. Analytics &amp; Visualization","text":"<p>Purpose: Present insights through dashboards and reports</p> <ul> <li>Metabase: Self-service BI tool for custom queries and reports</li> <li>Grafana: Real-time dashboards with Prometheus integration</li> <li>Web Dashboard: React-based frontend (planned)</li> </ul>"},{"location":"architecture/overview/#6-infrastructure-services","title":"6. Infrastructure Services","text":"<p>Purpose: Support platform operations and monitoring</p> <ul> <li>Prometheus: Metrics collection and alerting</li> <li>Grafana: Monitoring dashboards</li> <li>Apache Airflow: Workflow orchestration for batch jobs</li> <li>PgAdmin: Database administration</li> <li>Kafka UI: Message queue monitoring</li> </ul>"},{"location":"architecture/overview/#design-principles","title":"Design Principles","text":""},{"location":"architecture/overview/#1-microservices-architecture","title":"1. Microservices Architecture","text":"<p>Each service is independently deployable and scalable:</p> <ul> <li>Isolation: Services can be developed, deployed, and scaled independently</li> <li>Technology Diversity: Each service can use the most appropriate technology</li> <li>Fault Tolerance: Failure in one service doesn't cascade to others</li> <li>Team Autonomy: Different teams can own different services</li> </ul>"},{"location":"architecture/overview/#2-event-driven-architecture","title":"2. Event-Driven Architecture","text":"<p>Asynchronous communication through Apache Kafka:</p> <ul> <li>Decoupling: Services don't need to know about each other</li> <li>Scalability: Easily handle spikes in data collection</li> <li>Reliability: Message persistence and replay capabilities</li> <li>Real-time Processing: Stream processing for immediate insights</li> </ul>"},{"location":"architecture/overview/#3-api-first-design","title":"3. API-First Design","text":"<p>Well-defined APIs enable integration and extensibility:</p> <ul> <li>OpenAPI Specification: Auto-generated documentation</li> <li>Versioning: Backward compatibility with API versions</li> <li>Standard Protocols: REST, JSON, HTTP/2</li> <li>Rate Limiting: Protect against abuse</li> </ul>"},{"location":"architecture/overview/#4-data-driven-decisions","title":"4. Data-Driven Decisions","text":"<p>Store rich data to enable flexible analysis:</p> <ul> <li>Time-Series Data: Track metrics over time with TimescaleDB</li> <li>Event Sourcing: Store all events for audit and replay</li> <li>Schema Evolution: Support schema changes without downtime</li> <li>Data Retention: Configurable retention policies</li> </ul>"},{"location":"architecture/overview/#5-security-first","title":"5. Security First","text":"<p>Built-in security at every layer:</p> <ul> <li>Authentication: JWT tokens, API keys, OAuth 2.0</li> <li>Authorization: Role-based access control (RBAC)</li> <li>Encryption: TLS in transit, encryption at rest</li> <li>Audit Logging: Track all access and changes</li> </ul>"},{"location":"architecture/overview/#6-observability","title":"6. Observability","text":"<p>Comprehensive monitoring and debugging:</p> <ul> <li>Metrics: Prometheus metrics for all services</li> <li>Logs: Structured logging with correlation IDs</li> <li>Tracing: Distributed tracing (planned)</li> <li>Alerting: Proactive monitoring and alerts</li> </ul>"},{"location":"architecture/overview/#technology-stack","title":"Technology Stack","text":""},{"location":"architecture/overview/#backend-services","title":"Backend Services","text":"<ul> <li>Python 3.11+: Primary language for services</li> <li>FastAPI: Modern, fast API framework</li> <li>SQLAlchemy: ORM for database access</li> <li>Pydantic: Data validation and settings management</li> <li>Alembic: Database migration tool</li> </ul>"},{"location":"architecture/overview/#data-storage","title":"Data Storage","text":"<ul> <li>TimescaleDB: PostgreSQL extension for time-series data</li> <li>PostgreSQL 15+: Relational database</li> <li>Redis 7+: In-memory cache and session store</li> <li>Apache Kafka: Distributed event streaming</li> </ul>"},{"location":"architecture/overview/#infrastructure","title":"Infrastructure","text":"<ul> <li>Docker: Containerization</li> <li>Docker Compose: Local development orchestration</li> <li>Kubernetes: Production orchestration (planned)</li> <li>Nginx: Reverse proxy and load balancer (planned)</li> </ul>"},{"location":"architecture/overview/#monitoring-analytics","title":"Monitoring &amp; Analytics","text":"<ul> <li>Prometheus: Metrics collection</li> <li>Grafana: Visualization</li> <li>Metabase: Business intelligence</li> <li>Apache Airflow: Workflow orchestration</li> </ul>"},{"location":"architecture/overview/#development-tools","title":"Development Tools","text":"<ul> <li>pytest: Testing framework</li> <li>Black: Code formatter</li> <li>Flake8: Linting</li> <li>mypy: Type checking</li> <li>pre-commit: Git hooks</li> </ul>"},{"location":"architecture/overview/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"architecture/overview/#development-environment","title":"Development Environment","text":"<ul> <li>Docker Compose orchestrates all services</li> <li>Shared networks for inter-service communication</li> <li>Volume mounts for hot-reloading during development</li> <li>Local ports exposed for debugging</li> </ul>"},{"location":"architecture/overview/#production-environment-planned","title":"Production Environment (Planned)","text":"<ul> <li>Kubernetes cluster with multiple nodes</li> <li>Auto-scaling based on load</li> <li>Load balancing across service instances</li> <li>Blue-green deployments for zero downtime</li> <li>Managed databases (AWS RDS, TimescaleDB Cloud)</li> <li>CDN for static assets</li> </ul>"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#collection-flow","title":"Collection Flow","text":"<ol> <li>Collectors poll external APIs on schedule (hourly/daily)</li> <li>Raw data published to Kafka topics (<code>git.commits</code>, <code>jira.issues</code>)</li> <li>Data Processor consumes events from Kafka</li> <li>Processor transforms data and calculates metrics</li> <li>Metrics stored in TimescaleDB, metadata in PostgreSQL</li> </ol>"},{"location":"architecture/overview/#query-flow","title":"Query Flow","text":"<ol> <li>Client requests data from API Service</li> <li>API authenticates request and validates permissions</li> <li>API checks Redis cache for cached results</li> <li>On cache miss, API queries TimescaleDB/PostgreSQL</li> <li>Results cached in Redis with TTL</li> <li>Response returned to client with proper formatting</li> </ol>"},{"location":"architecture/overview/#analytics-flow","title":"Analytics Flow","text":"<ol> <li>Metabase/Grafana queries API or directly connects to databases</li> <li>Pre-computed metrics retrieved for dashboards</li> <li>Ad-hoc queries run for custom analysis</li> <li>Results visualized in charts and reports</li> </ol>"},{"location":"architecture/overview/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/overview/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Add more collector instances to handle more repositories</li> <li>Scale data processor instances to handle higher event volume</li> <li>Scale API service instances behind load balancer</li> </ul>"},{"location":"architecture/overview/#vertical-scaling","title":"Vertical Scaling","text":"<ul> <li>Increase database resources for larger datasets</li> <li>Increase Redis memory for more caching</li> <li>Increase Kafka brokers for higher throughput</li> </ul>"},{"location":"architecture/overview/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Connection pooling for databases</li> <li>Query optimization with proper indexes</li> <li>Caching frequently accessed data</li> <li>Pagination for large result sets</li> <li>Compression for data transfer</li> </ul>"},{"location":"architecture/overview/#security-architecture","title":"Security Architecture","text":""},{"location":"architecture/overview/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li>JWT tokens for API authentication</li> <li>API keys for service-to-service communication</li> <li>OAuth 2.0 for third-party integrations</li> <li>Role-based access control (RBAC)</li> </ul>"},{"location":"architecture/overview/#network-security","title":"Network Security","text":"<ul> <li>Services communicate within private networks</li> <li>Only API gateway exposed publicly</li> <li>TLS encryption for all connections</li> <li>Firewall rules limit access</li> </ul>"},{"location":"architecture/overview/#data-security","title":"Data Security","text":"<ul> <li>Secrets stored in environment variables</li> <li>Database encryption at rest</li> <li>Sensitive data redacted in logs</li> <li>Regular security audits</li> </ul>"},{"location":"architecture/overview/#next-steps","title":"Next Steps","text":"<ul> <li>System Design - Detailed component design</li> <li>Data Models - Database schemas and relationships</li> <li>API Design - API specifications</li> <li>Database Schema - Schema definitions</li> <li>Security - Security implementation details</li> </ul>"},{"location":"architecture/security/","title":"Security","text":""},{"location":"architecture/security/#security-overview","title":"Security Overview","text":"<p>The SEI Platform implements security at multiple layers to protect data and ensure authorized access.</p>"},{"location":"architecture/security/#authentication","title":"Authentication","text":""},{"location":"architecture/security/#jwt-token-authentication","title":"JWT Token Authentication","text":"<p>Token Structure:</p> <pre><code>{\n  \"sub\": \"user_id\",\n  \"email\": \"user@example.com\",\n  \"org_id\": \"organization_id\",\n  \"role\": \"admin\",\n  \"exp\": 1234567890,\n  \"iat\": 1234567800\n}\n</code></pre> <p>Token Generation:</p> <pre><code>import jwt\nfrom datetime import datetime, timedelta\n\ndef generate_token(user_id: str, email: str, org_id: str, role: str) -&gt; str:\n    payload = {\n        \"sub\": user_id,\n        \"email\": email,\n        \"org_id\": org_id,\n        \"role\": role,\n        \"exp\": datetime.utcnow() + timedelta(hours=24),\n        \"iat\": datetime.utcnow()\n    }\n    return jwt.encode(payload, SECRET_KEY, algorithm=\"HS256\")\n</code></pre> <p>Token Validation:</p> <pre><code>from fastapi import HTTPException, Security\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n\nsecurity = HTTPBearer()\n\nasync def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):\n    try:\n        payload = jwt.decode(\n            credentials.credentials,\n            SECRET_KEY,\n            algorithms=[\"HS256\"]\n        )\n        return payload\n    except jwt.ExpiredSignatureError:\n        raise HTTPException(status_code=401, detail=\"Token expired\")\n    except jwt.InvalidTokenError:\n        raise HTTPException(status_code=401, detail=\"Invalid token\")\n</code></pre>"},{"location":"architecture/security/#api-key-authentication","title":"API Key Authentication","text":"<p>API Key Format: <code>sei_live_&lt;random_32_chars&gt;</code></p> <p>Storage:</p> <pre><code>CREATE TABLE api_keys (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    organization_id UUID NOT NULL REFERENCES organizations(id),\n    key_hash VARCHAR(64) NOT NULL UNIQUE,\n    name VARCHAR(255) NOT NULL,\n    last_used_at TIMESTAMPTZ,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMPTZ\n);\n\nCREATE INDEX idx_api_keys_key_hash ON api_keys(key_hash);\nCREATE INDEX idx_api_keys_organization_id ON api_keys(organization_id);\n</code></pre> <p>API Key Validation:</p> <pre><code>import hashlib\n\ndef hash_api_key(api_key: str) -&gt; str:\n    return hashlib.sha256(api_key.encode()).hexdigest()\n\nasync def verify_api_key(api_key: str) -&gt; dict:\n    key_hash = hash_api_key(api_key)\n\n    result = await db.fetchrow(\n        \"SELECT * FROM api_keys WHERE key_hash = $1 AND \"\n        \"(expires_at IS NULL OR expires_at &gt; NOW())\",\n        key_hash\n    )\n\n    if not result:\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n\n    # Update last used timestamp\n    await db.execute(\n        \"UPDATE api_keys SET last_used_at = NOW() WHERE id = $1\",\n        result['id']\n    )\n\n    return result\n</code></pre>"},{"location":"architecture/security/#authorization","title":"Authorization","text":""},{"location":"architecture/security/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Roles:</p> <ul> <li><code>owner</code>: Full access to organization</li> <li><code>admin</code>: Manage teams and repositories</li> <li><code>member</code>: Read-only access to data</li> <li><code>viewer</code>: View dashboards only</li> </ul> <p>Permission Matrix:</p> Resource Owner Admin Member Viewer Organizations CRUD R R R Teams CRUD CRUD R R Repositories CRUD CRUD R R Developers CRUD CRUD R R Analytics R R R R API Keys CRUD R - - <p>Implementation:</p> <pre><code>from enum import Enum\nfrom fastapi import Depends, HTTPException\n\nclass Role(str, Enum):\n    OWNER = \"owner\"\n    ADMIN = \"admin\"\n    MEMBER = \"member\"\n    VIEWER = \"viewer\"\n\ndef require_role(required_role: Role):\n    async def role_checker(token_payload: dict = Depends(verify_token)):\n        user_role = Role(token_payload.get(\"role\"))\n\n        role_hierarchy = {\n            Role.OWNER: 4,\n            Role.ADMIN: 3,\n            Role.MEMBER: 2,\n            Role.VIEWER: 1\n        }\n\n        if role_hierarchy[user_role] &lt; role_hierarchy[required_role]:\n            raise HTTPException(\n                status_code=403,\n                detail=\"Insufficient permissions\"\n            )\n\n        return token_payload\n\n    return role_checker\n\n# Usage\n@app.post(\"/api/v1/organizations\")\nasync def create_organization(\n    org_data: OrganizationCreate,\n    user: dict = Depends(require_role(Role.OWNER))\n):\n    # Create organization\n    pass\n</code></pre>"},{"location":"architecture/security/#resource-level-permissions","title":"Resource-Level Permissions","text":"<p>Check Organization Access:</p> <pre><code>async def verify_organization_access(\n    organization_id: str,\n    user: dict = Depends(verify_token)\n) -&gt; bool:\n    result = await db.fetchrow(\n        \"\"\"\n        SELECT 1 FROM team_members tm\n        JOIN teams t ON tm.team_id = t.id\n        WHERE t.organization_id = $1 AND tm.developer_id = $2\n        \"\"\",\n        organization_id,\n        user['sub']\n    )\n\n    if not result:\n        raise HTTPException(\n            status_code=403,\n            detail=\"Access denied to organization\"\n        )\n\n    return True\n</code></pre>"},{"location":"architecture/security/#data-security","title":"Data Security","text":""},{"location":"architecture/security/#encryption-at-rest","title":"Encryption at Rest","text":"<p>Database Encryption:</p> <pre><code># Enable PostgreSQL encryption\nALTER SYSTEM SET ssl = on;\nALTER SYSTEM SET ssl_cert_file = '/path/to/server.crt';\nALTER SYSTEM SET ssl_key_file = '/path/to/server.key';\n</code></pre> <p>Sensitive Field Encryption:</p> <pre><code>from cryptography.fernet import Fernet\n\nclass EncryptedField:\n    def __init__(self, key: bytes):\n        self.cipher = Fernet(key)\n\n    def encrypt(self, value: str) -&gt; str:\n        return self.cipher.encrypt(value.encode()).decode()\n\n    def decrypt(self, encrypted_value: str) -&gt; str:\n        return self.cipher.decrypt(encrypted_value.encode()).decode()\n\n# Usage\ncipher = EncryptedField(ENCRYPTION_KEY)\nencrypted_token = cipher.encrypt(github_token)\n</code></pre>"},{"location":"architecture/security/#encryption-in-transit","title":"Encryption in Transit","text":"<p>TLS/SSL Configuration:</p> <pre><code># FastAPI with HTTPS\nimport uvicorn\n\nif __name__ == \"__main__\":\n    uvicorn.run(\n        \"main:app\",\n        host=\"0.0.0.0\",\n        port=8443,\n        ssl_keyfile=\"/path/to/key.pem\",\n        ssl_certfile=\"/path/to/cert.pem\"\n    )\n</code></pre> <p>Force HTTPS:</p> <pre><code>from fastapi import Request\nfrom fastapi.responses import RedirectResponse\n\n@app.middleware(\"http\")\nasync def https_redirect(request: Request, call_next):\n    if request.url.scheme != \"https\" and not request.url.hostname == \"localhost\":\n        url = request.url.replace(scheme=\"https\")\n        return RedirectResponse(url)\n    return await call_next(request)\n</code></pre>"},{"location":"architecture/security/#input-validation","title":"Input Validation","text":""},{"location":"architecture/security/#request-validation","title":"Request Validation","text":"<pre><code>from pydantic import BaseModel, Field, validator\n\nclass OrganizationCreate(BaseModel):\n    name: str = Field(..., min_length=1, max_length=255)\n    slug: str = Field(..., min_length=1, max_length=255, regex=r'^[a-z0-9-]+$')\n\n    @validator('slug')\n    def slug_must_be_lowercase(cls, v):\n        if not v.islower():\n            raise ValueError('slug must be lowercase')\n        return v\n\n@app.post(\"/api/v1/organizations\")\nasync def create_organization(org: OrganizationCreate):\n    # Pydantic automatically validates input\n    pass\n</code></pre>"},{"location":"architecture/security/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<pre><code># BAD - Vulnerable to SQL injection\nquery = f\"SELECT * FROM users WHERE email = '{user_email}'\"\n\n# GOOD - Use parameterized queries\nquery = \"SELECT * FROM users WHERE email = $1\"\nresult = await db.fetchrow(query, user_email)\n\n# GOOD - Use ORM\nfrom sqlalchemy import select\nquery = select(User).where(User.email == user_email)\n</code></pre>"},{"location":"architecture/security/#rate-limiting","title":"Rate Limiting","text":""},{"location":"architecture/security/#api-rate-limiting","title":"API Rate Limiting","text":"<pre><code>from slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\n\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.get(\"/api/v1/organizations\")\n@limiter.limit(\"100/hour\")\nasync def get_organizations(request: Request):\n    pass\n</code></pre>"},{"location":"architecture/security/#redis-based-rate-limiting","title":"Redis-Based Rate Limiting","text":"<pre><code>import redis\nfrom datetime import timedelta\n\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\nasync def check_rate_limit(key: str, max_requests: int, window: timedelta) -&gt; bool:\n    current = redis_client.get(key)\n\n    if current is None:\n        redis_client.setex(key, window, 1)\n        return True\n\n    if int(current) &gt;= max_requests:\n        return False\n\n    redis_client.incr(key)\n    return True\n\n# Usage\n@app.get(\"/api/v1/analytics\")\nasync def get_analytics(request: Request, user: dict = Depends(verify_token)):\n    key = f\"rate_limit:{user['sub']}:analytics\"\n\n    if not await check_rate_limit(key, max_requests=10, window=timedelta(minutes=1)):\n        raise HTTPException(status_code=429, detail=\"Rate limit exceeded\")\n\n    # Process request\n    pass\n</code></pre>"},{"location":"architecture/security/#security-headers","title":"Security Headers","text":""},{"location":"architecture/security/#http-security-headers","title":"HTTP Security Headers","text":"<pre><code>from fastapi.middleware.trustedhost import TrustedHostMiddleware\nfrom fastapi.middleware.cors import CORSMiddleware\n\n# CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://app.sei-platform.com\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\"],\n    allow_headers=[\"*\"],\n)\n\n# Trusted hosts\napp.add_middleware(\n    TrustedHostMiddleware,\n    allowed_hosts=[\"api.sei-platform.com\", \"*.sei-platform.com\"]\n)\n\n# Security headers\n@app.middleware(\"http\")\nasync def add_security_headers(request: Request, call_next):\n    response = await call_next(request)\n    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n    response.headers[\"X-Frame-Options\"] = \"DENY\"\n    response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n    response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n    response.headers[\"Content-Security-Policy\"] = \"default-src 'self'\"\n    return response\n</code></pre>"},{"location":"architecture/security/#secrets-management","title":"Secrets Management","text":""},{"location":"architecture/security/#environment-variables","title":"Environment Variables","text":"<pre><code>from pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    database_url: str\n    secret_key: str\n    github_client_id: str\n    github_client_secret: str\n\n    class Config:\n        env_file = \".env\"\n        env_file_encoding = 'utf-8'\n\nsettings = Settings()\n</code></pre>"},{"location":"architecture/security/#secrets-rotation","title":"Secrets Rotation","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\n\nasync def rotate_api_keys():\n    \"\"\"Rotate API keys older than 90 days\"\"\"\n    expired_keys = await db.fetch(\n        \"\"\"\n        SELECT id, organization_id FROM api_keys\n        WHERE created_at &lt; NOW() - INTERVAL '90 days'\n        \"\"\"\n    )\n\n    for key in expired_keys:\n        # Generate new key\n        new_key = generate_api_key()\n        new_key_hash = hash_api_key(new_key)\n\n        # Update database\n        await db.execute(\n            \"\"\"\n            UPDATE api_keys\n            SET key_hash = $1, created_at = NOW()\n            WHERE id = $2\n            \"\"\",\n            new_key_hash,\n            key['id']\n        )\n\n        # Notify organization\n        await notify_key_rotation(key['organization_id'], new_key)\n\n# Schedule rotation\nasyncio.create_task(rotate_api_keys())\n</code></pre>"},{"location":"architecture/security/#audit-logging","title":"Audit Logging","text":""},{"location":"architecture/security/#audit-log-schema","title":"Audit Log Schema","text":"<pre><code>CREATE TABLE audit_logs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    user_id UUID,\n    organization_id UUID,\n    action VARCHAR(50) NOT NULL,\n    resource_type VARCHAR(50) NOT NULL,\n    resource_id UUID,\n    ip_address INET,\n    user_agent TEXT,\n    request_id VARCHAR(255),\n    metadata JSONB\n);\n\nCREATE INDEX idx_audit_logs_timestamp ON audit_logs(timestamp DESC);\nCREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);\nCREATE INDEX idx_audit_logs_organization_id ON audit_logs(organization_id);\nCREATE INDEX idx_audit_logs_action ON audit_logs(action);\n</code></pre>"},{"location":"architecture/security/#audit-logging-implementation","title":"Audit Logging Implementation","text":"<pre><code>import logging\nfrom uuid import UUID\n\nclass AuditLogger:\n    def __init__(self, db):\n        self.db = db\n        self.logger = logging.getLogger(\"audit\")\n\n    async def log(\n        self,\n        user_id: UUID,\n        organization_id: UUID,\n        action: str,\n        resource_type: str,\n        resource_id: UUID = None,\n        ip_address: str = None,\n        user_agent: str = None,\n        request_id: str = None,\n        metadata: dict = None\n    ):\n        await self.db.execute(\n            \"\"\"\n            INSERT INTO audit_logs (\n                user_id, organization_id, action, resource_type,\n                resource_id, ip_address, user_agent, request_id, metadata\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n            \"\"\",\n            user_id, organization_id, action, resource_type,\n            resource_id, ip_address, user_agent, request_id, metadata\n        )\n\n        self.logger.info(\n            f\"Audit: {action} on {resource_type} by {user_id}\",\n            extra={\"request_id\": request_id}\n        )\n\n# Usage\naudit_logger = AuditLogger(db)\n\n@app.post(\"/api/v1/organizations\")\nasync def create_organization(\n    org: OrganizationCreate,\n    request: Request,\n    user: dict = Depends(verify_token)\n):\n    new_org = await create_org(org)\n\n    await audit_logger.log(\n        user_id=user['sub'],\n        organization_id=new_org.id,\n        action=\"create\",\n        resource_type=\"organization\",\n        resource_id=new_org.id,\n        ip_address=request.client.host,\n        user_agent=request.headers.get(\"user-agent\"),\n        request_id=request.state.request_id\n    )\n\n    return new_org\n</code></pre>"},{"location":"architecture/security/#vulnerability-scanning","title":"Vulnerability Scanning","text":""},{"location":"architecture/security/#dependency-scanning","title":"Dependency Scanning","text":"<pre><code># Install safety\npip install safety\n\n# Scan dependencies\nsafety check --json\n\n# In CI/CD\nsafety check --exit-code 1\n</code></pre>"},{"location":"architecture/security/#container-scanning","title":"Container Scanning","text":"<pre><code># Scan Docker images with Trivy\ntrivy image --severity HIGH,CRITICAL sei-platform-api:latest\n</code></pre>"},{"location":"architecture/security/#security-best-practices","title":"Security Best Practices","text":""},{"location":"architecture/security/#password-hashing","title":"Password Hashing","text":"<pre><code>from passlib.context import CryptContext\n\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n\ndef hash_password(password: str) -&gt; str:\n    return pwd_context.hash(password)\n\ndef verify_password(plain_password: str, hashed_password: str) -&gt; bool:\n    return pwd_context.verify(plain_password, hashed_password)\n</code></pre>"},{"location":"architecture/security/#secure-configuration","title":"Secure Configuration","text":"<pre><code># config.py\nimport os\nfrom typing import Optional\n\nclass SecurityConfig:\n    # JWT\n    JWT_SECRET_KEY: str = os.getenv(\"JWT_SECRET_KEY\")\n    JWT_ALGORITHM: str = \"HS256\"\n    JWT_EXPIRATION_HOURS: int = 24\n\n    # API Keys\n    API_KEY_LENGTH: int = 32\n    API_KEY_PREFIX: str = \"sei_live_\"\n\n    # Rate Limiting\n    RATE_LIMIT_PER_HOUR: int = 1000\n    RATE_LIMIT_PER_MINUTE: int = 100\n\n    # CORS\n    ALLOWED_ORIGINS: list = [\"https://app.sei-platform.com\"]\n\n    # TLS\n    TLS_CERT_FILE: Optional[str] = os.getenv(\"TLS_CERT_FILE\")\n    TLS_KEY_FILE: Optional[str] = os.getenv(\"TLS_KEY_FILE\")\n\n    # Database\n    DATABASE_SSL_MODE: str = \"require\"\n\n    @classmethod\n    def validate(cls):\n        if not cls.JWT_SECRET_KEY:\n            raise ValueError(\"JWT_SECRET_KEY must be set\")\n</code></pre>"},{"location":"architecture/security/#incident-response","title":"Incident Response","text":""},{"location":"architecture/security/#security-incident-workflow","title":"Security Incident Workflow","text":"<pre><code>graph TD\n    A[Security Event Detected] --&gt; B[Alert Security Team]\n    B --&gt; C{Severity?}\n    C --&gt;|Critical| D[Immediate Response]\n    C --&gt;|High| E[Escalate to Team Lead]\n    C --&gt;|Medium/Low| F[Create Ticket]\n\n    D --&gt; G[Isolate Affected Systems]\n    G --&gt; H[Investigate Root Cause]\n    H --&gt; I[Apply Fixes]\n    I --&gt; J[Post-Incident Review]\n\n    E --&gt; H\n    F --&gt; H</code></pre>"},{"location":"architecture/security/#incident-checklist","title":"Incident Checklist","text":"<ol> <li>Detection: Identify the security incident</li> <li>Containment: Isolate affected systems</li> <li>Eradication: Remove the threat</li> <li>Recovery: Restore systems to normal operation</li> <li>Post-Incident: Document and review</li> </ol>"},{"location":"architecture/security/#compliance","title":"Compliance","text":""},{"location":"architecture/security/#gdpr-compliance","title":"GDPR Compliance","text":"<ul> <li>User data deletion on request</li> <li>Data export functionality</li> <li>Consent management</li> <li>Data retention policies</li> </ul>"},{"location":"architecture/security/#soc-2-compliance","title":"SOC 2 Compliance","text":"<ul> <li>Access control</li> <li>Encryption</li> <li>Audit logging</li> <li>Incident response</li> <li>Change management</li> </ul>"},{"location":"architecture/security/#next-steps","title":"Next Steps","text":"<ul> <li>Data Models - Database security considerations</li> <li>API Design - API authentication and authorization</li> <li>Deployment - Production security setup</li> </ul>"},{"location":"architecture/system-design/","title":"System Design","text":""},{"location":"architecture/system-design/#service-architecture","title":"Service Architecture","text":""},{"location":"architecture/system-design/#api-service","title":"API Service","text":"<p>Technology: FastAPI, Python 3.11+</p> <p>Responsibilities:</p> <ul> <li>Expose REST API endpoints for all platform functionality</li> <li>Handle authentication and authorization</li> <li>Validate and sanitize user input</li> <li>Orchestrate data retrieval from databases</li> <li>Cache frequently accessed data in Redis</li> <li>Rate limiting and request throttling</li> </ul> <p>Port: 8080</p> <p>Key Components:</p> <pre><code>src/apis/\n\u251c\u2500\u2500 main.py              # FastAPI application entry point\n\u251c\u2500\u2500 config.py            # Configuration and settings\n\u251c\u2500\u2500 database.py          # Database connections\n\u251c\u2500\u2500 models/              # SQLAlchemy ORM models\n\u251c\u2500\u2500 routes/              # API route handlers\n\u2502   \u251c\u2500\u2500 organizations.py\n\u2502   \u251c\u2500\u2500 teams.py\n\u2502   \u251c\u2500\u2500 repositories.py\n\u2502   \u251c\u2500\u2500 developers.py\n\u2502   \u2514\u2500\u2500 analytics.py\n\u251c\u2500\u2500 schemas/             # Pydantic request/response schemas\n\u251c\u2500\u2500 services/            # Business logic layer\n\u2514\u2500\u2500 utils/               # Helper functions\n</code></pre> <p>API Endpoints:</p> <ul> <li><code>/health</code> - Health check endpoint</li> <li><code>/api/v1/organizations</code> - Organization CRUD</li> <li><code>/api/v1/teams</code> - Team management</li> <li><code>/api/v1/repositories</code> - Repository management</li> <li><code>/api/v1/developers</code> - Developer profiles</li> <li><code>/api/v1/analytics</code> - DORA metrics and analytics</li> </ul>"},{"location":"architecture/system-design/#git-collector-service","title":"Git Collector Service","text":"<p>Technology: FastAPI, Python 3.11+</p> <p>Responsibilities:</p> <ul> <li>Poll GitHub, GitLab, Bitbucket APIs for repository data</li> <li>Collect commits, pull requests, branches, tags</li> <li>Track code review activity</li> <li>Calculate code churn metrics</li> <li>Publish events to Kafka for processing</li> </ul> <p>Port: 8000</p> <p>Data Sources:</p> <ul> <li>GitHub: REST API v3, GraphQL API v4</li> <li>GitLab: REST API v4</li> <li>Bitbucket: REST API v2</li> </ul> <p>Collection Schedule:</p> <ul> <li>Commits: Every hour</li> <li>Pull Requests: Every 30 minutes</li> <li>Branches/Tags: Every 4 hours</li> <li>Contributors: Daily</li> </ul> <p>Event Topics:</p> <ul> <li><code>git.commits</code> - New commits</li> <li><code>git.pull_requests</code> - PR events</li> <li><code>git.code_reviews</code> - Code review activity</li> </ul>"},{"location":"architecture/system-design/#jira-collector-service","title":"Jira Collector Service","text":"<p>Technology: FastAPI, Python 3.11+</p> <p>Responsibilities:</p> <ul> <li>Integrate with Jira, Linear, Asana APIs</li> <li>Collect issues, sprints, story points</li> <li>Track issue lifecycle and transitions</li> <li>Calculate cycle time and lead time</li> <li>Publish events to Kafka</li> </ul> <p>Port: 8001</p> <p>Data Sources:</p> <ul> <li>Jira: REST API v3</li> <li>Linear: GraphQL API</li> <li>Asana: REST API v1</li> </ul> <p>Collection Schedule:</p> <ul> <li>Issues: Every 15 minutes</li> <li>Sprints: Hourly</li> <li>Boards: Every 4 hours</li> </ul> <p>Event Topics:</p> <ul> <li><code>jira.issues</code> - Issue events</li> <li><code>jira.sprints</code> - Sprint data</li> <li><code>jira.transitions</code> - Issue state changes</li> </ul>"},{"location":"architecture/system-design/#data-processor-service","title":"Data Processor Service","text":"<p>Technology: FastAPI, Python 3.11+, Kafka Consumer</p> <p>Responsibilities:</p> <ul> <li>Consume events from Kafka topics</li> <li>Transform raw data into normalized format</li> <li>Calculate DORA metrics</li> <li>Aggregate data for reporting</li> <li>Store processed data in databases</li> </ul> <p>Port: 8002</p> <p>Processing Pipeline:</p> <ol> <li>Event Consumption: Read from Kafka topics</li> <li>Validation: Validate event schema</li> <li>Transformation: Normalize data structure</li> <li>Enrichment: Add calculated fields</li> <li>Storage: Write to TimescaleDB/PostgreSQL</li> <li>Caching: Update Redis cache</li> </ol> <p>Metric Calculations:</p> <ul> <li>Deployment Frequency: Count deployments per day/week</li> <li>Lead Time for Changes: Time from commit to production</li> <li>Change Failure Rate: Percentage of deployments causing failures</li> <li>Time to Restore Service: Mean time to recovery (MTTR)</li> </ul>"},{"location":"architecture/system-design/#data-storage-design","title":"Data Storage Design","text":""},{"location":"architecture/system-design/#timescaledb-schema","title":"TimescaleDB Schema","text":"<p>Purpose: Time-series data for metrics and events</p> <p>Hypertables:</p> <pre><code>-- Commit events\nCREATE TABLE commits (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL,\n    commit_sha VARCHAR(40) NOT NULL,\n    author_id UUID NOT NULL,\n    lines_added INT,\n    lines_deleted INT,\n    files_changed INT,\n    message TEXT\n);\n\nSELECT create_hypertable('commits', 'time');\n\n-- Pull request events\nCREATE TABLE pull_requests (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL,\n    pr_number INT NOT NULL,\n    author_id UUID NOT NULL,\n    state VARCHAR(20),\n    merged_at TIMESTAMPTZ,\n    lines_added INT,\n    lines_deleted INT,\n    review_comments INT\n);\n\nSELECT create_hypertable('pull_requests', 'time');\n\n-- Deployment events\nCREATE TABLE deployments (\n    time TIMESTAMPTZ NOT NULL,\n    repository_id UUID NOT NULL,\n    environment VARCHAR(50),\n    status VARCHAR(20),\n    duration_seconds INT,\n    deployed_by UUID\n);\n\nSELECT create_hypertable('deployments', 'time');\n</code></pre> <p>Continuous Aggregates:</p> <pre><code>-- Daily commit stats\nCREATE MATERIALIZED VIEW daily_commit_stats\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 day', time) AS day,\n    repository_id,\n    COUNT(*) as commit_count,\n    SUM(lines_added) as total_lines_added,\n    SUM(lines_deleted) as total_lines_deleted\nFROM commits\nGROUP BY day, repository_id;\n\n-- Weekly DORA metrics\nCREATE MATERIALIZED VIEW weekly_dora_metrics\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 week', time) AS week,\n    repository_id,\n    COUNT(*) as deployment_count,\n    AVG(duration_seconds) as avg_duration,\n    COUNT(*) FILTER (WHERE status = 'failed') as failed_count\nFROM deployments\nGROUP BY week, repository_id;\n</code></pre>"},{"location":"architecture/system-design/#postgresql-schema","title":"PostgreSQL Schema","text":"<p>Purpose: Relational data for entities and relationships</p> <p>Core Tables:</p> <pre><code>-- Organizations\nCREATE TABLE organizations (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    slug VARCHAR(100) UNIQUE NOT NULL,\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Teams\nCREATE TABLE teams (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    organization_id UUID REFERENCES organizations(id),\n    name VARCHAR(255) NOT NULL,\n    slug VARCHAR(100) NOT NULL,\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    UNIQUE(organization_id, slug)\n);\n\n-- Repositories\nCREATE TABLE repositories (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    organization_id UUID REFERENCES organizations(id),\n    name VARCHAR(255) NOT NULL,\n    provider VARCHAR(50) NOT NULL,\n    provider_id VARCHAR(255) NOT NULL,\n    url TEXT,\n    default_branch VARCHAR(100),\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    UNIQUE(provider, provider_id)\n);\n\n-- Developers\nCREATE TABLE developers (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) UNIQUE NOT NULL,\n    name VARCHAR(255),\n    github_username VARCHAR(255),\n    gitlab_username VARCHAR(255),\n    created_at TIMESTAMPTZ DEFAULT NOW()\n);\n</code></pre>"},{"location":"architecture/system-design/#redis-cache-structure","title":"Redis Cache Structure","text":"<p>Key Patterns:</p> <pre><code>org:{org_id} -&gt; JSON organization\nteam:{team_id} -&gt; JSON team\nmetrics:dora:{repo_id}:{period} -&gt; JSON metrics\nratelimit:{ip}:{endpoint} -&gt; Request count\n</code></pre>"},{"location":"architecture/system-design/#event-schema-design","title":"Event Schema Design","text":""},{"location":"architecture/system-design/#kafka-topics","title":"Kafka Topics","text":"<pre><code>git.commits:\n  partitions: 10\n  replication: 3\n  retention.ms: 604800000\n\ngit.pull_requests:\n  partitions: 10\n  replication: 3\n  retention.ms: 604800000\n</code></pre>"},{"location":"architecture/system-design/#communication-patterns","title":"Communication Patterns","text":""},{"location":"architecture/system-design/#synchronous-communication","title":"Synchronous Communication","text":"<pre><code>Client \u2192 API Service \u2192 Database\n</code></pre>"},{"location":"architecture/system-design/#asynchronous-communication","title":"Asynchronous Communication","text":"<pre><code>Collector \u2192 Kafka \u2192 Data Processor \u2192 Database\n</code></pre>"},{"location":"architecture/system-design/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Database connection pooling</li> <li>Redis caching with TTL</li> <li>Kafka batch processing</li> <li>Query optimization with indexes</li> <li>Horizontal scaling capability</li> </ul>"},{"location":"contributing/code-style/","title":"Code Style Guide","text":"<p>Consistent code style improves readability and maintainability. This guide covers style requirements for all languages used in the SEI Platform.</p>"},{"location":"contributing/code-style/#python","title":"Python","text":""},{"location":"contributing/code-style/#style-guide","title":"Style Guide","text":"<p>Follow PEP 8 with these specific requirements:</p> <ul> <li>Line length: 100 characters maximum</li> <li>Indentation: 4 spaces (no tabs)</li> <li>String quotes: Double quotes for strings, single for keys</li> <li>Import sorting: isort with black profile</li> </ul>"},{"location":"contributing/code-style/#formatting-tools","title":"Formatting Tools","text":"<p>Use Black for automatic formatting:</p> <pre><code># Format all Python files\nblack src/ --line-length 100\n\n# Check formatting\nblack src/ --check --line-length 100\n</code></pre>"},{"location":"contributing/code-style/#linting","title":"Linting","text":"<p>Use flake8 and pylint:</p> <pre><code># Run flake8\nflake8 src/ --max-line-length=100\n\n# Run pylint\npylint src/ --max-line-length=100\n</code></pre>"},{"location":"contributing/code-style/#type-hints","title":"Type Hints","text":"<p>All new code must include type hints:</p> <pre><code>from typing import List, Optional, Dict, Any\nfrom datetime import datetime\n\ndef calculate_metrics(\n    team_id: str,\n    start_date: datetime,\n    end_date: datetime,\n    metric_types: Optional[List[str]] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Calculate metrics for a team.\n\n    Args:\n        team_id: Unique team identifier\n        start_date: Start of date range\n        end_date: End of date range\n        metric_types: Optional list of specific metrics to calculate\n\n    Returns:\n        Dictionary containing calculated metrics\n\n    Raises:\n        ValueError: If date range is invalid\n    \"\"\"\n    if start_date &gt; end_date:\n        raise ValueError(\"start_date must be before end_date\")\n\n    results: Dict[str, Any] = {}\n    # Implementation\n    return results\n</code></pre>"},{"location":"contributing/code-style/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> <pre><code>class DataCollector:\n    \"\"\"\n    Collects data from external sources.\n\n    This class handles authentication, rate limiting, and error\n    handling for data collection operations.\n\n    Attributes:\n        api_key: Authentication key for the data source\n        rate_limit: Maximum requests per minute\n        retry_count: Number of retries for failed requests\n\n    Example:\n        &gt;&gt;&gt; collector = DataCollector(api_key=\"key123\")\n        &gt;&gt;&gt; data = collector.collect(source=\"github\")\n    \"\"\"\n\n    def __init__(self, api_key: str, rate_limit: int = 100):\n        \"\"\"\n        Initialize the data collector.\n\n        Args:\n            api_key: API authentication key\n            rate_limit: Maximum requests per minute (default: 100)\n        \"\"\"\n        self.api_key = api_key\n        self.rate_limit = rate_limit\n</code></pre>"},{"location":"contributing/code-style/#imports","title":"Imports","text":"<p>Organize imports in three groups:</p> <pre><code># Standard library imports\nimport os\nimport sys\nfrom datetime import datetime\nfrom typing import List, Optional\n\n# Third-party imports\nimport pandas as pd\nimport requests\nfrom flask import Flask, jsonify\n\n# Local application imports\nfrom app.models import Team, Metric\nfrom app.services import DataCollector\nfrom app.utils import validate_date_range\n</code></pre> <p>Sort with isort:</p> <pre><code>isort src/ --profile black\n</code></pre>"},{"location":"contributing/code-style/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Classes: PascalCase</li> <li>Functions: snake_case</li> <li>Constants: UPPER_SNAKE_CASE</li> <li>Private methods: _leading_underscore</li> <li>Protected attributes: _single_underscore</li> </ul> <pre><code># Constants\nMAX_RETRY_COUNT = 3\nDEFAULT_TIMEOUT = 30\n\n# Classes\nclass MetricCalculator:\n    \"\"\"Calculator for team metrics.\"\"\"\n\n    def __init__(self):\n        self._cache = {}  # Private attribute\n\n    def calculate_velocity(self, team_id: str) -&gt; float:\n        \"\"\"Public method.\"\"\"\n        return self._fetch_from_cache(team_id)\n\n    def _fetch_from_cache(self, key: str) -&gt; float:\n        \"\"\"Private helper method.\"\"\"\n        return self._cache.get(key, 0.0)\n</code></pre>"},{"location":"contributing/code-style/#error-handling","title":"Error Handling","text":"<p>Use specific exceptions and proper error handling:</p> <pre><code>class TeamNotFoundError(Exception):\n    \"\"\"Raised when team ID is not found.\"\"\"\n    pass\n\ndef get_team_metrics(team_id: str) -&gt; Dict[str, Any]:\n    \"\"\"Get metrics for a team.\"\"\"\n    try:\n        team = Team.query.get(team_id)\n        if not team:\n            raise TeamNotFoundError(f\"Team {team_id} not found\")\n\n        return team.calculate_metrics()\n\n    except DatabaseError as e:\n        logger.error(f\"Database error: {e}\")\n        raise\n    except Exception as e:\n        logger.exception(\"Unexpected error calculating metrics\")\n        raise\n</code></pre>"},{"location":"contributing/code-style/#typescriptjavascript","title":"TypeScript/JavaScript","text":""},{"location":"contributing/code-style/#style-guide_1","title":"Style Guide","text":"<p>Follow the Airbnb JavaScript Style Guide with modifications:</p> <ul> <li>Use TypeScript for all new code</li> <li>Prefer functional components in React</li> <li>Use async/await over promises</li> <li>Enable strict mode in TypeScript</li> </ul>"},{"location":"contributing/code-style/#formatting","title":"Formatting","text":"<p>Use Prettier for formatting:</p> <pre><code># Format all TypeScript files\nprettier --write \"src/**/*.{ts,tsx}\"\n\n# Check formatting\nprettier --check \"src/**/*.{ts,tsx}\"\n</code></pre>"},{"location":"contributing/code-style/#linting_1","title":"Linting","text":"<p>Use ESLint with TypeScript plugin:</p> <pre><code># Run ESLint\neslint \"src/**/*.{ts,tsx}\"\n\n# Fix auto-fixable issues\neslint \"src/**/*.{ts,tsx}\" --fix\n</code></pre>"},{"location":"contributing/code-style/#typescript-configuration","title":"TypeScript Configuration","text":"<p>Enable strict type checking in tsconfig.json:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noImplicitAny\": true,\n    \"strictNullChecks\": true,\n    \"strictFunctionTypes\": true,\n    \"strictPropertyInitialization\": true,\n    \"noImplicitThis\": true,\n    \"alwaysStrict\": true\n  }\n}\n</code></pre>"},{"location":"contributing/code-style/#type-definitions","title":"Type Definitions","text":"<p>Define interfaces for all data structures:</p> <pre><code>interface Team {\n  id: string;\n  name: string;\n  members: TeamMember[];\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ninterface TeamMember {\n  userId: string;\n  role: 'developer' | 'lead' | 'manager';\n  joinedAt: Date;\n}\n\ninterface MetricData {\n  teamId: string;\n  metricType: string;\n  value: number;\n  timestamp: Date;\n  metadata?: Record&lt;string, unknown&gt;;\n}\n</code></pre>"},{"location":"contributing/code-style/#react-components","title":"React Components","text":"<p>Use functional components with TypeScript:</p> <pre><code>import React, { useState, useEffect } from 'react';\n\ninterface MetricCardProps {\n  teamId: string;\n  metricType: string;\n  refreshInterval?: number;\n}\n\nexport const MetricCard: React.FC&lt;MetricCardProps&gt; = ({\n  teamId,\n  metricType,\n  refreshInterval = 60000,\n}) =&gt; {\n  const [data, setData] = useState&lt;MetricData | null&gt;(null);\n  const [loading, setLoading] = useState&lt;boolean&gt;(true);\n  const [error, setError] = useState&lt;Error | null&gt;(null);\n\n  useEffect(() =&gt; {\n    const fetchMetric = async () =&gt; {\n      try {\n        setLoading(true);\n        const response = await fetch(`/api/v1/teams/${teamId}/metrics/${metricType}`);\n        const result = await response.json();\n        setData(result);\n        setError(null);\n      } catch (err) {\n        setError(err as Error);\n      } finally {\n        setLoading(false);\n      }\n    };\n\n    fetchMetric();\n    const interval = setInterval(fetchMetric, refreshInterval);\n\n    return () =&gt; clearInterval(interval);\n  }, [teamId, metricType, refreshInterval]);\n\n  if (loading) return &lt;LoadingSpinner /&gt;;\n  if (error) return &lt;ErrorDisplay error={error} /&gt;;\n  if (!data) return null;\n\n  return (\n    &lt;div className=\"metric-card\"&gt;\n      &lt;h3&gt;{metricType}&lt;/h3&gt;\n      &lt;p className=\"metric-value\"&gt;{data.value}&lt;/p&gt;\n    &lt;/div&gt;\n  );\n};\n</code></pre>"},{"location":"contributing/code-style/#naming-conventions_1","title":"Naming Conventions","text":"<ul> <li>Components: PascalCase</li> <li>Hooks: camelCase with use prefix</li> <li>Constants: UPPER_SNAKE_CASE</li> <li>Files: kebab-case for files, PascalCase for components</li> </ul> <pre><code>// Constants\nconst MAX_RETRIES = 3;\nconst API_BASE_URL = process.env.REACT_APP_API_URL;\n\n// Custom hooks\nfunction useTeamMetrics(teamId: string) {\n  // Implementation\n}\n\n// Components\nfunction MetricsDashboard() {\n  // Implementation\n}\n</code></pre>"},{"location":"contributing/code-style/#asyncawait","title":"Async/Await","text":"<p>Prefer async/await over promises:</p> <pre><code>// Good\nasync function fetchTeamData(teamId: string): Promise&lt;Team&gt; {\n  try {\n    const response = await fetch(`/api/v1/teams/${teamId}`);\n    if (!response.ok) {\n      throw new Error(`HTTP ${response.status}`);\n    }\n    return await response.json();\n  } catch (error) {\n    logger.error('Failed to fetch team data', error);\n    throw error;\n  }\n}\n\n// Avoid\nfunction fetchTeamData(teamId: string): Promise&lt;Team&gt; {\n  return fetch(`/api/v1/teams/${teamId}`)\n    .then(response =&gt; {\n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}`);\n      }\n      return response.json();\n    })\n    .catch(error =&gt; {\n      logger.error('Failed to fetch team data', error);\n      throw error;\n    });\n}\n</code></pre>"},{"location":"contributing/code-style/#sql","title":"SQL","text":""},{"location":"contributing/code-style/#style-guide_2","title":"Style Guide","text":"<p>Follow SQL Style Guide best practices:</p> <ul> <li>Keywords in UPPERCASE</li> <li>Table and column names in snake_case</li> <li>Indent nested queries</li> <li>Use explicit JOINs</li> </ul>"},{"location":"contributing/code-style/#examples","title":"Examples","text":"<pre><code>-- Good\nSELECT\n    t.id,\n    t.name,\n    COUNT(m.id) AS member_count,\n    AVG(mt.value) AS avg_velocity\nFROM teams t\n    LEFT JOIN team_members m ON t.id = m.team_id\n    LEFT JOIN metrics mt ON t.id = mt.team_id\nWHERE\n    t.is_active = TRUE\n    AND mt.metric_type = 'velocity'\n    AND mt.created_at &gt;= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY\n    t.id,\n    t.name\nHAVING\n    COUNT(m.id) &gt; 0\nORDER BY\n    avg_velocity DESC\nLIMIT 10;\n\n-- Create indexes for performance\nCREATE INDEX idx_metrics_team_type_date\n    ON metrics (team_id, metric_type, created_at DESC);\n\n-- Use meaningful constraint names\nALTER TABLE team_members\n    ADD CONSTRAINT fk_team_members_team_id\n    FOREIGN KEY (team_id)\n    REFERENCES teams (id)\n    ON DELETE CASCADE;\n</code></pre>"},{"location":"contributing/code-style/#yaml","title":"YAML","text":""},{"location":"contributing/code-style/#style-guide_3","title":"Style Guide","text":"<p>For Kubernetes manifests and configuration files:</p> <ul> <li>2-space indentation</li> <li>No tabs</li> <li>Explicit string quotes for special characters</li> <li>Comments for complex configurations</li> </ul> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-service\n  namespace: sei-platform\n  labels:\n    app: api-service\n    version: v1.0.0\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api-service\n  template:\n    metadata:\n      labels:\n        app: api-service\n        version: v1.0.0\n    spec:\n      containers:\n      - name: api-service\n        image: sei-platform/api-service:latest\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: database-credentials\n              key: url\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"1000m\"\n</code></pre>"},{"location":"contributing/code-style/#markdown","title":"Markdown","text":""},{"location":"contributing/code-style/#style-guide_4","title":"Style Guide","text":"<p>For documentation files:</p> <ul> <li>Use ATX-style headers</li> <li>One sentence per line for easy diffs</li> <li>Code blocks with language specifiers</li> <li>Relative links for internal references</li> </ul> <pre><code># Main Title\n\n## Section Title\n\nThis is a paragraph.\nIt uses one sentence per line.\n\n### Subsection\n\nCode example:\n\n\u200b```python\ndef example():\n    return \"Hello, World!\"\n\u200b```\n\nLinks:\n\n- [Internal link](../guide/setup.md)\n- [External link](https://example.com)\n\nLists:\n\n- Item one\n- Item two\n    - Nested item\n    - Another nested item\n</code></pre>"},{"location":"contributing/code-style/#configuration-files","title":"Configuration Files","text":""},{"location":"contributing/code-style/#editorconfig","title":".editorconfig","text":"<p>Use EditorConfig for consistent formatting:</p> <pre><code>root = true\n\n[*]\ncharset = utf-8\nend_of_line = lf\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\n[*.{py,java,go}]\nindent_style = space\nindent_size = 4\n\n[*.{js,ts,tsx,json,yml,yaml}]\nindent_style = space\nindent_size = 2\n\n[Makefile]\nindent_style = tab\n</code></pre>"},{"location":"contributing/code-style/#code-review-checklist","title":"Code Review Checklist","text":"<p>Before submitting code, verify:</p> <ul> <li> Code follows language-specific style guide</li> <li> Automated formatters have been run</li> <li> Linters pass with no errors</li> <li> Type hints/types are present</li> <li> Documentation is complete</li> <li> Tests are included</li> <li> No hardcoded values or secrets</li> <li> Error handling is appropriate</li> <li> Performance is acceptable</li> <li> Security best practices followed</li> </ul>"},{"location":"contributing/code-style/#tools-configuration","title":"Tools Configuration","text":""},{"location":"contributing/code-style/#setup-pre-commit-hooks","title":"Setup Pre-commit Hooks","text":"<p>Install pre-commit hooks to automatically check style:</p> <pre><code># Install pre-commit\npip install pre-commit\n\n# Install hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/code-style/#pre-commit-configyaml","title":".pre-commit-config.yaml","text":"<pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 23.1.0\n    hooks:\n      - id: black\n        language_version: python3.10\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n        args: [\"--profile\", \"black\"]\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.0.0\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=100\"]\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.0.0\n    hooks:\n      - id: prettier\n        types_or: [javascript, typescript, tsx, json, yaml]\n</code></pre>"},{"location":"contributing/code-style/#additional-resources","title":"Additional Resources","text":"<ul> <li>PEP 8 Style Guide</li> <li>Airbnb JavaScript Style Guide</li> <li>TypeScript Handbook</li> <li>Contributing Guidelines</li> <li>Pull Request Guide</li> </ul>"},{"location":"contributing/guidelines/","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to the Open Source SEI Platform. This document provides guidelines and best practices for contributing to the project.</p>"},{"location":"contributing/guidelines/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to maintain a respectful, inclusive, and collaborative environment. We expect all contributors to:</p> <ul> <li>Be respectful and considerate in all interactions</li> <li>Welcome newcomers and help them get started</li> <li>Focus on constructive feedback</li> <li>Accept differing viewpoints gracefully</li> <li>Prioritize the community's best interests</li> </ul> <p>Report unacceptable behavior to conduct@sei-platform.org.</p>"},{"location":"contributing/guidelines/#getting-started","title":"Getting Started","text":""},{"location":"contributing/guidelines/#prerequisites","title":"Prerequisites","text":"<p>Before contributing, ensure you have:</p> <ul> <li>Git installed and configured</li> <li>Docker and Docker Compose</li> <li>Python 3.10 or higher</li> <li>Node.js 18 or higher</li> <li>kubectl (for Kubernetes development)</li> <li>A GitHub account</li> </ul>"},{"location":"contributing/guidelines/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<ol> <li> <p>Fork the repository on GitHub</p> </li> <li> <p>Clone your fork:</p> <pre><code>git clone https://github.com/YOUR_USERNAME/open-source-sei-platform.git\ncd open-source-sei-platform\n</code></pre> </li> <li> <p>Add upstream remote:</p> <pre><code>git remote add upstream https://github.com/rcdelacruz/open-source-sei-platform.git\n</code></pre> </li> <li> <p>Set up the development environment:</p> <pre><code>make quickstart\n</code></pre> </li> <li> <p>Verify the setup:</p> <pre><code>make test\n</code></pre> </li> </ol>"},{"location":"contributing/guidelines/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Create a feature branch:</p> <pre><code>git checkout -b feature/your-feature-name\n</code></pre> </li> <li> <p>Make your changes following the code style guide</p> </li> <li> <p>Write or update tests for your changes</p> </li> <li> <p>Run tests locally:</p> <pre><code>make test\nmake lint\n</code></pre> </li> <li> <p>Commit your changes with a descriptive message:</p> <pre><code>git commit -m \"Add feature: description of your changes\"\n</code></pre> </li> <li> <p>Keep your branch updated:</p> <pre><code>git fetch upstream\ngit rebase upstream/master\n</code></pre> </li> <li> <p>Push to your fork:</p> <pre><code>git push origin feature/your-feature-name\n</code></pre> </li> <li> <p>Open a Pull Request on GitHub</p> </li> </ol>"},{"location":"contributing/guidelines/#contribution-types","title":"Contribution Types","text":""},{"location":"contributing/guidelines/#bug-reports","title":"Bug Reports","text":"<p>When reporting bugs, include:</p> <ul> <li>Clear, descriptive title</li> <li>Steps to reproduce the issue</li> <li>Expected vs actual behavior</li> <li>Environment details (OS, versions, etc.)</li> <li>Screenshots if applicable</li> <li>Relevant logs or error messages</li> </ul> <p>Use the bug report template when creating issues.</p>"},{"location":"contributing/guidelines/#feature-requests","title":"Feature Requests","text":"<p>For new features, provide:</p> <ul> <li>Problem description and use case</li> <li>Proposed solution</li> <li>Alternative solutions considered</li> <li>Impact on existing features</li> <li>Implementation complexity estimate</li> </ul> <p>Use the feature request template when creating issues.</p>"},{"location":"contributing/guidelines/#documentation","title":"Documentation","text":"<p>Documentation improvements are always welcome:</p> <ul> <li>Fix typos and grammatical errors</li> <li>Clarify confusing sections</li> <li>Add missing documentation</li> <li>Update outdated content</li> <li>Create tutorials and examples</li> </ul>"},{"location":"contributing/guidelines/#code-contributions","title":"Code Contributions","text":"<p>Code contributions should:</p> <ul> <li>Address a specific issue or feature request</li> <li>Include comprehensive tests</li> <li>Follow the code style guidelines</li> <li>Update relevant documentation</li> <li>Pass all CI/CD checks</li> </ul>"},{"location":"contributing/guidelines/#code-review-process","title":"Code Review Process","text":"<p>All contributions go through code review:</p> <ol> <li> <p>Automated checks run on PR creation:</p> <ul> <li>Linting and formatting</li> <li>Unit tests</li> <li>Integration tests</li> <li>Security scans</li> <li>Code coverage analysis</li> </ul> </li> <li> <p>Maintainers review the code for:</p> <ul> <li>Code quality and maintainability</li> <li>Test coverage</li> <li>Documentation completeness</li> <li>Breaking changes</li> <li>Performance implications</li> </ul> </li> <li> <p>Address review feedback:</p> <ul> <li>Make requested changes</li> <li>Respond to comments</li> <li>Update tests if needed</li> </ul> </li> <li> <p>Once approved, maintainers merge the PR</p> </li> </ol>"},{"location":"contributing/guidelines/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/guidelines/#unit-tests","title":"Unit Tests","text":"<p>Write unit tests for all new code:</p> <pre><code>import pytest\nfrom app.services import DataCollector\n\ndef test_data_collector_initialization():\n    collector = DataCollector(api_key=\"test_key\")\n    assert collector.is_authenticated()\n\ndef test_data_collection_success():\n    collector = DataCollector(api_key=\"test_key\")\n    result = collector.collect_data()\n    assert result.status == \"success\"\n    assert len(result.data) &gt; 0\n</code></pre>"},{"location":"contributing/guidelines/#integration-tests","title":"Integration Tests","text":"<p>Test interactions between components:</p> <pre><code>@pytest.mark.integration\ndef test_api_to_database_flow():\n    # Create test data via API\n    response = client.post('/api/v1/metrics', json=test_data)\n    assert response.status_code == 201\n\n    # Verify data in database\n    record = db.query(Metric).filter_by(id=response.json['id']).first()\n    assert record is not None\n    assert record.value == test_data['value']\n</code></pre>"},{"location":"contributing/guidelines/#end-to-end-tests","title":"End-to-End Tests","text":"<p>Test complete user workflows:</p> <pre><code>describe('Dashboard Workflow', () =&gt; {\n  it('should display team metrics', async () =&gt; {\n    await page.goto('http://localhost:3000/dashboard');\n    await page.waitForSelector('.metrics-card');\n\n    const metrics = await page.$$eval('.metric-value',\n      els =&gt; els.map(el =&gt; el.textContent)\n    );\n\n    expect(metrics.length).toBeGreaterThan(0);\n  });\n});\n</code></pre>"},{"location":"contributing/guidelines/#test-coverage","title":"Test Coverage","text":"<p>Maintain high test coverage:</p> <ul> <li>Aim for 80% overall coverage</li> <li>90% for critical paths</li> <li>100% for security-sensitive code</li> </ul> <p>Run coverage reports:</p> <pre><code>make test-coverage\n</code></pre>"},{"location":"contributing/guidelines/#documentation-requirements","title":"Documentation Requirements","text":"<p>All code changes must include documentation:</p>"},{"location":"contributing/guidelines/#code-documentation","title":"Code Documentation","text":"<p>Add docstrings to all functions and classes:</p> <pre><code>def calculate_dora_metrics(team_id: str, start_date: datetime, end_date: datetime) -&gt; DORAMetrics:\n    \"\"\"\n    Calculate DORA metrics for a team within a date range.\n\n    Args:\n        team_id: Unique identifier for the team\n        start_date: Start of the date range\n        end_date: End of the date range\n\n    Returns:\n        DORAMetrics object containing calculated metrics\n\n    Raises:\n        ValueError: If date range is invalid\n        TeamNotFoundError: If team_id doesn't exist\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"contributing/guidelines/#api-documentation","title":"API Documentation","text":"<p>Document all API endpoints:</p> <pre><code>@app.route('/api/v1/teams/&lt;team_id&gt;/metrics', methods=['GET'])\ndef get_team_metrics(team_id):\n    \"\"\"\n    Get metrics for a specific team.\n\n    Path Parameters:\n        team_id (str): Team identifier\n\n    Query Parameters:\n        start_date (str): Start date in ISO 8601 format\n        end_date (str): End date in ISO 8601 format\n        metric_type (str): Type of metrics to retrieve\n\n    Returns:\n        200: Metrics data\n        404: Team not found\n        400: Invalid parameters\n    \"\"\"\n</code></pre>"},{"location":"contributing/guidelines/#user-documentation","title":"User Documentation","text":"<p>Update user-facing documentation:</p> <ul> <li>Add new features to user guides</li> <li>Update screenshots if UI changed</li> <li>Add usage examples</li> <li>Update troubleshooting guides</li> </ul>"},{"location":"contributing/guidelines/#commit-message-guidelines","title":"Commit Message Guidelines","text":"<p>Follow conventional commits format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types:</p> <ul> <li>feat: New feature</li> <li>fix: Bug fix</li> <li>docs: Documentation changes</li> <li>style: Code formatting (no logic changes)</li> <li>refactor: Code refactoring</li> <li>perf: Performance improvements</li> <li>test: Adding or updating tests</li> <li>chore: Build process or auxiliary tool changes</li> </ul> <p>Examples:</p> <pre><code>feat(api): add DORA metrics calculation endpoint\n\nImplement new endpoint for calculating DORA metrics including\ndeployment frequency, lead time, change failure rate, and MTTR.\n\nCloses #123\n</code></pre> <pre><code>fix(database): resolve connection pool exhaustion\n\nFixed issue where database connections were not being properly\nreleased, causing pool exhaustion under high load.\n\nFixes #456\n</code></pre>"},{"location":"contributing/guidelines/#branch-naming","title":"Branch Naming","text":"<p>Use descriptive branch names:</p> <ul> <li>feature/add-github-integration</li> <li>fix/database-connection-leak</li> <li>docs/update-installation-guide</li> <li>refactor/simplify-auth-flow</li> </ul>"},{"location":"contributing/guidelines/#pull-request-guidelines","title":"Pull Request Guidelines","text":""},{"location":"contributing/guidelines/#pr-title","title":"PR Title","text":"<p>Use clear, descriptive titles:</p> <ul> <li>Good: \"Add support for GitLab data collection\"</li> <li>Good: \"Fix memory leak in data processor\"</li> <li>Bad: \"Update code\"</li> <li>Bad: \"Bug fix\"</li> </ul>"},{"location":"contributing/guidelines/#pr-description","title":"PR Description","text":"<p>Include in the description:</p> <ul> <li>Summary of changes</li> <li>Related issue numbers</li> <li>Testing performed</li> <li>Screenshots (for UI changes)</li> <li>Breaking changes</li> <li>Migration notes</li> </ul> <p>Use the PR template provided.</p>"},{"location":"contributing/guidelines/#pr-size","title":"PR Size","text":"<p>Keep PRs focused and manageable:</p> <ul> <li>Aim for &lt;500 lines of code</li> <li>One feature or fix per PR</li> <li>Split large changes into multiple PRs</li> <li>Create draft PRs for work in progress</li> </ul>"},{"location":"contributing/guidelines/#security","title":"Security","text":""},{"location":"contributing/guidelines/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>Do not open public issues for security vulnerabilities.</p> <p>Email security@sei-platform.org with:</p> <ul> <li>Description of the vulnerability</li> <li>Steps to reproduce</li> <li>Potential impact</li> <li>Suggested fix (if available)</li> </ul>"},{"location":"contributing/guidelines/#security-guidelines","title":"Security Guidelines","text":"<ul> <li>Never commit secrets or credentials</li> <li>Use environment variables for configuration</li> <li>Validate all user inputs</li> <li>Implement proper authentication and authorization</li> <li>Follow OWASP security best practices</li> <li>Keep dependencies updated</li> </ul>"},{"location":"contributing/guidelines/#performance-considerations","title":"Performance Considerations","text":"<p>When contributing, consider performance:</p> <ul> <li>Profile before optimizing</li> <li>Use appropriate data structures</li> <li>Implement caching where beneficial</li> <li>Minimize database queries</li> <li>Use async/await for I/O operations</li> <li>Add indexes for frequently queried fields</li> </ul>"},{"location":"contributing/guidelines/#accessibility","title":"Accessibility","text":"<p>Ensure contributions are accessible:</p> <ul> <li>Use semantic HTML</li> <li>Provide alt text for images</li> <li>Ensure keyboard navigation</li> <li>Meet WCAG 2.1 Level AA standards</li> <li>Test with screen readers</li> <li>Maintain sufficient color contrast</li> </ul>"},{"location":"contributing/guidelines/#internationalization","title":"Internationalization","text":"<p>Prepare for future internationalization:</p> <ul> <li>Avoid hardcoded strings</li> <li>Use i18n libraries</li> <li>Format dates, numbers, and currencies properly</li> <li>Consider RTL language support</li> <li>Use Unicode for text handling</li> </ul>"},{"location":"contributing/guidelines/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"contributing/guidelines/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in:</p> <ul> <li>CONTRIBUTORS.md file</li> <li>Release notes</li> <li>Project README</li> <li>Annual contributor highlights</li> </ul> <p>Significant contributors may be invited to join the maintainers team.</p>"},{"location":"contributing/guidelines/#getting-help","title":"Getting Help","text":"<p>Need help with your contribution?</p> <ul> <li>Ask questions in GitHub Discussions</li> <li>Join our Discord channel</li> <li>Email contributors@sei-platform.org</li> <li>Check the FAQ in documentation</li> </ul>"},{"location":"contributing/guidelines/#resources","title":"Resources","text":"<ul> <li>Code Style Guide</li> <li>Pull Request Guide</li> <li>Project Roadmap</li> <li>Architecture Documentation</li> </ul> <p>Thank you for contributing to the Open Source SEI Platform!</p>"},{"location":"contributing/pull-requests/","title":"Pull Request Guide","text":"<p>This guide covers the pull request process for the SEI Platform project, from creation to merge.</p>"},{"location":"contributing/pull-requests/#before-creating-a-pull-request","title":"Before Creating a Pull Request","text":""},{"location":"contributing/pull-requests/#check-prerequisites","title":"Check Prerequisites","text":"<p>Before opening a PR, ensure you have:</p> <ul> <li>Created an issue describing the change (unless it's a trivial fix)</li> <li>Discussed the approach with maintainers (for significant changes)</li> <li>Read the contributing guidelines</li> <li>Set up your development environment</li> <li>Created a feature branch from the latest master</li> </ul>"},{"location":"contributing/pull-requests/#run-local-checks","title":"Run Local Checks","text":"<p>Run all checks locally before pushing:</p> <pre><code># Run linters\nmake lint\n\n# Run formatters\nmake format\n\n# Run all tests\nmake test\n\n# Check test coverage\nmake test-coverage\n\n# Run security scans\nmake security\n</code></pre> <p>Fix any issues before proceeding.</p>"},{"location":"contributing/pull-requests/#creating-a-pull-request","title":"Creating a Pull Request","text":""},{"location":"contributing/pull-requests/#pr-title","title":"PR Title","text":"<p>Follow conventional commits format for PR titles:</p> <p>Format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n</code></pre> <p>Types:</p> <ul> <li>feat: New feature</li> <li>fix: Bug fix</li> <li>docs: Documentation only</li> <li>style: Code style changes (formatting, etc.)</li> <li>refactor: Code refactoring</li> <li>perf: Performance improvements</li> <li>test: Adding or updating tests</li> <li>chore: Build process or tooling changes</li> </ul> <p>Examples:</p> <pre><code>feat(api): add DORA metrics calculation endpoint\nfix(database): resolve connection pool exhaustion\ndocs(deployment): update Kubernetes deployment guide\nrefactor(auth): simplify JWT token validation\n</code></pre>"},{"location":"contributing/pull-requests/#pr-description","title":"PR Description","text":"<p>Use the provided PR template and include:</p> <p>Summary: Brief description of what and why</p> <pre><code>## Summary\n\nThis PR adds support for calculating DORA metrics (deployment frequency,\nlead time for changes, change failure rate, and mean time to recovery)\nfor teams. This addresses the core requirement for engineering metrics\ntracking.\n</code></pre> <p>Related Issues: Link related issues</p> <pre><code>## Related Issues\n\nCloses #123\nRelates to #456\n</code></pre> <p>Changes Made: List key changes</p> <pre><code>## Changes Made\n\n- Implemented DORA metrics calculation service\n- Added new API endpoints for metrics retrieval\n- Created database migrations for metrics storage\n- Added comprehensive unit and integration tests\n- Updated API documentation\n</code></pre> <p>Testing: Describe testing performed</p> <pre><code>## Testing\n\n- Added unit tests with 95% coverage\n- Integration tests verify end-to-end flow\n- Manually tested against production-like dataset\n- Load tested with 10,000 requests/second\n</code></pre> <p>Screenshots: For UI changes, include before/after screenshots</p> <pre><code>## Screenshots\n\n### Before\n![Before](path/to/before.png)\n\n### After\n![After](path/to/after.png)\n</code></pre> <p>Breaking Changes: Call out any breaking changes</p> <pre><code>## Breaking Changes\n\n- Changed API endpoint from `/metrics` to `/api/v1/metrics`\n- Renamed `team_id` parameter to `teamId` for consistency\n\n### Migration Guide\n\nUpdate API calls:\n\u200b```diff\n- GET /metrics?team_id=123\n+ GET /api/v1/metrics?teamId=123\n\u200b```\n</code></pre> <p>Checklist: Complete the checklist</p> <pre><code>## Checklist\n\n- [x] Tests added/updated\n- [x] Documentation updated\n- [x] Code follows style guide\n- [x] All tests passing\n- [x] No breaking changes (or documented)\n</code></pre>"},{"location":"contributing/pull-requests/#pr-size-and-scope","title":"PR Size and Scope","text":""},{"location":"contributing/pull-requests/#keep-prs-small","title":"Keep PRs Small","text":"<p>Aim for PRs with:</p> <ul> <li>Less than 500 lines of code changed</li> <li>Single, focused purpose</li> <li>Clear scope and boundaries</li> </ul>"},{"location":"contributing/pull-requests/#split-large-changes","title":"Split Large Changes","text":"<p>For large features, create multiple PRs:</p> <ol> <li>PR 1: Database schema and models</li> <li>PR 2: Core business logic</li> <li>PR 3: API endpoints</li> <li>PR 4: Frontend components</li> <li>PR 5: Documentation and examples</li> </ol> <p>Each PR should be independently reviewable and mergeable.</p>"},{"location":"contributing/pull-requests/#draft-prs","title":"Draft PRs","text":"<p>For work in progress:</p> <pre><code>## [WIP] Feature Name\n\nThis is a work in progress to gather early feedback on the approach.\n\nCurrent status:\n- [x] Database schema designed\n- [x] Core logic implemented\n- [ ] Tests to be added\n- [ ] Documentation pending\n\nFeedback needed on:\n- API design approach\n- Error handling strategy\n</code></pre> <p>Mark as draft until ready for full review.</p>"},{"location":"contributing/pull-requests/#code-review-process","title":"Code Review Process","text":""},{"location":"contributing/pull-requests/#automated-checks","title":"Automated Checks","text":"<p>When you create a PR, automated checks run:</p> <p>Continuous Integration:</p> <ul> <li>Linting (flake8, pylint, ESLint)</li> <li>Formatting (Black, Prettier)</li> <li>Type checking (mypy, TypeScript)</li> <li>Unit tests</li> <li>Integration tests</li> <li>Security scanning (Bandit, npm audit)</li> <li>Code coverage analysis</li> </ul> <p>All checks must pass before review.</p>"},{"location":"contributing/pull-requests/#reviewer-assignment","title":"Reviewer Assignment","text":"<p>The system automatically assigns reviewers based on:</p> <ul> <li>Code ownership (CODEOWNERS file)</li> <li>Area of expertise</li> <li>Recent activity</li> <li>Availability</li> </ul> <p>You can also request specific reviewers.</p>"},{"location":"contributing/pull-requests/#review-timeline","title":"Review Timeline","text":"<p>Expected timeline:</p> <ul> <li>Initial review: Within 2 business days</li> <li>Follow-up reviews: Within 1 business day</li> <li>Merge: After approval and CI passes</li> </ul>"},{"location":"contributing/pull-requests/#addressing-review-comments","title":"Addressing Review Comments","text":"<p>When you receive feedback:</p> <p>1. Read all comments carefully</p> <p>Understand the feedback before responding or making changes.</p> <p>2. Respond to each comment</p> <p>Either:</p> <ul> <li>Acknowledge and make the requested change</li> <li>Ask for clarification if needed</li> <li>Explain your approach if you disagree</li> </ul> <p>3. Make requested changes</p> <p>Commit changes with clear messages:</p> <pre><code>git commit -m \"refactor: extract validation logic to separate function\n\nAddresses review feedback from @reviewer\"\n</code></pre> <p>4. Re-request review</p> <p>After addressing all comments:</p> <pre><code># Push changes\ngit push origin feature/your-feature\n\n# Request re-review on GitHub UI\n</code></pre> <p>5. Mark resolved</p> <p>When you've addressed a comment, mark it as resolved.</p>"},{"location":"contributing/pull-requests/#common-review-feedback","title":"Common Review Feedback","text":""},{"location":"contributing/pull-requests/#code-quality","title":"Code Quality","text":"<p>Issue: Complex function needs simplification</p> <pre><code># Reviewer feedback: This function is too complex\n\n# Before\ndef process_data(data):\n    result = []\n    for item in data:\n        if item['type'] == 'metric':\n            if item['value'] &gt; 0:\n                if item['team_id'] in allowed_teams:\n                    result.append(transform(item))\n    return result\n\n# After: Extracted helper functions\ndef is_valid_metric(item):\n    return (item['type'] == 'metric' and\n            item['value'] &gt; 0 and\n            item['team_id'] in allowed_teams)\n\ndef process_data(data):\n    valid_metrics = filter(is_valid_metric, data)\n    return [transform(item) for item in valid_metrics]\n</code></pre>"},{"location":"contributing/pull-requests/#testing","title":"Testing","text":"<p>Issue: Missing test cases</p> <pre><code># Reviewer feedback: Add tests for error cases\n\n# Add edge case tests\ndef test_calculate_metrics_with_empty_data():\n    \"\"\"Test that empty data returns default values.\"\"\"\n    result = calculate_metrics(team_id=\"123\", data=[])\n    assert result.deployment_frequency == 0\n    assert result.lead_time == 0\n\ndef test_calculate_metrics_with_invalid_team():\n    \"\"\"Test that invalid team raises error.\"\"\"\n    with pytest.raises(TeamNotFoundError):\n        calculate_metrics(team_id=\"invalid\", data=test_data)\n</code></pre>"},{"location":"contributing/pull-requests/#documentation","title":"Documentation","text":"<p>Issue: Missing docstring</p> <pre><code># Reviewer feedback: Add docstring\n\ndef calculate_dora_metrics(team_id: str, start_date: datetime, end_date: datetime):\n    \"\"\"\n    Calculate DORA metrics for a team within a date range.\n\n    Args:\n        team_id: Unique identifier for the team\n        start_date: Start of the date range (inclusive)\n        end_date: End of the date range (inclusive)\n\n    Returns:\n        DORAMetrics object containing:\n        - deployment_frequency: Deployments per day\n        - lead_time: Average hours from commit to deploy\n        - change_failure_rate: Percentage of failed deployments\n        - recovery_time: Average hours to recover from failure\n\n    Raises:\n        ValueError: If date range is invalid\n        TeamNotFoundError: If team_id doesn't exist\n    \"\"\"\n</code></pre>"},{"location":"contributing/pull-requests/#performance","title":"Performance","text":"<p>Issue: N+1 query problem</p> <pre><code># Reviewer feedback: This causes N+1 queries\n\n# Before\ndef get_teams_with_members():\n    teams = Team.query.all()\n    return [\n        {\n            'team': team,\n            'members': team.members.all()  # N+1: Query for each team\n        }\n        for team in teams\n    ]\n\n# After: Use eager loading\ndef get_teams_with_members():\n    teams = Team.query.options(\n        joinedload(Team.members)\n    ).all()\n    return [\n        {\n            'team': team,\n            'members': team.members  # Already loaded\n        }\n        for team in teams\n    ]\n</code></pre>"},{"location":"contributing/pull-requests/#merging","title":"Merging","text":""},{"location":"contributing/pull-requests/#merge-criteria","title":"Merge Criteria","text":"<p>PRs are merged when:</p> <ul> <li>All automated checks pass</li> <li>At least one maintainer approves</li> <li>All review comments addressed</li> <li>No merge conflicts</li> <li>Branch is up-to-date with master</li> </ul>"},{"location":"contributing/pull-requests/#merge-strategies","title":"Merge Strategies","text":"<p>We use squash and merge for most PRs:</p> <ul> <li>Creates single commit on master</li> <li>Keeps history clean</li> <li>Preserves PR reference</li> </ul> <p>For some cases, we use merge commit:</p> <ul> <li>Feature branches with meaningful commit history</li> <li>PRs with co-authors</li> <li>When commits tell a story</li> </ul>"},{"location":"contributing/pull-requests/#post-merge","title":"Post-Merge","text":"<p>After your PR is merged:</p> <p>1. Delete your branch</p> <pre><code>git branch -d feature/your-feature\ngit push origin --delete feature/your-feature\n</code></pre> <p>2. Update your local master</p> <pre><code>git checkout master\ngit pull upstream master\n</code></pre> <p>3. Verify in production</p> <p>Monitor that your changes work as expected in production.</p> <p>4. Close related issues</p> <p>If not automatically closed, manually close related issues.</p>"},{"location":"contributing/pull-requests/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/pull-requests/#ci-failures","title":"CI Failures","text":"<p>Linting failures:</p> <pre><code># Run linter locally\nmake lint\n\n# Auto-fix issues\nmake format\n</code></pre> <p>Test failures:</p> <pre><code># Run tests locally\nmake test\n\n# Run specific test\npytest tests/test_specific.py -v\n\n# Debug failing test\npytest tests/test_specific.py -v -s --pdb\n</code></pre> <p>Merge conflicts:</p> <pre><code># Update from master\ngit fetch upstream\ngit rebase upstream/master\n\n# Resolve conflicts\n# Edit conflicting files\ngit add .\ngit rebase --continue\n\n# Force push (be careful!)\ngit push origin feature/your-feature --force-with-lease\n</code></pre>"},{"location":"contributing/pull-requests/#review-delays","title":"Review Delays","text":"<p>If your PR hasn't been reviewed:</p> <ul> <li>Ensure all CI checks pass</li> <li>Ping in PR comments after 3 business days</li> <li>Ask in Discord #dev channel</li> <li>Email maintainers@sei-platform.org</li> </ul>"},{"location":"contributing/pull-requests/#disagreements","title":"Disagreements","text":"<p>If you disagree with feedback:</p> <ol> <li>Explain your reasoning politely</li> <li>Provide evidence (benchmarks, examples)</li> <li>Suggest alternatives</li> <li>Be open to compromise</li> </ol> <p>If no consensus, maintainers make final decision.</p>"},{"location":"contributing/pull-requests/#best-practices","title":"Best Practices","text":""},{"location":"contributing/pull-requests/#before-submitting","title":"Before Submitting","text":"<ul> <li>Test locally in clean environment</li> <li>Review your own code first</li> <li>Check diff for unintended changes</li> <li>Verify no debug code or console.logs</li> <li>Ensure no secrets or credentials</li> </ul>"},{"location":"contributing/pull-requests/#during-review","title":"During Review","text":"<ul> <li>Respond promptly to feedback</li> <li>Ask questions if unclear</li> <li>Be receptive to suggestions</li> <li>Thank reviewers for their time</li> </ul>"},{"location":"contributing/pull-requests/#communication","title":"Communication","text":"<ul> <li>Be professional and respectful</li> <li>Focus on code, not people</li> <li>Explain your reasoning</li> <li>Admit mistakes gracefully</li> </ul>"},{"location":"contributing/pull-requests/#learning","title":"Learning","text":"<ul> <li>Learn from feedback</li> <li>Apply lessons to future PRs</li> <li>Help review others' PRs</li> <li>Contribute to review discussions</li> </ul>"},{"location":"contributing/pull-requests/#pr-templates","title":"PR Templates","text":""},{"location":"contributing/pull-requests/#bug-fix-template","title":"Bug Fix Template","text":"<pre><code>## Bug Fix: [Brief Description]\n\n### Problem\n[Describe the bug and its impact]\n\n### Root Cause\n[Explain what caused the bug]\n\n### Solution\n[Describe how you fixed it]\n\n### Testing\n- [ ] Added regression test\n- [ ] Verified fix in development\n- [ ] Tested edge cases\n\nFixes #[issue-number]\n</code></pre>"},{"location":"contributing/pull-requests/#feature-template","title":"Feature Template","text":"<pre><code>## Feature: [Feature Name]\n\n### Description\n[What does this feature do and why is it needed?]\n\n### Implementation\n[Key technical decisions and approach]\n\n### Testing\n- [ ] Unit tests added\n- [ ] Integration tests added\n- [ ] Documentation updated\n\nCloses #[issue-number]\n</code></pre>"},{"location":"contributing/pull-requests/#documentation-template","title":"Documentation Template","text":"<pre><code>## Documentation: [Area]\n\n### Changes\n[What documentation was added/updated?]\n\n### Motivation\n[Why was this documentation needed?]\n\n### Checklist\n- [ ] Checked for broken links\n- [ ] Verified code examples work\n- [ ] Updated table of contents if needed\n</code></pre>"},{"location":"contributing/pull-requests/#additional-resources","title":"Additional Resources","text":"<ul> <li>Contributing Guidelines</li> <li>Code Style Guide</li> <li>GitHub Pull Request Documentation</li> <li>Conventional Commits</li> </ul>"},{"location":"contributing/pull-requests/#questions","title":"Questions?","text":"<ul> <li>Check GitHub Discussions</li> <li>Ask in Discord #dev channel</li> <li>Email contributors@sei-platform.org</li> </ul> <p>Thank you for contributing to the SEI Platform!</p>"},{"location":"contributing/roadmap/","title":"Contributing to the Roadmap","text":"<p>This document explains how contributors can align their work with the project roadmap and help shape the platform's future direction.</p>"},{"location":"contributing/roadmap/#understanding-the-roadmap","title":"Understanding the Roadmap","text":"<p>The SEI Platform follows a phased development approach over 12 months. The roadmap breaks down each phase into monthly and weekly deliverables.</p>"},{"location":"contributing/roadmap/#current-phase","title":"Current Phase","text":"<p>Check the roadmap to see which phase we're currently in:</p> <ul> <li>Phase 1 (Months 1-3): Foundation</li> <li>Phase 2 (Months 4-6): Core Features</li> <li>Phase 3 (Months 7-9): Advanced Analytics</li> <li>Phase 4 (Months 10-12): Enterprise Features</li> </ul>"},{"location":"contributing/roadmap/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/roadmap/#align-with-current-phase","title":"Align with Current Phase","text":"<p>Focus contributions on the current phase priorities:</p> <p>Phase 1 Focus:</p> <ul> <li>Infrastructure components</li> <li>Basic data collectors</li> <li>Core database schema</li> <li>Initial API endpoints</li> <li>Simple dashboards</li> </ul> <p>Phase 2 Focus:</p> <ul> <li>DORA metrics implementation</li> <li>Team performance analytics</li> <li>Advanced integrations</li> <li>Real-time processing</li> </ul> <p>Phase 3 Focus:</p> <ul> <li>Machine learning models</li> <li>Predictive analytics</li> <li>Custom metrics framework</li> <li>Mobile applications</li> </ul> <p>Phase 4 Focus:</p> <ul> <li>Multi-tenant architecture</li> <li>Enterprise security</li> <li>Performance optimization</li> <li>Documentation completion</li> </ul>"},{"location":"contributing/roadmap/#finding-tasks","title":"Finding Tasks","text":"<p>1. Check the roadmap for current sprint</p> <p>Each phase breaks down into monthly and weekly deliverables. Look for:</p> <ul> <li>Unchecked items in current month</li> <li>Items marked as \"help wanted\"</li> <li>Tasks aligned with your expertise</li> </ul> <p>2. Review GitHub Issues</p> <p>Issues are tagged by phase and priority:</p> <ul> <li><code>phase-1-foundation</code></li> <li><code>phase-2-core</code></li> <li><code>phase-3-advanced</code></li> <li><code>phase-4-enterprise</code></li> <li><code>good-first-issue</code></li> <li><code>help-wanted</code></li> </ul> <p>3. Join planning discussions</p> <p>Participate in:</p> <ul> <li>Weekly sprint planning meetings</li> <li>Monthly phase review sessions</li> <li>GitHub Discussions for roadmap topics</li> </ul>"},{"location":"contributing/roadmap/#proposing-new-features","title":"Proposing New Features","text":""},{"location":"contributing/roadmap/#feature-proposal-process","title":"Feature Proposal Process","text":"<p>To propose a feature not on the roadmap:</p> <p>1. Create a feature proposal issue</p> <p>Use the feature request template and include:</p> <ul> <li>Problem statement</li> <li>Proposed solution</li> <li>User stories</li> <li>Technical approach</li> <li>Estimated effort</li> <li>Alignment with project goals</li> </ul> <p>2. Discuss with maintainers</p> <p>Maintainers will evaluate based on:</p> <ul> <li>Alignment with platform vision</li> <li>Priority relative to roadmap items</li> <li>Resource availability</li> <li>Technical feasibility</li> <li>Community benefit</li> </ul> <p>3. Get approval before starting</p> <p>Wait for maintainer approval before investing significant effort.</p> <p>4. Update roadmap if approved</p> <p>Approved features are added to the appropriate phase.</p>"},{"location":"contributing/roadmap/#feature-criteria","title":"Feature Criteria","text":"<p>Features are more likely to be accepted if they:</p> <ul> <li>Solve a common engineering intelligence problem</li> <li>Align with DORA metrics and DevOps best practices</li> <li>Integrate well with existing architecture</li> <li>Can be implemented incrementally</li> <li>Have broad community benefit</li> <li>Include comprehensive tests and documentation</li> </ul>"},{"location":"contributing/roadmap/#sprint-planning","title":"Sprint Planning","text":""},{"location":"contributing/roadmap/#sprint-structure","title":"Sprint Structure","text":"<p>We operate in 2-week sprints:</p> <p>Week 1: Development and review Week 2: Testing and integration</p>"},{"location":"contributing/roadmap/#sprint-participation","title":"Sprint Participation","text":"<p>To participate in sprints:</p> <p>1. Attend sprint planning (every other Monday)</p> <ul> <li>Review upcoming tasks</li> <li>Claim tasks you want to work on</li> <li>Discuss dependencies and blockers</li> </ul> <p>2. Daily check-ins (async in Discord)</p> <ul> <li>What you completed yesterday</li> <li>What you're working on today</li> <li>Any blockers</li> </ul> <p>3. Sprint review (Friday of week 2)</p> <ul> <li>Demo completed work</li> <li>Get feedback from team</li> <li>Identify improvements</li> </ul>"},{"location":"contributing/roadmap/#roadmap-milestones","title":"Roadmap Milestones","text":""},{"location":"contributing/roadmap/#phase-milestones","title":"Phase Milestones","text":"<p>Each phase has defined success criteria:</p> <p>Phase 1 Success Criteria:</p> <ul> <li>100+ developers tracked</li> <li>5+ repositories integrated</li> <li>Basic DORA metrics displayed</li> <li>99%+ system uptime</li> <li>Sub-5 second dashboard load times</li> </ul> <p>Phase 2 Success Criteria:</p> <ul> <li>All 4 DORA metrics implemented</li> <li>10+ integrations working</li> <li>Real-time alerts functioning</li> <li>500+ developers tracked</li> <li>Sub-2 second query response times</li> </ul> <p>Phase 3 Success Criteria:</p> <ul> <li>5+ ML models in production</li> <li>Custom metrics framework live</li> <li>Mobile apps in app stores</li> <li>1000+ API requests/minute</li> <li>95%+ prediction accuracy</li> </ul> <p>Phase 4 Success Criteria:</p> <ul> <li>Multi-tenant architecture deployed</li> <li>Enterprise security certified</li> <li>10,000+ users supported</li> <li>Complete documentation available</li> <li>Active community established</li> </ul>"},{"location":"contributing/roadmap/#contributing-to-milestones","title":"Contributing to Milestones","text":"<p>Help achieve milestones by:</p> <ul> <li>Implementing features toward success criteria</li> <li>Writing tests to ensure reliability</li> <li>Improving performance metrics</li> <li>Documenting capabilities</li> <li>Testing with realistic data</li> </ul>"},{"location":"contributing/roadmap/#priority-areas","title":"Priority Areas","text":""},{"location":"contributing/roadmap/#high-priority-always-needed","title":"High Priority (Always Needed)","text":"<ul> <li>Bug fixes for existing features</li> <li>Performance optimizations</li> <li>Security improvements</li> <li>Test coverage increases</li> <li>Documentation updates</li> </ul>"},{"location":"contributing/roadmap/#medium-priority-phase-dependent","title":"Medium Priority (Phase Dependent)","text":"<ul> <li>Features from current phase</li> <li>Integration improvements</li> <li>UI/UX enhancements</li> <li>API additions</li> </ul>"},{"location":"contributing/roadmap/#low-priority-future-phases","title":"Low Priority (Future Phases)","text":"<ul> <li>Features from future phases</li> <li>Experimental capabilities</li> <li>Nice-to-have improvements</li> </ul>"},{"location":"contributing/roadmap/#technical-decisions","title":"Technical Decisions","text":""},{"location":"contributing/roadmap/#architecture-decision-records","title":"Architecture Decision Records","text":"<p>Significant technical decisions are documented in ADRs.</p> <p>When to create an ADR:</p> <ul> <li>Choosing between architectural approaches</li> <li>Adopting new technologies</li> <li>Changing core patterns</li> <li>Making breaking changes</li> </ul> <p>ADR Process:</p> <ol> <li>Create ADR draft in <code>docs/adr/</code></li> <li>Discuss in GitHub Discussions</li> <li>Get maintainer approval</li> <li>Implement decision</li> <li>Update ADR with outcomes</li> </ol>"},{"location":"contributing/roadmap/#technology-choices","title":"Technology Choices","text":"<p>The platform has established technology choices:</p> <p>Backend: Python (FastAPI), Go (DORA engine) Frontend: React, Vue.js, Next.js Data: TimescaleDB, PostgreSQL, Redis Processing: Apache Spark, Kafka Deployment: Kubernetes, Docker</p> <p>Proposing different technologies requires strong justification.</p>"},{"location":"contributing/roadmap/#community-involvement","title":"Community Involvement","text":""},{"location":"contributing/roadmap/#ways-to-help","title":"Ways to Help","text":"<p>Beyond code contributions:</p> <p>Documentation:</p> <ul> <li>Write tutorials and guides</li> <li>Create video walkthroughs</li> <li>Improve API documentation</li> <li>Translate to other languages</li> </ul> <p>Testing:</p> <ul> <li>Test new features</li> <li>Report bugs</li> <li>Create test cases</li> <li>Perform usability testing</li> </ul> <p>Design:</p> <ul> <li>Create UI mockups</li> <li>Design dashboards</li> <li>Improve user experience</li> <li>Develop brand assets</li> </ul> <p>Community Support:</p> <ul> <li>Answer questions in Discussions</li> <li>Help new contributors</li> <li>Write blog posts</li> <li>Give conference talks</li> </ul>"},{"location":"contributing/roadmap/#special-interest-groups","title":"Special Interest Groups","text":"<p>Join or create SIGs for specific areas:</p> <ul> <li>SIG-Analytics: ML and predictive analytics</li> <li>SIG-Integrations: Third-party integrations</li> <li>SIG-Security: Security and compliance</li> <li>SIG-Performance: Scalability and optimization</li> </ul>"},{"location":"contributing/roadmap/#communication-channels","title":"Communication Channels","text":""},{"location":"contributing/roadmap/#roadmap-discussions","title":"Roadmap Discussions","text":"<ul> <li>GitHub Discussions: Roadmap category</li> <li>Discord: #roadmap channel</li> <li>Monthly calls: First Friday of each month</li> </ul>"},{"location":"contributing/roadmap/#stay-updated","title":"Stay Updated","text":"<ul> <li>Watch the GitHub repository</li> <li>Subscribe to roadmap discussion topics</li> <li>Join Discord for real-time updates</li> <li>Read monthly progress reports</li> </ul>"},{"location":"contributing/roadmap/#recognition","title":"Recognition","text":"<p>Contributors to roadmap items receive:</p> <ul> <li>Credit in release notes</li> <li>Mention in monthly newsletters</li> <li>Badge in GitHub profile</li> <li>Invitation to contributor events</li> </ul> <p>Significant contributors become roadmap co-authors.</p>"},{"location":"contributing/roadmap/#example-workflow","title":"Example Workflow","text":""},{"location":"contributing/roadmap/#contributing-to-phase-2-dora-metrics","title":"Contributing to Phase 2 (DORA Metrics)","text":"<ol> <li>Check roadmap: Phase 2, Month 4, Weeks 13-14</li> <li>Find task: \"Implement deployment frequency calculation\"</li> <li>Check issues: Look for related issue or create one</li> <li>Discuss approach: Comment on issue with proposed solution</li> <li>Get approval: Wait for maintainer OK</li> <li>Implement: Create PR following guidelines</li> <li>Test: Ensure all DORA metrics tests pass</li> <li>Document: Update DORA metrics documentation</li> <li>Submit: Open PR referencing roadmap item</li> <li>Review: Address feedback and merge</li> </ol>"},{"location":"contributing/roadmap/#questions","title":"Questions?","text":"<ul> <li>Ask in GitHub Discussions</li> <li>Join #roadmap channel in Discord</li> <li>Email roadmap@sei-platform.org</li> </ul> <p>Thank you for helping build the future of the SEI Platform!</p>"},{"location":"deployment/docker-compose/","title":"Docker Compose Deployment","text":"<p>Docker Compose provides a simple way to run the SEI Platform for development and small-scale deployments. This guide covers setup, configuration, and troubleshooting.</p>"},{"location":"deployment/docker-compose/#prerequisites","title":"Prerequisites","text":"<p>Before deploying with Docker Compose, ensure you have:</p> <ul> <li>Docker Engine 20.10 or higher</li> <li>Docker Compose v2.0 or higher</li> <li>At least 8GB of RAM available</li> <li>20GB of free disk space</li> <li>Linux, macOS, or Windows with WSL2</li> </ul> <p>Verify your installation:</p> <pre><code>docker --version\ndocker compose version\n</code></pre>"},{"location":"deployment/docker-compose/#quick-start","title":"Quick Start","text":"<p>The fastest way to get the platform running:</p> <pre><code># Clone the repository\ngit clone https://github.com/rcdelacruz/open-source-sei-platform.git\ncd open-source-sei-platform\n\n# Copy and configure environment variables\ncp .env.example .env\n\n# Start all services\nmake dev\n\n# Or use docker-compose directly\ndocker-compose up -d\n</code></pre> <p>The platform will be available at the following endpoints:</p> <ul> <li>Frontend Dashboard: http://localhost:3002</li> <li>API Service: http://localhost:8080</li> <li>Metabase: http://localhost:3000</li> <li>Grafana: http://localhost:3001</li> <li>Airflow: http://localhost:8082</li> <li>Kafka UI: http://localhost:8083</li> <li>PgAdmin: http://localhost:8084</li> </ul>"},{"location":"deployment/docker-compose/#architecture-overview","title":"Architecture Overview","text":"<p>The Docker Compose setup includes the following service categories:</p>"},{"location":"deployment/docker-compose/#core-services","title":"Core Services","text":"<p>TimescaleDB: Time-series database for metrics storage</p> <ul> <li>Port: 5432</li> <li>Volume: timescale_data</li> <li>Initial data loaded from init-timescaledb.sql</li> </ul> <p>PostgreSQL: Metadata and configuration storage</p> <ul> <li>Port: 5433</li> <li>Volume: postgres_data</li> <li>Initial data loaded from init-postgresql.sql</li> </ul> <p>Redis: Caching and session management</p> <ul> <li>Port: 6379</li> <li>Volume: redis_data</li> <li>Used for API response caching and rate limiting</li> </ul>"},{"location":"deployment/docker-compose/#message-queue","title":"Message Queue","text":"<p>Zookeeper: Kafka coordination service</p> <ul> <li>Port: 2181</li> <li>Required for Kafka operation</li> </ul> <p>Kafka: Event streaming platform</p> <ul> <li>Ports: 9092 (internal), 29092 (external)</li> <li>Volume: kafka_data</li> <li>Used for data collection pipelines</li> </ul>"},{"location":"deployment/docker-compose/#analytics","title":"Analytics","text":"<p>Metabase: Business intelligence and visualization</p> <ul> <li>Port: 3000</li> <li>Volume: metabase_data</li> <li>Default credentials: admin/admin123</li> </ul>"},{"location":"deployment/docker-compose/#monitoring","title":"Monitoring","text":"<p>Prometheus: Metrics collection</p> <ul> <li>Port: 9090</li> <li>Configuration: config/prometheus.yml</li> <li>Retention: 200 hours</li> </ul> <p>Grafana: Metrics visualization</p> <ul> <li>Port: 3001</li> <li>Default credentials: admin/admin123</li> <li>Volume: grafana_data</li> </ul>"},{"location":"deployment/docker-compose/#api-gateway","title":"API Gateway","text":"<p>Kong: API gateway and routing</p> <ul> <li>Ports: 8000 (proxy), 8001 (admin)</li> <li>Configuration: config/kong.yml</li> <li>Database-less mode for simplicity</li> </ul>"},{"location":"deployment/docker-compose/#application-services","title":"Application Services","text":"<p>Git Collector: GitHub/GitLab data collection</p> <ul> <li>Connects to Kafka and Redis</li> <li>Configuration via environment variables</li> </ul> <p>Jira Collector: Project management data collection</p> <ul> <li>Connects to Kafka and Redis</li> <li>Requires Jira API credentials</li> </ul> <p>Data Processor: Stream processing pipeline</p> <ul> <li>Processes Kafka messages</li> <li>Writes to TimescaleDB</li> </ul> <p>API Service: REST/GraphQL API</p> <ul> <li>Port: 8080</li> <li>Connects to all databases</li> <li>Serves frontend and external clients</li> </ul> <p>Frontend Dev: React development server</p> <ul> <li>Port: 3002</li> <li>Hot reload enabled</li> <li>Connects to API service</li> </ul>"},{"location":"deployment/docker-compose/#workflow-orchestration","title":"Workflow Orchestration","text":"<p>Airflow Webserver: DAG management UI</p> <ul> <li>Port: 8082</li> <li>Default credentials: admin/admin123</li> </ul> <p>Airflow Scheduler: Task scheduling and execution</p> <ul> <li>Runs scheduled data collection workflows</li> <li>Monitors DAG execution</li> </ul>"},{"location":"deployment/docker-compose/#development-tools","title":"Development Tools","text":"<p>Kafka UI: Kafka topic and consumer monitoring</p> <ul> <li>Port: 8083</li> <li>Provides insight into message flow</li> </ul> <p>PgAdmin: PostgreSQL database management</p> <ul> <li>Port: 8084</li> <li>Default credentials: admin@sei.com/admin123</li> </ul>"},{"location":"deployment/docker-compose/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/docker-compose/#required-environment-variables","title":"Required Environment Variables","text":"<p>Edit the <code>.env</code> file with your credentials:</p> <pre><code># Database Configuration\nTIMESCALE_URL=postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\nPOSTGRES_URL=postgresql://sei_user:sei_password@postgresql:5432/sei_metadata\nREDIS_URL=redis://redis:6379\n\n# Message Queue\nKAFKA_BROKERS=kafka:9092\nKAFKA_TOPIC_PREFIX=sei_\n\n# API Keys\nGITHUB_TOKEN=your_github_token_here\nGITLAB_TOKEN=your_gitlab_token_here\nJIRA_API_TOKEN=your_jira_token_here\nJIRA_BASE_URL=https://your-domain.atlassian.net\nSLACK_BOT_TOKEN=your_slack_token_here\n\n# Authentication\nJWT_SECRET=your_jwt_secret_here\nJWT_EXPIRATION=3600\n\n# Application Settings\nLOG_LEVEL=INFO\nDEBUG=true\nENVIRONMENT=development\n</code></pre>"},{"location":"deployment/docker-compose/#obtaining-api-keys","title":"Obtaining API Keys","text":"<p>GitHub Token:</p> <ol> <li>Go to GitHub Settings &gt; Developer settings &gt; Personal access tokens</li> <li>Generate new token with <code>repo</code>, <code>read:org</code>, <code>read:user</code> scopes</li> <li>Copy token to <code>.env</code> file</li> </ol> <p>GitLab Token:</p> <ol> <li>Go to GitLab User Settings &gt; Access Tokens</li> <li>Create token with <code>read_api</code>, <code>read_repository</code> scopes</li> <li>Copy token to <code>.env</code> file</li> </ol> <p>Jira API Token:</p> <ol> <li>Go to Atlassian Account &gt; Security &gt; API tokens</li> <li>Create API token</li> <li>Copy token and base URL to <code>.env</code> file</li> </ol>"},{"location":"deployment/docker-compose/#service-management","title":"Service Management","text":""},{"location":"deployment/docker-compose/#starting-services","title":"Starting Services","text":"<p>Start all services in detached mode:</p> <pre><code>docker-compose up -d\n</code></pre> <p>Start specific services:</p> <pre><code>docker-compose up -d timescaledb redis kafka\n</code></pre> <p>Start with logs visible:</p> <pre><code>docker-compose up\n</code></pre>"},{"location":"deployment/docker-compose/#stopping-services","title":"Stopping Services","text":"<p>Stop all services:</p> <pre><code>docker-compose down\n</code></pre> <p>Stop and remove volumes:</p> <pre><code>docker-compose down -v\n</code></pre> <p>Stop specific services:</p> <pre><code>docker-compose stop api-service frontend-dev\n</code></pre>"},{"location":"deployment/docker-compose/#restarting-services","title":"Restarting Services","text":"<p>Restart all services:</p> <pre><code>docker-compose restart\n</code></pre> <p>Restart specific service:</p> <pre><code>docker-compose restart api-service\n</code></pre>"},{"location":"deployment/docker-compose/#viewing-logs","title":"Viewing Logs","text":"<p>Follow all logs:</p> <pre><code>docker-compose logs -f\n</code></pre> <p>Follow specific service logs:</p> <pre><code>docker-compose logs -f api-service\ndocker-compose logs -f git-collector jira-collector\n</code></pre> <p>View last 100 lines:</p> <pre><code>docker-compose logs --tail=100 api-service\n</code></pre>"},{"location":"deployment/docker-compose/#service-health-checks","title":"Service Health Checks","text":"<p>Check service status:</p> <pre><code>docker-compose ps\n</code></pre> <p>View resource usage:</p> <pre><code>docker stats\n</code></pre> <p>Inspect specific service:</p> <pre><code>docker-compose exec api-service /bin/bash\n</code></pre>"},{"location":"deployment/docker-compose/#database-operations","title":"Database Operations","text":""},{"location":"deployment/docker-compose/#accessing-databases","title":"Accessing Databases","text":"<p>Access TimescaleDB:</p> <pre><code>docker-compose exec timescaledb psql -U sei_user -d sei_platform\n</code></pre> <p>Access PostgreSQL:</p> <pre><code>docker-compose exec postgresql psql -U sei_user -d sei_metadata\n</code></pre> <p>Access Redis:</p> <pre><code>docker-compose exec redis redis-cli\n</code></pre>"},{"location":"deployment/docker-compose/#running-migrations","title":"Running Migrations","text":"<p>Execute database migrations:</p> <pre><code>make db-migrate\n</code></pre>"},{"location":"deployment/docker-compose/#seeding-sample-data","title":"Seeding Sample Data","text":"<p>Populate with sample data for testing:</p> <pre><code>make db-seed\n</code></pre>"},{"location":"deployment/docker-compose/#backup-and-restore","title":"Backup and Restore","text":"<p>Create database backup:</p> <pre><code>make db-backup\n</code></pre> <p>Restore from backup:</p> <pre><code>make db-restore\n</code></pre>"},{"location":"deployment/docker-compose/#network-configuration","title":"Network Configuration","text":"<p>All services communicate on the <code>sei-network</code> bridge network. Service names are used as hostnames for inter-service communication.</p> <p>Service discovery:</p> <ul> <li>Services can reference each other by container name</li> <li>Example: <code>api-service</code> connects to <code>timescaledb:5432</code></li> <li>No need for IP addresses</li> </ul> <p>Exposing additional ports:</p> <p>Edit <code>docker-compose.yml</code> to add port mappings:</p> <pre><code>api-service:\n  ports:\n    - \"8080:8080\"\n    - \"8081:8081\"  # Add new port\n</code></pre>"},{"location":"deployment/docker-compose/#volume-management","title":"Volume Management","text":""},{"location":"deployment/docker-compose/#data-persistence","title":"Data Persistence","text":"<p>The following volumes store persistent data:</p> <ul> <li><code>timescale_data</code>: TimescaleDB data</li> <li><code>postgres_data</code>: PostgreSQL data</li> <li><code>redis_data</code>: Redis persistence</li> <li><code>kafka_data</code>: Kafka topics and logs</li> <li><code>metabase_data</code>: Metabase dashboards</li> <li><code>prometheus_data</code>: Metrics history</li> <li><code>grafana_data</code>: Grafana dashboards</li> <li><code>pgadmin_data</code>: PgAdmin configuration</li> </ul>"},{"location":"deployment/docker-compose/#backing-up-volumes","title":"Backing Up Volumes","text":"<p>Create volume backups:</p> <pre><code>docker run --rm \\\n  -v sei-platform_timescale_data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar czf /backup/timescale-$(date +%Y%m%d).tar.gz /data\n</code></pre>"},{"location":"deployment/docker-compose/#restoring-volumes","title":"Restoring Volumes","text":"<p>Restore from backup:</p> <pre><code>docker run --rm \\\n  -v sei-platform_timescale_data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar xzf /backup/timescale-20250101.tar.gz -C /\n</code></pre>"},{"location":"deployment/docker-compose/#cleaning-volumes","title":"Cleaning Volumes","text":"<p>Remove unused volumes:</p> <pre><code>docker volume prune -f\n</code></pre>"},{"location":"deployment/docker-compose/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker-compose/#common-issues","title":"Common Issues","text":"<p>Services fail to start:</p> <p>Check logs for errors:</p> <pre><code>docker-compose logs [service-name]\n</code></pre> <p>Verify environment variables are set:</p> <pre><code>docker-compose config\n</code></pre> <p>Port conflicts:</p> <p>Check if ports are already in use:</p> <pre><code>lsof -i :5432\nlsof -i :8080\n</code></pre> <p>Modify port mappings in <code>docker-compose.yml</code> if needed.</p> <p>Out of memory:</p> <p>Increase Docker memory limit:</p> <ul> <li>Docker Desktop: Settings &gt; Resources &gt; Memory</li> <li>Linux: Edit <code>/etc/docker/daemon.json</code></li> </ul> <p>Database connection failures:</p> <p>Wait for database to be ready:</p> <pre><code>docker-compose logs timescaledb | grep \"ready to accept connections\"\n</code></pre> <p>Check connection string in <code>.env</code> file.</p> <p>Kafka connection issues:</p> <p>Ensure Zookeeper is running:</p> <pre><code>docker-compose ps zookeeper\n</code></pre> <p>Check Kafka advertised listeners configuration.</p>"},{"location":"deployment/docker-compose/#performance-tuning","title":"Performance Tuning","text":"<p>Database Performance:</p> <p>Increase shared buffers in TimescaleDB:</p> <pre><code>timescaledb:\n  command:\n    - postgres\n    - -c\n    - shared_buffers=2GB\n    - -c\n    - max_connections=200\n</code></pre> <p>Kafka Performance:</p> <p>Adjust memory settings:</p> <pre><code>kafka:\n  environment:\n    KAFKA_HEAP_OPTS: \"-Xmx2G -Xms2G\"\n</code></pre> <p>Redis Performance:</p> <p>Enable persistence and memory limits:</p> <pre><code>redis:\n  command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"deployment/docker-compose/#debugging","title":"Debugging","text":"<p>Enable debug logging:</p> <pre><code># Edit .env\nLOG_LEVEL=DEBUG\nDEBUG=true\n\n# Restart services\ndocker-compose restart\n</code></pre> <p>Access service shell:</p> <pre><code>docker-compose exec api-service /bin/bash\ndocker-compose exec git-collector sh\n</code></pre> <p>View service resource usage:</p> <pre><code>docker stats --no-stream\n</code></pre>"},{"location":"deployment/docker-compose/#production-considerations","title":"Production Considerations","text":"<p>Docker Compose is suitable for development and small deployments, but for production consider:</p> <ul> <li>Use production-ready configuration file: <code>docker-compose.prod.yml</code></li> <li>Enable SSL/TLS for all exposed services</li> <li>Use secrets management instead of <code>.env</code> file</li> <li>Implement proper backup strategies</li> <li>Set up log aggregation</li> <li>Enable health checks and restart policies</li> <li>Use external managed databases for better reliability</li> <li>Implement rate limiting and security policies</li> <li>Monitor resource usage and scale appropriately</li> </ul> <p>For production deployments, consider using Kubernetes instead. See the Kubernetes Deployment guide.</p>"},{"location":"deployment/docker-compose/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Compose Documentation</li> <li>Docker Best Practices</li> <li>Production Deployment Guide</li> <li>Monitoring Setup</li> </ul>"},{"location":"deployment/docker-compose/#makefile-commands","title":"Makefile Commands","text":"<p>The project includes helpful Makefile targets:</p> <pre><code>make dev          # Start development environment\nmake dev-stop     # Stop development environment\nmake dev-restart  # Restart development environment\nmake dev-logs     # Follow all logs\nmake clean        # Clean up containers and volumes\nmake reset        # Complete environment reset\n</code></pre> <p>View all available commands:</p> <pre><code>make help\n</code></pre>"},{"location":"deployment/kubernetes/","title":"Kubernetes Deployment","text":"<p>This guide covers deploying the SEI Platform to Kubernetes for production-ready, scalable environments. Kubernetes provides orchestration, auto-scaling, self-healing, and efficient resource management.</p>"},{"location":"deployment/kubernetes/#prerequisites","title":"Prerequisites","text":"<p>Before deploying to Kubernetes, ensure you have:</p> <ul> <li>Kubernetes cluster 1.24 or higher</li> <li>kubectl CLI configured to access your cluster</li> <li>Helm 3.8 or higher</li> <li>At least 16GB of RAM across nodes</li> <li>100GB of available storage</li> <li>Load balancer support or Ingress controller</li> </ul> <p>Verify your setup:</p> <pre><code>kubectl version --client\nkubectl cluster-info\nhelm version\n</code></pre>"},{"location":"deployment/kubernetes/#architecture-overview","title":"Architecture Overview","text":"<p>The Kubernetes deployment consists of:</p> <ul> <li>Namespace isolation for multi-tenancy</li> <li>StatefulSets for databases</li> <li>Deployments for stateless services</li> <li>Services for internal communication</li> <li>Ingress for external access</li> <li>ConfigMaps for configuration</li> <li>Secrets for sensitive data</li> <li>PersistentVolumeClaims for data storage</li> <li>HorizontalPodAutoscalers for auto-scaling</li> </ul>"},{"location":"deployment/kubernetes/#quick-start","title":"Quick Start","text":"<p>Deploy the platform to your Kubernetes cluster:</p> <pre><code># Create namespace and RBAC\nkubectl apply -f k8s/namespace.yaml\n\n# Create ConfigMaps and Secrets\nkubectl create configmap sei-config --from-file=config/ -n sei-platform\nkubectl create secret generic sei-secrets --from-env-file=.env -n sei-platform\n\n# Deploy all components\nkubectl apply -f k8s/\n\n# Or use the Makefile\nmake deploy-local\n</code></pre>"},{"location":"deployment/kubernetes/#namespace-setup","title":"Namespace Setup","text":"<p>The platform runs in the <code>sei-platform</code> namespace with dedicated RBAC:</p> <pre><code># Verify namespace\nkubectl get namespace sei-platform\n\n# Check service account\nkubectl get serviceaccount sei-platform-sa -n sei-platform\n\n# View RBAC permissions\nkubectl describe clusterrole sei-platform-role\n</code></pre>"},{"location":"deployment/kubernetes/#storage-configuration","title":"Storage Configuration","text":""},{"location":"deployment/kubernetes/#persistent-volumes","title":"Persistent Volumes","text":"<p>The platform requires persistent storage for databases:</p> <p>Create a StorageClass for dynamic provisioning:</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: sei-fast-storage\nprovisioner: kubernetes.io/gce-pd  # Adjust for your cloud provider\nparameters:\n  type: pd-ssd\n  replication-type: regional-pd\nreclaimPolicy: Retain\nallowVolumeExpansion: true\n</code></pre> <p>Apply the StorageClass:</p> <pre><code>kubectl apply -f k8s/storage/storageclass.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#persistent-volume-claims","title":"Persistent Volume Claims","text":"<p>Each database service uses a PVC:</p> <ul> <li>TimescaleDB: 100Gi for time-series metrics</li> <li>PostgreSQL: 50Gi for metadata</li> <li>Kafka: 50Gi for message logs</li> <li>Prometheus: 100Gi for monitoring data</li> </ul> <p>View PVCs:</p> <pre><code>kubectl get pvc -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#database-deployment","title":"Database Deployment","text":""},{"location":"deployment/kubernetes/#timescaledb-statefulset","title":"TimescaleDB StatefulSet","text":"<p>Deploy TimescaleDB for time-series data:</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: timescaledb\n  namespace: sei-platform\nspec:\n  serviceName: timescaledb\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timescaledb\n  template:\n    metadata:\n      labels:\n        app: timescaledb\n    spec:\n      containers:\n      - name: timescaledb\n        image: timescale/timescaledb:latest-pg14\n        ports:\n        - containerPort: 5432\n        env:\n        - name: POSTGRES_DB\n          value: sei_platform\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: sei-secrets\n              key: DB_USER\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: sei-secrets\n              key: DB_PASSWORD\n        volumeMounts:\n        - name: timescale-data\n          mountPath: /var/lib/postgresql/data\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n  volumeClaimTemplates:\n  - metadata:\n      name: timescale-data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: sei-fast-storage\n      resources:\n        requests:\n          storage: 100Gi\n</code></pre>"},{"location":"deployment/kubernetes/#postgresql-statefulset","title":"PostgreSQL StatefulSet","text":"<p>Deploy PostgreSQL for metadata:</p> <pre><code>kubectl apply -f k8s/databases/postgresql-statefulset.yaml\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl get statefulset -n sei-platform\nkubectl get pods -l app=postgresql -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#application-services","title":"Application Services","text":""},{"location":"deployment/kubernetes/#api-service-deployment","title":"API Service Deployment","text":"<p>Deploy the REST/GraphQL API:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-service\n  namespace: sei-platform\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api-service\n  template:\n    metadata:\n      labels:\n        app: api-service\n    spec:\n      containers:\n      - name: api-service\n        image: sei-platform/api-service:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: TIMESCALE_URL\n          valueFrom:\n            secretKeyRef:\n              name: sei-secrets\n              key: TIMESCALE_URL\n        - name: REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: sei-secrets\n              key: REDIS_URL\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"1000m\"\n</code></pre>"},{"location":"deployment/kubernetes/#data-collectors","title":"Data Collectors","text":"<p>Deploy data collectors for GitHub, GitLab, and Jira:</p> <pre><code>kubectl apply -f k8s/collectors/git-collector-deployment.yaml\nkubectl apply -f k8s/collectors/jira-collector-deployment.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#data-processors","title":"Data Processors","text":"<p>Deploy stream processing services:</p> <pre><code>kubectl apply -f k8s/processors/data-processor-deployment.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#message-queue-setup","title":"Message Queue Setup","text":""},{"location":"deployment/kubernetes/#kafka-deployment","title":"Kafka Deployment","text":"<p>Deploy Kafka for event streaming:</p> <pre><code>kubectl apply -f k8s/messaging/zookeeper-statefulset.yaml\nkubectl apply -f k8s/messaging/kafka-statefulset.yaml\n</code></pre> <p>Verify Kafka is running:</p> <pre><code>kubectl get pods -l app=kafka -n sei-platform\nkubectl logs kafka-0 -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#monitoring-stack","title":"Monitoring Stack","text":""},{"location":"deployment/kubernetes/#prometheus","title":"Prometheus","text":"<p>Deploy Prometheus for metrics collection:</p> <pre><code>kubectl apply -f k8s/monitoring/prometheus-config.yaml\nkubectl apply -f k8s/monitoring/prometheus-deployment.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#grafana","title":"Grafana","text":"<p>Deploy Grafana for visualization:</p> <pre><code>kubectl apply -f k8s/monitoring/grafana-deployment.yaml\n</code></pre> <p>Access Grafana:</p> <pre><code>kubectl port-forward svc/grafana 3000:3000 -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#service-configuration","title":"Service Configuration","text":""},{"location":"deployment/kubernetes/#internal-services","title":"Internal Services","text":"<p>Services for internal communication:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  namespace: sei-platform\nspec:\n  selector:\n    app: api-service\n  ports:\n  - port: 8080\n    targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"deployment/kubernetes/#external-access","title":"External Access","text":"<p>Create a LoadBalancer service for external access:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api-service-external\n  namespace: sei-platform\nspec:\n  selector:\n    app: api-service\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: LoadBalancer\n</code></pre>"},{"location":"deployment/kubernetes/#ingress-configuration","title":"Ingress Configuration","text":""},{"location":"deployment/kubernetes/#nginx-ingress","title":"Nginx Ingress","text":"<p>Configure Ingress for HTTP/HTTPS access:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sei-platform-ingress\n  namespace: sei-platform\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - sei.example.com\n    secretName: sei-tls-cert\n  rules:\n  - host: sei.example.com\n    http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 8080\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: frontend-service\n            port:\n              number: 3000\n</code></pre> <p>Apply the Ingress:</p> <pre><code>kubectl apply -f k8s/ingress/ingress.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#configuration-management","title":"Configuration Management","text":""},{"location":"deployment/kubernetes/#configmaps","title":"ConfigMaps","text":"<p>Create ConfigMaps for application configuration:</p> <pre><code># From files\nkubectl create configmap sei-config \\\n  --from-file=config/app.yaml \\\n  --from-file=config/prometheus.yml \\\n  -n sei-platform\n\n# From literals\nkubectl create configmap sei-env-config \\\n  --from-literal=LOG_LEVEL=INFO \\\n  --from-literal=ENVIRONMENT=production \\\n  -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#secrets","title":"Secrets","text":"<p>Create Secrets for sensitive data:</p> <pre><code># From environment file\nkubectl create secret generic sei-secrets \\\n  --from-env-file=.env.production \\\n  -n sei-platform\n\n# From literals\nkubectl create secret generic api-keys \\\n  --from-literal=GITHUB_TOKEN=ghp_xxxxx \\\n  --from-literal=JIRA_TOKEN=xxxxx \\\n  -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#auto-scaling","title":"Auto-scaling","text":""},{"location":"deployment/kubernetes/#horizontal-pod-autoscaler","title":"Horizontal Pod Autoscaler","text":"<p>Configure HPA for API service:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: api-service-hpa\n  namespace: sei-platform\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: api-service\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre> <p>Apply HPA:</p> <pre><code>kubectl apply -f k8s/autoscaling/api-service-hpa.yaml\n</code></pre> <p>Verify HPA:</p> <pre><code>kubectl get hpa -n sei-platform\nkubectl describe hpa api-service-hpa -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#health-checks","title":"Health Checks","text":""},{"location":"deployment/kubernetes/#liveness-probes","title":"Liveness Probes","text":"<p>Ensure containers are restarted if unhealthy:</p> <pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n</code></pre>"},{"location":"deployment/kubernetes/#readiness-probes","title":"Readiness Probes","text":"<p>Prevent traffic to containers not ready:</p> <pre><code>readinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 5\n  timeoutSeconds: 3\n  failureThreshold: 3\n</code></pre>"},{"location":"deployment/kubernetes/#security","title":"Security","text":""},{"location":"deployment/kubernetes/#network-policies","title":"Network Policies","text":"<p>Restrict network traffic between pods:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-service-netpol\n  namespace: sei-platform\nspec:\n  podSelector:\n    matchLabels:\n      app: api-service\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend-service\n    ports:\n    - protocol: TCP\n      port: 8080\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: timescaledb\n    ports:\n    - protocol: TCP\n      port: 5432\n</code></pre>"},{"location":"deployment/kubernetes/#pod-security-policies","title":"Pod Security Policies","text":"<p>Apply security constraints:</p> <pre><code>apiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: sei-platform-psp\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  runAsUser:\n    rule: MustRunAsNonRoot\n  fsGroup:\n    rule: RunAsAny\n  seLinux:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  volumes:\n    - configMap\n    - secret\n    - persistentVolumeClaim\n</code></pre>"},{"location":"deployment/kubernetes/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":""},{"location":"deployment/kubernetes/#database-backups","title":"Database Backups","text":"<p>Create CronJob for automated backups:</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: timescaledb-backup\n  namespace: sei-platform\nspec:\n  schedule: \"0 2 * * *\"  # Daily at 2 AM\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: postgres:14\n            command:\n            - sh\n            - -c\n            - pg_dump -h timescaledb -U sei_user sei_platform | gzip &gt; /backup/backup-$(date +%Y%m%d).sql.gz\n            env:\n            - name: PGPASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: sei-secrets\n                  key: DB_PASSWORD\n            volumeMounts:\n            - name: backup-storage\n              mountPath: /backup\n          volumes:\n          - name: backup-storage\n            persistentVolumeClaim:\n              claimName: backup-pvc\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"deployment/kubernetes/#velero-for-cluster-backups","title":"Velero for Cluster Backups","text":"<p>Install Velero for complete cluster backups:</p> <pre><code># Install Velero CLI\nbrew install velero\n\n# Install Velero in cluster\nvelero install \\\n  --provider aws \\\n  --bucket sei-platform-backups \\\n  --secret-file ./credentials-velero\n\n# Create backup schedule\nvelero schedule create sei-daily \\\n  --schedule=\"@daily\" \\\n  --include-namespaces sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"deployment/kubernetes/#prometheus-monitoring","title":"Prometheus Monitoring","text":"<p>Configure ServiceMonitor for metrics:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: api-service-monitor\n  namespace: sei-platform\nspec:\n  selector:\n    matchLabels:\n      app: api-service\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n</code></pre>"},{"location":"deployment/kubernetes/#logging-with-fluent-bit","title":"Logging with Fluent Bit","text":"<p>Deploy Fluent Bit for log aggregation:</p> <pre><code>kubectl apply -f k8s/logging/fluent-bit-daemonset.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"deployment/kubernetes/#rolling-update","title":"Rolling Update","text":"<p>Default deployment strategy with zero downtime:</p> <pre><code>spec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n</code></pre>"},{"location":"deployment/kubernetes/#blue-green-deployment","title":"Blue-Green Deployment","text":"<p>Switch between versions instantly:</p> <pre><code># Deploy new version (green)\nkubectl apply -f k8s/deployments/api-service-v2.yaml\n\n# Test green deployment\nkubectl port-forward deployment/api-service-v2 8081:8080\n\n# Switch service to green\nkubectl patch service api-service -p '{\"spec\":{\"selector\":{\"version\":\"v2\"}}}'\n\n# Remove blue deployment\nkubectl delete deployment api-service-v1\n</code></pre>"},{"location":"deployment/kubernetes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/kubernetes/#pod-issues","title":"Pod Issues","text":"<p>Check pod status:</p> <pre><code>kubectl get pods -n sei-platform\nkubectl describe pod &lt;pod-name&gt; -n sei-platform\nkubectl logs &lt;pod-name&gt; -n sei-platform\nkubectl logs &lt;pod-name&gt; -n sei-platform --previous\n</code></pre>"},{"location":"deployment/kubernetes/#service-connectivity","title":"Service Connectivity","text":"<p>Test service connectivity:</p> <pre><code>kubectl run test-pod --rm -it --image=busybox -n sei-platform -- sh\nwget -O- http://api-service:8080/health\n</code></pre>"},{"location":"deployment/kubernetes/#resource-issues","title":"Resource Issues","text":"<p>Check resource usage:</p> <pre><code>kubectl top nodes\nkubectl top pods -n sei-platform\nkubectl describe node &lt;node-name&gt;\n</code></pre>"},{"location":"deployment/kubernetes/#events","title":"Events","text":"<p>View cluster events:</p> <pre><code>kubectl get events -n sei-platform --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"deployment/kubernetes/#scaling-operations","title":"Scaling Operations","text":""},{"location":"deployment/kubernetes/#manual-scaling","title":"Manual Scaling","text":"<p>Scale deployments manually:</p> <pre><code># Scale API service\nkubectl scale deployment api-service --replicas=5 -n sei-platform\n\n# Scale data collectors\nkubectl scale deployment git-collector --replicas=3 -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#cluster-auto-scaling","title":"Cluster Auto-scaling","text":"<p>Configure cluster autoscaler for node scaling:</p> <pre><code>kubectl apply -f k8s/autoscaling/cluster-autoscaler.yaml\n</code></pre>"},{"location":"deployment/kubernetes/#upgrades-and-updates","title":"Upgrades and Updates","text":""},{"location":"deployment/kubernetes/#rolling-update_1","title":"Rolling Update","text":"<p>Update deployment with new image:</p> <pre><code>kubectl set image deployment/api-service \\\n  api-service=sei-platform/api-service:v2.0.0 \\\n  -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#rollback","title":"Rollback","text":"<p>Rollback to previous version:</p> <pre><code># View rollout history\nkubectl rollout history deployment/api-service -n sei-platform\n\n# Rollback to previous revision\nkubectl rollout undo deployment/api-service -n sei-platform\n\n# Rollback to specific revision\nkubectl rollout undo deployment/api-service --to-revision=2 -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#production-best-practices","title":"Production Best Practices","text":"<ul> <li>Use resource requests and limits for all pods</li> <li>Implement proper health checks</li> <li>Configure HPA for dynamic scaling</li> <li>Use StatefulSets for stateful services</li> <li>Implement network policies for security</li> <li>Use secrets for sensitive data</li> <li>Enable RBAC for access control</li> <li>Set up monitoring and alerting</li> <li>Implement backup strategies</li> <li>Use multiple replicas for high availability</li> <li>Configure anti-affinity rules</li> <li>Use init containers for dependencies</li> <li>Implement graceful shutdown</li> <li>Use readiness gates for traffic management</li> </ul>"},{"location":"deployment/kubernetes/#useful-commands","title":"Useful Commands","text":"<pre><code># Get cluster info\nkubectl cluster-info\nkubectl get nodes\n\n# Manage deployments\nkubectl get deployments -n sei-platform\nkubectl get pods -n sei-platform -o wide\nkubectl get services -n sei-platform\n\n# View logs\nkubectl logs -f deployment/api-service -n sei-platform\nkubectl logs -f -l app=api-service -n sei-platform\n\n# Execute commands\nkubectl exec -it &lt;pod-name&gt; -n sei-platform -- /bin/bash\nkubectl exec -it timescaledb-0 -n sei-platform -- psql -U sei_user\n\n# Port forwarding\nkubectl port-forward svc/api-service 8080:8080 -n sei-platform\nkubectl port-forward svc/grafana 3000:3000 -n sei-platform\n\n# Configuration\nkubectl get configmap -n sei-platform\nkubectl get secret -n sei-platform\nkubectl describe configmap sei-config -n sei-platform\n</code></pre>"},{"location":"deployment/kubernetes/#additional-resources","title":"Additional Resources","text":"<ul> <li>Kubernetes Documentation</li> <li>Helm Charts</li> <li>Production Deployment Guide</li> <li>Monitoring Setup</li> <li>Docker Compose Deployment</li> </ul>"},{"location":"deployment/monitoring/","title":"Monitoring and Observability","text":"<p>Comprehensive monitoring is critical for maintaining the health, performance, and reliability of the SEI Platform. This guide covers setting up monitoring, alerting, and observability tools.</p>"},{"location":"deployment/monitoring/#overview","title":"Overview","text":"<p>The monitoring stack consists of:</p> <ul> <li>Prometheus for metrics collection and storage</li> <li>Grafana for visualization and dashboards</li> <li>AlertManager for alert routing and notifications</li> <li>Fluent Bit for log collection</li> <li>Elasticsearch for log storage</li> <li>Kibana for log visualization</li> <li>Jaeger for distributed tracing</li> <li>Node Exporter for infrastructure metrics</li> <li>Kube State Metrics for Kubernetes metrics</li> </ul>"},{"location":"deployment/monitoring/#prometheus-setup","title":"Prometheus Setup","text":""},{"location":"deployment/monitoring/#installation","title":"Installation","text":"<p>Deploy Prometheus using Helm:</p> <pre><code># Add Prometheus Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Install Prometheus\nhelm install prometheus prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --create-namespace \\\n  --set prometheus.prometheusSpec.retention=30d \\\n  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=100Gi\n</code></pre>"},{"location":"deployment/monitoring/#configuration","title":"Configuration","text":"<p>Configure Prometheus scrape targets:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: monitoring\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n      external_labels:\n        cluster: sei-platform\n        environment: production\n\n    alerting:\n      alertmanagers:\n      - static_configs:\n        - targets:\n          - alertmanager:9093\n\n    rule_files:\n    - /etc/prometheus/rules/*.yml\n\n    scrape_configs:\n    - job_name: 'kubernetes-apiservers'\n      kubernetes_sd_configs:\n      - role: endpoints\n      scheme: https\n      tls_config:\n        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n    - job_name: 'kubernetes-nodes'\n      kubernetes_sd_configs:\n      - role: node\n      relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n\n    - job_name: 'kubernetes-pods'\n      kubernetes_sd_configs:\n      - role: pod\n        namespaces:\n          names:\n          - sei-platform\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n        action: keep\n        regex: true\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n        action: replace\n        target_label: __metrics_path__\n        regex: (.+)\n      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n        action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: $1:$2\n        target_label: __address__\n\n    - job_name: 'timescaledb'\n      static_configs:\n      - targets:\n        - timescaledb-exporter:9187\n        labels:\n          service: timescaledb\n\n    - job_name: 'kafka'\n      static_configs:\n      - targets:\n        - kafka-exporter:9308\n        labels:\n          service: kafka\n\n    - job_name: 'redis'\n      static_configs:\n      - targets:\n        - redis-exporter:9121\n        labels:\n          service: redis\n</code></pre>"},{"location":"deployment/monitoring/#servicemonitor-for-applications","title":"ServiceMonitor for Applications","text":"<p>Configure automatic scraping for application metrics:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: api-service-monitor\n  namespace: sei-platform\nspec:\n  selector:\n    matchLabels:\n      app: api-service\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n    scheme: http\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: data-collector-monitor\n  namespace: sei-platform\nspec:\n  selector:\n    matchLabels:\n      component: data-collector\n  endpoints:\n  - port: metrics\n    interval: 60s\n</code></pre>"},{"location":"deployment/monitoring/#grafana-setup","title":"Grafana Setup","text":""},{"location":"deployment/monitoring/#installation_1","title":"Installation","text":"<p>Grafana is included with kube-prometheus-stack, or install separately:</p> <pre><code>helm install grafana grafana/grafana \\\n  --namespace monitoring \\\n  --set persistence.enabled=true \\\n  --set persistence.size=10Gi \\\n  --set adminPassword=admin123\n</code></pre>"},{"location":"deployment/monitoring/#access-grafana","title":"Access Grafana","text":"<pre><code># Port forward to access Grafana\nkubectl port-forward -n monitoring svc/grafana 3000:80\n\n# Get admin password\nkubectl get secret -n monitoring grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre>"},{"location":"deployment/monitoring/#data-source-configuration","title":"Data Source Configuration","text":"<p>Add Prometheus as data source:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-datasources\n  namespace: monitoring\ndata:\n  prometheus.yaml: |\n    apiVersion: 1\n    datasources:\n    - name: Prometheus\n      type: prometheus\n      access: proxy\n      url: http://prometheus:9090\n      isDefault: true\n      editable: false\n</code></pre>"},{"location":"deployment/monitoring/#dashboards","title":"Dashboards","text":"<p>Import pre-built dashboards:</p> <pre><code># Kubernetes cluster monitoring\nkubectl apply -f k8s/monitoring/grafana-dashboards/kubernetes-cluster.json\n\n# API service dashboard\nkubectl apply -f k8s/monitoring/grafana-dashboards/api-service.json\n\n# Database performance dashboard\nkubectl apply -f k8s/monitoring/grafana-dashboards/timescaledb.json\n\n# Kafka metrics dashboard\nkubectl apply -f k8s/monitoring/grafana-dashboards/kafka.json\n</code></pre> <p>Key dashboard panels:</p> <ul> <li>Request rate and latency</li> <li>Error rate by endpoint</li> <li>Database query performance</li> <li>Cache hit/miss ratio</li> <li>Queue depth and lag</li> <li>Resource utilization</li> <li>Pod status and health</li> </ul>"},{"location":"deployment/monitoring/#alert-configuration","title":"Alert Configuration","text":""},{"location":"deployment/monitoring/#alertmanager-setup","title":"AlertManager Setup","text":"<p>Configure AlertManager for alert routing:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: alertmanager-config\n  namespace: monitoring\ndata:\n  alertmanager.yml: |\n    global:\n      resolve_timeout: 5m\n      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n\n    route:\n      group_by: ['alertname', 'cluster', 'service']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 12h\n      receiver: 'default'\n      routes:\n      - match:\n          severity: critical\n        receiver: 'pagerduty'\n        continue: true\n      - match:\n          severity: warning\n        receiver: 'slack'\n\n    receivers:\n    - name: 'default'\n      slack_configs:\n      - channel: '#sei-platform-alerts'\n        title: 'Alert: {{ .GroupLabels.alertname }}'\n        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'\n\n    - name: 'slack'\n      slack_configs:\n      - channel: '#sei-platform-warnings'\n        title: 'Warning: {{ .GroupLabels.alertname }}'\n        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'\n        send_resolved: true\n\n    - name: 'pagerduty'\n      pagerduty_configs:\n      - service_key: 'YOUR_PAGERDUTY_KEY'\n        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'\n\n    inhibit_rules:\n    - source_match:\n        severity: 'critical'\n      target_match:\n        severity: 'warning'\n      equal: ['alertname', 'cluster', 'service']\n</code></pre>"},{"location":"deployment/monitoring/#alert-rules","title":"Alert Rules","text":"<p>Critical platform alerts:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: sei-platform-alerts\n  namespace: monitoring\nspec:\n  groups:\n  - name: api_service\n    interval: 30s\n    rules:\n    - alert: APIHighErrorRate\n      expr: |\n        sum(rate(http_requests_total{job=\"api-service\",status=~\"5..\"}[5m]))\n        /\n        sum(rate(http_requests_total{job=\"api-service\"}[5m]))\n        &gt; 0.05\n      for: 5m\n      labels:\n        severity: critical\n        service: api-service\n      annotations:\n        summary: API error rate is above 5%\n        description: Error rate is {{ $value | humanizePercentage }}\n\n    - alert: APIHighLatency\n      expr: |\n        histogram_quantile(0.95,\n          sum(rate(http_request_duration_seconds_bucket{job=\"api-service\"}[5m])) by (le)\n        ) &gt; 1\n      for: 10m\n      labels:\n        severity: warning\n        service: api-service\n      annotations:\n        summary: API p95 latency is above 1 second\n        description: p95 latency is {{ $value }}s\n\n    - alert: APIServiceDown\n      expr: up{job=\"api-service\"} == 0\n      for: 1m\n      labels:\n        severity: critical\n        service: api-service\n      annotations:\n        summary: API service is down\n        description: API service has been down for more than 1 minute\n\n  - name: database\n    interval: 30s\n    rules:\n    - alert: DatabaseConnectionPoolHigh\n      expr: |\n        pg_stat_database_numbackends{datname=\"sei_platform\"}\n        /\n        pg_settings_max_connections\n        &gt; 0.8\n      for: 5m\n      labels:\n        severity: warning\n        service: timescaledb\n      annotations:\n        summary: Database connection pool usage is high\n        description: Connection pool at {{ $value | humanizePercentage }} capacity\n\n    - alert: DatabaseSlowQueries\n      expr: |\n        rate(pg_stat_database_blk_read_time{datname=\"sei_platform\"}[5m])\n        &gt; 100\n      for: 10m\n      labels:\n        severity: warning\n        service: timescaledb\n      annotations:\n        summary: Database experiencing slow queries\n        description: Average query time increased\n\n    - alert: DatabaseReplicationLag\n      expr: |\n        pg_replication_lag\n        &gt; 60\n      for: 5m\n      labels:\n        severity: critical\n        service: timescaledb\n      annotations:\n        summary: Database replication lag is high\n        description: Replication lag is {{ $value }} seconds\n\n  - name: kafka\n    interval: 30s\n    rules:\n    - alert: KafkaConsumerLag\n      expr: |\n        kafka_consumergroup_lag\n        &gt; 10000\n      for: 10m\n      labels:\n        severity: warning\n        service: kafka\n      annotations:\n        summary: Kafka consumer lag is high\n        description: Consumer lag is {{ $value }} messages\n\n    - alert: KafkaOfflinePartitions\n      expr: kafka_server_replicamanager_offlinereplicacount &gt; 0\n      for: 5m\n      labels:\n        severity: critical\n        service: kafka\n      annotations:\n        summary: Kafka has offline partitions\n        description: {{ $value }} offline partitions detected\n\n  - name: resources\n    interval: 30s\n    rules:\n    - alert: PodCPUThrottling\n      expr: |\n        rate(container_cpu_cfs_throttled_seconds_total{namespace=\"sei-platform\"}[5m])\n        &gt; 0.5\n      for: 10m\n      labels:\n        severity: warning\n      annotations:\n        summary: Pod experiencing CPU throttling\n        description: Pod {{ $labels.pod }} is being CPU throttled\n\n    - alert: PodMemoryPressure\n      expr: |\n        container_memory_working_set_bytes{namespace=\"sei-platform\"}\n        /\n        container_spec_memory_limit_bytes{namespace=\"sei-platform\"}\n        &gt; 0.9\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: Pod under memory pressure\n        description: Pod {{ $labels.pod }} using {{ $value | humanizePercentage }} of memory\n\n    - alert: PersistentVolumeNearFull\n      expr: |\n        kubelet_volume_stats_available_bytes{namespace=\"sei-platform\"}\n        /\n        kubelet_volume_stats_capacity_bytes{namespace=\"sei-platform\"}\n        &lt; 0.1\n      for: 10m\n      labels:\n        severity: critical\n      annotations:\n        summary: Persistent volume nearly full\n        description: Volume {{ $labels.persistentvolumeclaim }} has less than 10% free space\n</code></pre>"},{"location":"deployment/monitoring/#logging","title":"Logging","text":""},{"location":"deployment/monitoring/#fluent-bit-deployment","title":"Fluent Bit Deployment","text":"<p>Deploy Fluent Bit for log collection:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluent-bit-config\n  namespace: monitoring\ndata:\n  fluent-bit.conf: |\n    [SERVICE]\n        Flush         5\n        Log_Level     info\n        Daemon        off\n        Parsers_File  parsers.conf\n\n    [INPUT]\n        Name              tail\n        Path              /var/log/containers/*sei-platform*.log\n        Parser            docker\n        Tag               kube.*\n        Refresh_Interval  5\n        Mem_Buf_Limit     50MB\n        Skip_Long_Lines   On\n\n    [FILTER]\n        Name                kubernetes\n        Match               kube.*\n        Kube_URL            https://kubernetes.default.svc:443\n        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\n        Merge_Log           On\n        K8S-Logging.Parser  On\n        K8S-Logging.Exclude On\n\n    [OUTPUT]\n        Name            es\n        Match           *\n        Host            elasticsearch\n        Port            9200\n        Index           sei-platform\n        Type            _doc\n        Logstash_Format On\n        Retry_Limit     False\n\n  parsers.conf: |\n    [PARSER]\n        Name        docker\n        Format      json\n        Time_Key    time\n        Time_Format %Y-%m-%dT%H:%M:%S.%L\n        Time_Keep   On\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluent-bit\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:\n      app: fluent-bit\n  template:\n    metadata:\n      labels:\n        app: fluent-bit\n    spec:\n      containers:\n      - name: fluent-bit\n        image: fluent/fluent-bit:2.0\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluent-bit-config\n          mountPath: /fluent-bit/etc/\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: fluent-bit-config\n        configMap:\n          name: fluent-bit-config\n</code></pre>"},{"location":"deployment/monitoring/#elasticsearch-and-kibana","title":"Elasticsearch and Kibana","text":"<p>Deploy Elasticsearch for log storage:</p> <pre><code>helm install elasticsearch elastic/elasticsearch \\\n  --namespace monitoring \\\n  --set replicas=3 \\\n  --set minimumMasterNodes=2 \\\n  --set persistence.enabled=true \\\n  --set volumeClaimTemplate.resources.requests.storage=100Gi\n\nhelm install kibana elastic/kibana \\\n  --namespace monitoring \\\n  --set elasticsearch.hosts=http://elasticsearch-master:9200\n</code></pre> <p>Access Kibana:</p> <pre><code>kubectl port-forward -n monitoring svc/kibana 5601:5601\n</code></pre>"},{"location":"deployment/monitoring/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"deployment/monitoring/#jaeger-setup","title":"Jaeger Setup","text":"<p>Deploy Jaeger for distributed tracing:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: jaegertracing.io/v1\nkind: Jaeger\nmetadata:\n  name: sei-platform-jaeger\n  namespace: monitoring\nspec:\n  strategy: production\n  storage:\n    type: elasticsearch\n    options:\n      es:\n        server-urls: http://elasticsearch:9200\n        index-prefix: jaeger\n  ingress:\n    enabled: true\nEOF\n</code></pre>"},{"location":"deployment/monitoring/#application-integration","title":"Application Integration","text":"<p>Add tracing to applications:</p> <pre><code>from jaeger_client import Config\nfrom flask import Flask\nfrom flask_opentracing import FlaskTracing\n\napp = Flask(__name__)\n\nconfig = Config(\n    config={\n        'sampler': {'type': 'const', 'param': 1},\n        'logging': True,\n        'reporter_batch_size': 1,\n    },\n    service_name='api-service',\n    validate=True,\n)\n\ntracer = config.initialize_tracer()\ntracing = FlaskTracing(tracer, True, app)\n</code></pre>"},{"location":"deployment/monitoring/#custom-metrics","title":"Custom Metrics","text":""},{"location":"deployment/monitoring/#application-metrics","title":"Application Metrics","text":"<p>Expose custom metrics from applications:</p> <pre><code>from prometheus_client import Counter, Histogram, Gauge, generate_latest\nfrom flask import Response\n\n# Define metrics\nrequests_total = Counter(\n    'api_requests_total',\n    'Total API requests',\n    ['method', 'endpoint', 'status']\n)\n\nrequest_duration = Histogram(\n    'api_request_duration_seconds',\n    'API request duration',\n    ['method', 'endpoint']\n)\n\nactive_users = Gauge(\n    'api_active_users',\n    'Number of active users'\n)\n\n# Metrics endpoint\n@app.route('/metrics')\ndef metrics():\n    return Response(generate_latest(), mimetype='text/plain')\n\n# Instrument endpoints\n@app.route('/api/data')\n@request_duration.labels(method='GET', endpoint='/api/data').time()\ndef get_data():\n    requests_total.labels(method='GET', endpoint='/api/data', status=200).inc()\n    return jsonify({'data': 'value'})\n</code></pre>"},{"location":"deployment/monitoring/#monitoring-best-practices","title":"Monitoring Best Practices","text":""},{"location":"deployment/monitoring/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"<p>Application Metrics:</p> <ul> <li>Request rate</li> <li>Error rate</li> <li>Response time (p50, p95, p99)</li> <li>Saturation (queue depth, connection pool usage)</li> </ul> <p>Infrastructure Metrics:</p> <ul> <li>CPU utilization</li> <li>Memory usage</li> <li>Disk I/O</li> <li>Network throughput</li> <li>Pod restarts</li> </ul> <p>Business Metrics:</p> <ul> <li>Active users</li> <li>Data processing rate</li> <li>API usage by customer</li> <li>Feature adoption</li> </ul>"},{"location":"deployment/monitoring/#dashboard-organization","title":"Dashboard Organization","text":"<p>Create role-specific dashboards:</p> <p>Operations Dashboard:</p> <ul> <li>System health overview</li> <li>Resource utilization</li> <li>Error rates</li> <li>Alert status</li> </ul> <p>Development Dashboard:</p> <ul> <li>Application performance</li> <li>API latency breakdown</li> <li>Database query performance</li> <li>Cache hit rates</li> </ul> <p>Executive Dashboard:</p> <ul> <li>System uptime</li> <li>User growth</li> <li>Cost metrics</li> <li>SLA compliance</li> </ul>"},{"location":"deployment/monitoring/#health-checks","title":"Health Checks","text":""},{"location":"deployment/monitoring/#liveness-and-readiness-probes","title":"Liveness and Readiness Probes","text":"<p>Implement health check endpoints:</p> <pre><code>from flask import Flask, jsonify\nimport psycopg2\n\napp = Flask(__name__)\n\n@app.route('/health')\ndef liveness():\n    \"\"\"Liveness probe - is the application running?\"\"\"\n    return jsonify({'status': 'healthy'}), 200\n\n@app.route('/ready')\ndef readiness():\n    \"\"\"Readiness probe - can the application serve traffic?\"\"\"\n    checks = {\n        'database': check_database(),\n        'redis': check_redis(),\n        'kafka': check_kafka()\n    }\n\n    if all(checks.values()):\n        return jsonify({'status': 'ready', 'checks': checks}), 200\n    else:\n        return jsonify({'status': 'not ready', 'checks': checks}), 503\n\ndef check_database():\n    try:\n        conn = psycopg2.connect(DATABASE_URL)\n        conn.close()\n        return True\n    except:\n        return False\n</code></pre>"},{"location":"deployment/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/monitoring/#high-cpu-usage","title":"High CPU Usage","text":"<p>Check for:</p> <ul> <li>Inefficient queries</li> <li>Excessive logging</li> <li>Resource limits too low</li> <li>Background jobs</li> </ul> <pre><code>kubectl top pods -n sei-platform\nkubectl describe pod &lt;pod-name&gt; -n sei-platform\n</code></pre>"},{"location":"deployment/monitoring/#memory-leaks","title":"Memory Leaks","text":"<p>Monitor memory growth over time:</p> <pre><code>rate(container_memory_working_set_bytes{namespace=\"sei-platform\"}[1h])\n</code></pre> <p>Investigate with heap profiling:</p> <pre><code>kubectl exec -it &lt;pod-name&gt; -- python -m memory_profiler script.py\n</code></pre>"},{"location":"deployment/monitoring/#slow-database-queries","title":"Slow Database Queries","text":"<p>Identify slow queries:</p> <pre><code>SELECT query, mean_exec_time, calls\nFROM pg_stat_statements\nORDER BY mean_exec_time DESC\nLIMIT 10;\n</code></pre>"},{"location":"deployment/monitoring/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Dashboards</li> <li>Production Deployment Guide</li> <li>Kubernetes Deployment</li> </ul>"},{"location":"deployment/production/","title":"Production Deployment","text":"<p>This guide covers best practices and procedures for deploying the SEI Platform to production environments, ensuring security, reliability, and scalability.</p>"},{"location":"deployment/production/#production-readiness-checklist","title":"Production Readiness Checklist","text":"<p>Before deploying to production, complete the following:</p>"},{"location":"deployment/production/#infrastructure","title":"Infrastructure","text":"<ul> <li> Kubernetes cluster with at least 3 nodes</li> <li> Load balancer configured for external access</li> <li> SSL/TLS certificates from trusted CA</li> <li> DNS records configured</li> <li> Firewall rules and security groups defined</li> <li> Persistent storage with replication</li> <li> Backup solution in place</li> <li> Disaster recovery plan documented</li> </ul>"},{"location":"deployment/production/#security","title":"Security","text":"<ul> <li> Secrets stored in secure vault (not environment files)</li> <li> RBAC policies configured and tested</li> <li> Network policies enforced</li> <li> API authentication enabled</li> <li> Rate limiting configured</li> <li> Security scanning passed</li> <li> Vulnerability assessment completed</li> <li> Penetration testing performed</li> </ul>"},{"location":"deployment/production/#monitoring","title":"Monitoring","text":"<ul> <li> Prometheus and Grafana deployed</li> <li> Alert rules configured</li> <li> Logging aggregation set up</li> <li> Uptime monitoring enabled</li> <li> Performance metrics collected</li> <li> Error tracking configured</li> <li> On-call rotation established</li> </ul>"},{"location":"deployment/production/#data","title":"Data","text":"<ul> <li> Database migrations tested</li> <li> Backup procedures automated</li> <li> Restore procedures tested</li> <li> Data retention policies defined</li> <li> GDPR compliance verified</li> <li> Data encryption at rest enabled</li> <li> Data encryption in transit enabled</li> </ul>"},{"location":"deployment/production/#application","title":"Application","text":"<ul> <li> Health checks implemented</li> <li> Graceful shutdown configured</li> <li> Resource limits defined</li> <li> Auto-scaling policies set</li> <li> Circuit breakers implemented</li> <li> Retry logic configured</li> <li> Caching strategy deployed</li> <li> CDN configured for static assets</li> </ul>"},{"location":"deployment/production/#architecture-for-production","title":"Architecture for Production","text":""},{"location":"deployment/production/#high-availability-setup","title":"High Availability Setup","text":"<p>Deploy services across multiple availability zones:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-service\nspec:\n  replicas: 6\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - api-service\n            topologyKey: topology.kubernetes.io/zone\n</code></pre>"},{"location":"deployment/production/#database-replication","title":"Database Replication","text":"<p>Configure TimescaleDB for high availability:</p> <ul> <li>Primary-standby replication</li> <li>Automated failover with Patroni</li> <li>Point-in-time recovery enabled</li> <li>Continuous WAL archiving</li> </ul>"},{"location":"deployment/production/#load-balancing","title":"Load Balancing","text":"<p>Use external load balancer with:</p> <ul> <li>Health check endpoints</li> <li>Session affinity if needed</li> <li>SSL termination</li> <li>DDoS protection</li> </ul>"},{"location":"deployment/production/#secrets-management","title":"Secrets Management","text":""},{"location":"deployment/production/#using-hashicorp-vault","title":"Using HashiCorp Vault","text":"<p>Store secrets in Vault instead of Kubernetes Secrets:</p> <pre><code># Install Vault\nhelm install vault hashicorp/vault \\\n  --set server.ha.enabled=true \\\n  --set server.ha.replicas=3\n\n# Configure Vault auth\nvault auth enable kubernetes\n\n# Store secrets\nvault kv put secret/sei-platform/database \\\n  username=sei_user \\\n  password=secure_password\n\n# Create policy\nvault policy write sei-platform-policy - &lt;&lt;EOF\npath \"secret/data/sei-platform/*\" {\n  capabilities = [\"read\"]\n}\nEOF\n</code></pre> <p>Configure pods to use Vault:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    vault.hashicorp.com/agent-inject: \"true\"\n    vault.hashicorp.com/role: \"sei-platform\"\n    vault.hashicorp.com/agent-inject-secret-database: \"secret/data/sei-platform/database\"\nspec:\n  serviceAccountName: sei-platform-sa\n</code></pre>"},{"location":"deployment/production/#aws-secrets-manager","title":"AWS Secrets Manager","text":"<p>Alternative using AWS Secrets Manager:</p> <pre><code># Store secret\naws secretsmanager create-secret \\\n  --name sei-platform/database \\\n  --secret-string '{\"username\":\"sei_user\",\"password\":\"secure_pass\"}'\n\n# Grant IAM permissions\naws iam attach-role-policy \\\n  --role-name sei-platform-role \\\n  --policy-arn arn:aws:iam::aws:policy/SecretsManagerReadWrite\n</code></pre>"},{"location":"deployment/production/#ssltls-configuration","title":"SSL/TLS Configuration","text":""},{"location":"deployment/production/#certificate-management","title":"Certificate Management","text":"<p>Use cert-manager for automatic certificate provisioning:</p> <pre><code># Install cert-manager\nkubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yaml\n\n# Create ClusterIssuer\nkubectl apply -f - &lt;&lt;EOF\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@example.com\n    privateKeySecretRef:\n      name: letsencrypt-prod-key\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\nEOF\n</code></pre>"},{"location":"deployment/production/#ingress-with-ssl","title":"Ingress with SSL","text":"<p>Configure Ingress with automatic SSL:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sei-platform-ingress\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\nspec:\n  tls:\n  - hosts:\n    - sei.example.com\n    - api.sei.example.com\n    secretName: sei-platform-tls\n  rules:\n  - host: sei.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          service:\n            name: frontend-service\n            port:\n              number: 3000\n</code></pre>"},{"location":"deployment/production/#database-configuration","title":"Database Configuration","text":""},{"location":"deployment/production/#production-settings","title":"Production Settings","text":"<p>Configure TimescaleDB for production workloads:</p> <pre><code>-- Connection pooling\nALTER SYSTEM SET max_connections = 200;\nALTER SYSTEM SET shared_buffers = '4GB';\nALTER SYSTEM SET effective_cache_size = '12GB';\nALTER SYSTEM SET maintenance_work_mem = '1GB';\nALTER SYSTEM SET checkpoint_completion_target = 0.9;\nALTER SYSTEM SET wal_buffers = '16MB';\nALTER SYSTEM SET default_statistics_target = 100;\nALTER SYSTEM SET random_page_cost = 1.1;\nALTER SYSTEM SET effective_io_concurrency = 200;\nALTER SYSTEM SET work_mem = '20MB';\nALTER SYSTEM SET min_wal_size = '2GB';\nALTER SYSTEM SET max_wal_size = '8GB';\n</code></pre>"},{"location":"deployment/production/#connection-pooling","title":"Connection Pooling","text":"<p>Use PgBouncer for connection pooling:</p> <pre><code>[databases]\nsei_platform = host=timescaledb port=5432 dbname=sei_platform\n\n[pgbouncer]\nlisten_addr = 0.0.0.0\nlisten_port = 6432\nauth_type = md5\nauth_file = /etc/pgbouncer/userlist.txt\npool_mode = transaction\nmax_client_conn = 1000\ndefault_pool_size = 25\nmax_db_connections = 100\nserver_idle_timeout = 600\n</code></pre> <p>Deploy PgBouncer:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pgbouncer\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: pgbouncer\n        image: edoburu/pgbouncer:latest\n        ports:\n        - containerPort: 6432\n        volumeMounts:\n        - name: pgbouncer-config\n          mountPath: /etc/pgbouncer\n</code></pre>"},{"location":"deployment/production/#performance-optimization","title":"Performance Optimization","text":""},{"location":"deployment/production/#caching-strategy","title":"Caching Strategy","text":"<p>Implement multi-layer caching:</p> <p>Redis Configuration:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: redis-config\ndata:\n  redis.conf: |\n    maxmemory 4gb\n    maxmemory-policy allkeys-lru\n    save 900 1\n    save 300 10\n    save 60 10000\n    appendonly yes\n    appendfsync everysec\n</code></pre> <p>Application Caching:</p> <pre><code>from redis import Redis\nfrom functools import wraps\n\nredis_client = Redis(host='redis', port=6379, decode_responses=True)\n\ndef cache_result(ttl=3600):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            cache_key = f\"{func.__name__}:{args}:{kwargs}\"\n            cached = redis_client.get(cache_key)\n            if cached:\n                return json.loads(cached)\n            result = func(*args, **kwargs)\n            redis_client.setex(cache_key, ttl, json.dumps(result))\n            return result\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"deployment/production/#cdn-integration","title":"CDN Integration","text":"<p>Configure CDN for static assets:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: frontend-cdn\n  annotations:\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      add_header Cache-Control \"public, max-age=31536000, immutable\";\n      add_header X-CDN-Cache $upstream_cache_status;\nspec:\n  rules:\n  - host: cdn.sei.example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          service:\n            name: frontend-service\n            port:\n              number: 3000\n</code></pre>"},{"location":"deployment/production/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"deployment/production/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>Production Prometheus setup:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n      external_labels:\n        cluster: production\n        environment: prod\n\n    alerting:\n      alertmanagers:\n      - static_configs:\n        - targets:\n          - alertmanager:9093\n\n    rule_files:\n    - /etc/prometheus/rules/*.yml\n\n    scrape_configs:\n    - job_name: kubernetes-pods\n      kubernetes_sd_configs:\n      - role: pod\n        namespaces:\n          names:\n          - sei-platform\n</code></pre>"},{"location":"deployment/production/#alert-rules","title":"Alert Rules","text":"<p>Critical alert rules:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-rules\ndata:\n  alerts.yml: |\n    groups:\n    - name: sei_platform_alerts\n      interval: 30s\n      rules:\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status=~\"5..\"}[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: High error rate detected\n          description: Error rate is {{ $value }} errors/sec\n\n      - alert: HighMemoryUsage\n        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes &gt; 0.9\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: High memory usage\n          description: Memory usage is {{ $value | humanizePercentage }}\n\n      - alert: DatabaseConnectionPoolExhausted\n        expr: pg_stat_database_numbackends / pg_settings_max_connections &gt; 0.8\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Database connection pool near exhaustion\n\n      - alert: APILatencyHigh\n        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 1\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: API latency is high\n</code></pre>"},{"location":"deployment/production/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Import production dashboards:</p> <pre><code># Import Kubernetes cluster dashboard\nkubectl apply -f k8s/monitoring/grafana-dashboards/kubernetes-cluster.json\n\n# Import application dashboard\nkubectl apply -f k8s/monitoring/grafana-dashboards/sei-platform.json\n</code></pre>"},{"location":"deployment/production/#logging","title":"Logging","text":""},{"location":"deployment/production/#centralized-logging","title":"Centralized Logging","text":"<p>Deploy ELK Stack for log aggregation:</p> <pre><code># Deploy Elasticsearch\nkubectl apply -f k8s/logging/elasticsearch-statefulset.yaml\n\n# Deploy Logstash\nkubectl apply -f k8s/logging/logstash-deployment.yaml\n\n# Deploy Kibana\nkubectl apply -f k8s/logging/kibana-deployment.yaml\n\n# Deploy Filebeat as DaemonSet\nkubectl apply -f k8s/logging/filebeat-daemonset.yaml\n</code></pre>"},{"location":"deployment/production/#log-retention","title":"Log Retention","text":"<p>Configure log retention policies:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: elasticsearch-config\ndata:\n  elasticsearch.yml: |\n    indices.lifecycle.poll_interval: 1m\n\n    # Delete logs older than 30 days\n    PUT _ilm/policy/sei_platform_logs\n    {\n      \"policy\": {\n        \"phases\": {\n          \"hot\": {\n            \"actions\": {\n              \"rollover\": {\n                \"max_age\": \"1d\",\n                \"max_size\": \"50gb\"\n              }\n            }\n          },\n          \"delete\": {\n            \"min_age\": \"30d\",\n            \"actions\": {\n              \"delete\": {}\n            }\n          }\n        }\n      }\n    }\n</code></pre>"},{"location":"deployment/production/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":""},{"location":"deployment/production/#automated-backups","title":"Automated Backups","text":"<p>Daily automated backups:</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: database-backup\nspec:\n  schedule: \"0 2 * * *\"\n  successfulJobsHistoryLimit: 7\n  failedJobsHistoryLimit: 3\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: sei-platform/backup-tool:latest\n            env:\n            - name: BACKUP_DESTINATION\n              value: s3://sei-platform-backups/\n            - name: RETENTION_DAYS\n              value: \"30\"\n            - name: ENCRYPTION_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: backup-encryption\n                  key: key\n            command:\n            - /bin/bash\n            - -c\n            - |\n              TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n              pg_dump -h timescaledb -U sei_user sei_platform | \\\n                gzip | \\\n                openssl enc -aes-256-cbc -salt -pass env:ENCRYPTION_KEY | \\\n                aws s3 cp - ${BACKUP_DESTINATION}backup_${TIMESTAMP}.sql.gz.enc\n\n              # Remove old backups\n              aws s3 ls ${BACKUP_DESTINATION} | \\\n                awk '{print $4}' | \\\n                head -n -${RETENTION_DAYS} | \\\n                xargs -I {} aws s3 rm ${BACKUP_DESTINATION}{}\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"deployment/production/#disaster-recovery-plan","title":"Disaster Recovery Plan","text":"<p>Recovery Time Objective (RTO): 1 hour Recovery Point Objective (RPO): 24 hours</p> <p>Steps for disaster recovery:</p> <ol> <li> <p>Provision new infrastructure</p> <pre><code>terraform apply -var-file=prod.tfvars\n</code></pre> </li> <li> <p>Restore cluster state from Velero</p> <pre><code>velero restore create --from-backup sei-platform-daily-20250101\n</code></pre> </li> <li> <p>Restore database from backup</p> <pre><code>aws s3 cp s3://sei-platform-backups/latest.sql.gz.enc - | \\\n  openssl enc -d -aes-256-cbc -pass env:ENCRYPTION_KEY | \\\n  gunzip | \\\n  psql -h new-timescaledb -U sei_user sei_platform\n</code></pre> </li> <li> <p>Verify services</p> <pre><code>kubectl get pods -n sei-platform\nkubectl run smoke-test --rm -it --image=sei-platform/smoke-tests:latest\n</code></pre> </li> <li> <p>Update DNS to point to new cluster</p> </li> </ol>"},{"location":"deployment/production/#deployment-process","title":"Deployment Process","text":""},{"location":"deployment/production/#blue-green-deployment","title":"Blue-Green Deployment","text":"<p>Zero-downtime deployment strategy:</p> <pre><code># Deploy green environment\nkubectl apply -f k8s/production/green/\n\n# Run smoke tests\n./scripts/smoke-test.sh green\n\n# Switch traffic to green\nkubectl patch service api-service -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'\n\n# Monitor for issues\nkubectl logs -f -l version=green\n\n# If successful, remove blue\nkubectl delete -f k8s/production/blue/\n\n# If issues, rollback\nkubectl patch service api-service -p '{\"spec\":{\"selector\":{\"version\":\"blue\"}}}'\n</code></pre>"},{"location":"deployment/production/#canary-deployment","title":"Canary Deployment","text":"<p>Gradual rollout with traffic splitting:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\nspec:\n  selector:\n    app: api-service\n  # 90% traffic to stable, 10% to canary\n  sessionAffinity: ClientIP\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-service-stable\nspec:\n  replicas: 9\n  template:\n    metadata:\n      labels:\n        app: api-service\n        version: stable\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-service-canary\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: api-service\n        version: canary\n</code></pre>"},{"location":"deployment/production/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/production/#network-policies","title":"Network Policies","text":"<p>Restrict network access:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-api-to-db\nspec:\n  podSelector:\n    matchLabels:\n      app: timescaledb\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: api-service\n    ports:\n    - protocol: TCP\n      port: 5432\n</code></pre>"},{"location":"deployment/production/#pod-security-standards","title":"Pod Security Standards","text":"<p>Enforce pod security:</p> <pre><code>apiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: restricted\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n  - ALL\n  volumes:\n  - 'configMap'\n  - 'secret'\n  - 'persistentVolumeClaim'\n  runAsUser:\n    rule: 'MustRunAsNonRoot'\n  seLinux:\n    rule: 'RunAsAny'\n  fsGroup:\n    rule: 'RunAsAny'\n  readOnlyRootFilesystem: true\n</code></pre>"},{"location":"deployment/production/#compliance","title":"Compliance","text":""},{"location":"deployment/production/#gdpr-compliance","title":"GDPR Compliance","text":"<p>Implement data protection measures:</p> <ul> <li>Data encryption at rest and in transit</li> <li>Right to erasure implementation</li> <li>Data portability features</li> <li>Privacy by design</li> <li>Regular security audits</li> <li>Data processing agreements</li> </ul>"},{"location":"deployment/production/#audit-logging","title":"Audit Logging","text":"<p>Enable comprehensive audit logging:</p> <pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: RequestResponse\n  resources:\n  - group: \"\"\n    resources: [\"secrets\", \"configmaps\"]\n- level: Metadata\n  resources:\n  - group: \"\"\n    resources: [\"pods\", \"services\"]\n</code></pre>"},{"location":"deployment/production/#performance-benchmarks","title":"Performance Benchmarks","text":"<p>Target performance metrics for production:</p> <ul> <li>API response time: p50 &lt; 100ms, p95 &lt; 500ms, p99 &lt; 1s</li> <li>Database query time: p95 &lt; 100ms</li> <li>Page load time: &lt; 2 seconds</li> <li>Time to first byte: &lt; 500ms</li> <li>Throughput: 10,000 requests/second</li> <li>Uptime: 99.9%</li> <li>Error rate: &lt; 0.1%</li> </ul>"},{"location":"deployment/production/#scaling-guidelines","title":"Scaling Guidelines","text":""},{"location":"deployment/production/#vertical-scaling","title":"Vertical Scaling","text":"<p>Increase resources for individual services:</p> <pre><code>kubectl set resources deployment api-service \\\n  --requests=cpu=1000m,memory=2Gi \\\n  --limits=cpu=2000m,memory=4Gi\n</code></pre>"},{"location":"deployment/production/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Scale based on metrics:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: api-service-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: api-service\n  minReplicas: 10\n  maxReplicas: 50\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: \"1000\"\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 0\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 30\n      - type: Pods\n        value: 4\n        periodSeconds: 30\n</code></pre>"},{"location":"deployment/production/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Use spot instances for non-critical workloads</li> <li>Implement auto-scaling to match demand</li> <li>Use reserved instances for baseline capacity</li> <li>Optimize container images to reduce size</li> <li>Implement resource quotas and limits</li> <li>Monitor and eliminate unused resources</li> <li>Use multi-tenancy to share infrastructure</li> <li>Leverage CDN to reduce bandwidth costs</li> </ul>"},{"location":"deployment/production/#additional-resources","title":"Additional Resources","text":"<ul> <li>Kubernetes Production Best Practices</li> <li>Docker Compose Deployment</li> <li>Kubernetes Deployment</li> <li>Monitoring Setup</li> </ul>"},{"location":"development/code-quality/","title":"Code Quality","text":"<p>This guide covers code quality standards, tools, and practices for the SEI Platform.</p>"},{"location":"development/code-quality/#code-quality-standards","title":"Code Quality Standards","text":"<p>The SEI Platform maintains high code quality through:</p> <ul> <li>Consistent code style and formatting</li> <li>Static analysis and linting</li> <li>Type checking and validation</li> <li>Code review processes</li> <li>Automated quality checks</li> <li>Pre-commit hooks</li> <li>Continuous integration checks</li> </ul>"},{"location":"development/code-quality/#python-code-quality","title":"Python Code Quality","text":""},{"location":"development/code-quality/#code-formatting","title":"Code Formatting","text":"<p>Python code uses Black for consistent formatting:</p> <pre><code># Format all Python code\nmake format\n\n# Format specific file\nblack src/apis/main.py\n\n# Check formatting without changes\nblack --check src/\n</code></pre> <p>Black configuration in <code>pyproject.toml</code>:</p> <pre><code>[tool.black]\nline-length = 100\ntarget-version = ['py39']\ninclude = '\\.pyi?$'\nexclude = '''\n/(\n    \\.git\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n</code></pre>"},{"location":"development/code-quality/#import-sorting","title":"Import Sorting","text":"<p>Use isort to organize imports:</p> <pre><code># Sort imports\nisort src/\n\n# Check import order\nisort --check-only src/\n\n# Combined with Black\nisort src/ --profile=black\n</code></pre> <p>Configuration in <code>pyproject.toml</code>:</p> <pre><code>[tool.isort]\nprofile = \"black\"\nline_length = 100\nmulti_line_output = 3\ninclude_trailing_comma = true\nforce_grid_wrap = 0\nuse_parentheses = true\nensure_newline_before_comments = true\n</code></pre>"},{"location":"development/code-quality/#linting","title":"Linting","text":"<p>Flake8 checks for code quality issues:</p> <pre><code># Run flake8\nmake lint\n\n# Check specific file\nflake8 src/apis/main.py\n\n# Generate report\nflake8 src/ --format=html --htmldir=reports/flake8\n</code></pre> <p>Configuration in <code>.flake8</code>:</p> <pre><code>[flake8]\nmax-line-length = 100\nexclude = .git,__pycache__,build,dist,.venv\nignore = E203,E266,E501,W503\nmax-complexity = 10\nper-file-ignores =\n    __init__.py:F401\n</code></pre>"},{"location":"development/code-quality/#static-analysis","title":"Static Analysis","text":"<p>Pylint performs deep code analysis:</p> <pre><code># Run pylint\npylint src/\n\n# Check specific module\npylint src/apis/\n\n# Generate report\npylint src/ --output-format=json &gt; reports/pylint.json\n</code></pre> <p>Configuration in <code>.pylintrc</code>:</p> <pre><code>[MASTER]\nmax-line-length=100\ndisable=\n    C0111,  # missing-docstring\n    C0103,  # invalid-name\n    R0903,  # too-few-public-methods\n\n[MESSAGES CONTROL]\nconfidence=HIGH,INFERENCE\n\n[DESIGN]\nmax-args=7\nmax-attributes=10\nmax-locals=15\n</code></pre>"},{"location":"development/code-quality/#type-checking","title":"Type Checking","text":"<p>MyPy provides static type checking:</p> <pre><code># Run mypy\nmypy src/\n\n# Check specific module\nmypy src/apis/\n\n# Generate HTML report\nmypy src/ --html-report reports/mypy\n</code></pre> <p>Configuration in <code>mypy.ini</code>:</p> <pre><code>[mypy]\npython_version = 3.9\nwarn_return_any = True\nwarn_unused_configs = True\ndisallow_untyped_defs = True\ndisallow_incomplete_defs = True\ncheck_untyped_defs = True\nno_implicit_optional = True\n\n[mypy-tests.*]\nignore_errors = True\n</code></pre> <p>Type annotation examples:</p> <pre><code>from typing import List, Dict, Optional\nfrom datetime import datetime\n\ndef calculate_velocity(\n    commits: List[Dict[str, any]],\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -&gt; Dict[str, float]:\n    \"\"\"Calculate development velocity.\n\n    Args:\n        commits: List of commit dictionaries\n        start_date: Start of measurement period\n        end_date: End of measurement period (defaults to now)\n\n    Returns:\n        Dictionary with velocity metrics\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/code-quality/#security-scanning","title":"Security Scanning","text":"<p>Bandit scans for security issues:</p> <pre><code># Run bandit\nbandit -r src/\n\n# Generate JSON report\nbandit -r src/ -f json -o reports/bandit-report.json\n\n# Check specific severity\nbandit -r src/ -ll  # Only high severity\n</code></pre> <p>Safety checks dependencies:</p> <pre><code># Check for vulnerabilities\nsafety check\n\n# Check specific requirements file\nsafety check -r requirements.txt\n\n# Generate report\nsafety check --json &gt; reports/safety-report.json\n</code></pre>"},{"location":"development/code-quality/#javascripttypescript-code-quality","title":"JavaScript/TypeScript Code Quality","text":""},{"location":"development/code-quality/#code-formatting_1","title":"Code Formatting","text":"<p>Prettier formats JavaScript/TypeScript code:</p> <pre><code># Format frontend code\ncd src/frontend\nnpm run format\n\n# Check formatting\nnpm run format:check\n\n# Format specific file\nprettier --write src/components/Dashboard.tsx\n</code></pre> <p>Configuration in <code>.prettierrc</code>:</p> <pre><code>{\n  \"semi\": true,\n  \"trailingComma\": \"es5\",\n  \"singleQuote\": true,\n  \"printWidth\": 100,\n  \"tabWidth\": 2,\n  \"arrowParens\": \"avoid\"\n}\n</code></pre>"},{"location":"development/code-quality/#linting_1","title":"Linting","text":"<p>ESLint checks JavaScript/TypeScript code:</p> <pre><code># Run ESLint\ncd src/frontend\nnpm run lint\n\n# Fix auto-fixable issues\nnpm run lint:fix\n\n# Check specific file\neslint src/components/Dashboard.tsx\n</code></pre> <p>Configuration in <code>.eslintrc.json</code>:</p> <pre><code>{\n  \"extends\": [\n    \"react-app\",\n    \"react-app/jest\",\n    \"eslint:recommended\",\n    \"plugin:@typescript-eslint/recommended\"\n  ],\n  \"rules\": {\n    \"no-console\": \"warn\",\n    \"no-unused-vars\": \"error\",\n    \"@typescript-eslint/explicit-function-return-type\": \"off\",\n    \"@typescript-eslint/no-explicit-any\": \"warn\"\n  }\n}\n</code></pre>"},{"location":"development/code-quality/#type-checking_1","title":"Type Checking","text":"<p>TypeScript compiler checks types:</p> <pre><code># Type check\ncd src/frontend\nnpx tsc --noEmit\n\n# Watch mode\nnpx tsc --noEmit --watch\n</code></pre> <p>Configuration in <code>tsconfig.json</code>:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"es5\",\n    \"lib\": [\"dom\", \"dom.iterable\", \"esnext\"],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"esModuleInterop\": true,\n    \"allowSyntheticDefaultImports\": true,\n    \"strict\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"noEmit\": true,\n    \"jsx\": \"react-jsx\"\n  },\n  \"include\": [\"src\"]\n}\n</code></pre>"},{"location":"development/code-quality/#docker-quality","title":"Docker Quality","text":""},{"location":"development/code-quality/#dockerfile-linting","title":"Dockerfile Linting","text":"<p>Hadolint checks Dockerfiles:</p> <pre><code># Lint all Dockerfiles\nmake lint\n\n# Lint specific Dockerfile\ndocker run --rm -i hadolint/hadolint &lt; Dockerfile\n\n# Generate report\ndocker run --rm -i hadolint/hadolint --format json &lt; Dockerfile &gt; reports/hadolint.json\n</code></pre> <p>Best practices for Dockerfiles:</p> <ul> <li>Use specific image tags, not latest</li> <li>Minimize layer count</li> <li>Order commands by change frequency</li> <li>Use multi-stage builds</li> <li>Don't run as root user</li> <li>Clean up in same layer</li> <li>Use .dockerignore</li> </ul> <p>Example well-formatted Dockerfile:</p> <pre><code>FROM python:3.9-slim as base\n\nWORKDIR /app\n\n# Install dependencies first (cache layer)\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Run as non-root user\nRUN useradd -m appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8080/health || exit 1\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n</code></pre>"},{"location":"development/code-quality/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Pre-commit hooks ensure code quality before commits:</p> <pre><code># Install pre-commit\npip install pre-commit\n\n# Install hooks\nmake hooks-install\n\n# Run hooks manually\npre-commit run --all-files\n</code></pre> <p>Configuration in <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-json\n      - id: check-merge-conflict\n\n  - repo: https://github.com/psf/black\n    rev: 23.11.0\n    hooks:\n      - id: black\n        language_version: python3.9\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n        args: [\"--profile\", \"black\"]\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.1.0\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=100\"]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.7.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.5\n    hooks:\n      - id: bandit\n        args: [\"-c\", \"pyproject.toml\"]\n</code></pre>"},{"location":"development/code-quality/#code-review-process","title":"Code Review Process","text":""},{"location":"development/code-quality/#pull-request-requirements","title":"Pull Request Requirements","text":"<p>All code changes require:</p> <ol> <li> <p>Passing CI Checks</p> <ul> <li>All tests pass</li> <li>Code coverage meets threshold</li> <li>Linting passes</li> <li>Type checking passes</li> <li>Security scans pass</li> </ul> </li> <li> <p>Code Review Approval</p> <ul> <li>At least one reviewer approval</li> <li>No unresolved comments</li> <li>Changes address review feedback</li> </ul> </li> <li> <p>Documentation Updates</p> <ul> <li>API documentation updated</li> <li>README updated if needed</li> <li>Changelog entry added</li> <li>Architecture docs updated</li> </ul> </li> <li> <p>Testing Requirements</p> <ul> <li>New features have tests</li> <li>Bug fixes have regression tests</li> <li>Test coverage maintained or improved</li> </ul> </li> </ol>"},{"location":"development/code-quality/#review-checklist","title":"Review Checklist","text":"<p>Reviewers should verify:</p> <ul> <li>Code follows style guidelines</li> <li>Logic is clear and correct</li> <li>Error handling is appropriate</li> <li>Security considerations addressed</li> <li>Performance implications considered</li> <li>Documentation is complete</li> <li>Tests are comprehensive</li> <li>No hardcoded credentials or secrets</li> </ul>"},{"location":"development/code-quality/#code-review-best-practices","title":"Code Review Best Practices","text":"<p>For authors:</p> <ul> <li>Keep PRs small and focused</li> <li>Write clear PR descriptions</li> <li>Self-review before requesting review</li> <li>Respond to feedback promptly</li> <li>Update based on comments</li> </ul> <p>For reviewers:</p> <ul> <li>Review promptly (within 24 hours)</li> <li>Be constructive and specific</li> <li>Ask questions, don't demand</li> <li>Acknowledge good practices</li> <li>Test changes locally if needed</li> </ul>"},{"location":"development/code-quality/#continuous-integration-checks","title":"Continuous Integration Checks","text":""},{"location":"development/code-quality/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>CI pipeline runs on every push and PR:</p> <pre><code># .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [master, develop]\n  pull_request:\n    branches: [master, develop]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Run linters\n        run: make lint\n\n  type-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Run mypy\n        run: mypy src/\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Run tests\n        run: pytest --cov=src --cov-report=xml\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Run security checks\n        run: |\n          pip install safety bandit\n          safety check\n          bandit -r src/\n</code></pre>"},{"location":"development/code-quality/#required-status-checks","title":"Required Status Checks","text":"<p>Configure branch protection rules:</p> <ul> <li>Require status checks to pass before merging</li> <li>Require branches to be up to date</li> <li>Require linear history</li> <li>Do not allow bypassing rules</li> </ul> <p>Status checks required:</p> <ul> <li>lint</li> <li>type-check</li> <li>test</li> <li>security</li> <li>build</li> </ul>"},{"location":"development/code-quality/#code-metrics","title":"Code Metrics","text":""},{"location":"development/code-quality/#complexity-metrics","title":"Complexity Metrics","text":"<p>Monitor code complexity:</p> <pre><code># Calculate cyclomatic complexity\nradon cc src/ -a\n\n# Calculate maintainability index\nradon mi src/ -s\n\n# Generate HTML report\nradon cc src/ -a --total-average -o reports/complexity.html\n</code></pre> <p>Complexity thresholds:</p> <ul> <li>A (1-5): Simple, low risk</li> <li>B (6-10): Moderate complexity</li> <li>C (11-20): Complex, higher risk</li> <li>D (21-50): Very complex, test thoroughly</li> <li>F (50+): Extremely complex, consider refactoring</li> </ul>"},{"location":"development/code-quality/#code-coverage","title":"Code Coverage","text":"<p>Maintain high test coverage:</p> <pre><code># Generate coverage report\npytest --cov=src --cov-report=html --cov-report=term\n\n# View detailed report\nopen htmlcov/index.html\n\n# Check coverage threshold\npytest --cov=src --cov-fail-under=80\n</code></pre> <p>Coverage targets:</p> <ul> <li>Overall: 80% minimum</li> <li>Critical paths: 90%+ recommended</li> <li>New code: 100% for new features</li> <li>Bug fixes: Include regression test</li> </ul>"},{"location":"development/code-quality/#technical-debt","title":"Technical Debt","text":"<p>Track technical debt:</p> <ul> <li>Use TODO comments sparingly</li> <li>Create issues for known problems</li> <li>Regular refactoring sessions</li> <li>Address warnings and deprecations</li> <li>Update dependencies regularly</li> </ul>"},{"location":"development/code-quality/#best-practices","title":"Best Practices","text":""},{"location":"development/code-quality/#writing-clean-code","title":"Writing Clean Code","text":"<p>Follow these principles:</p> <ul> <li>Single Responsibility Principle</li> <li>Don't Repeat Yourself (DRY)</li> <li>Keep It Simple (KISS)</li> <li>Meaningful names</li> <li>Small functions (under 50 lines)</li> <li>Clear comments when needed</li> <li>Consistent error handling</li> </ul>"},{"location":"development/code-quality/#code-organization","title":"Code Organization","text":"<p>Maintain clean structure:</p> <ul> <li>Group related functionality</li> <li>Consistent file organization</li> <li>Clear module boundaries</li> <li>Avoid circular dependencies</li> <li>Use appropriate design patterns</li> </ul>"},{"location":"development/code-quality/#documentation","title":"Documentation","text":"<p>Document effectively:</p> <ul> <li>Docstrings for all public functions</li> <li>Type hints for parameters and returns</li> <li>Clear inline comments for complex logic</li> <li>README for each module</li> <li>API documentation auto-generated</li> </ul> <p>Example well-documented function:</p> <pre><code>def calculate_velocity(\n    commits: List[Dict[str, Any]],\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -&gt; Dict[str, float]:\n    \"\"\"Calculate development velocity metrics.\n\n    Analyzes commit data to compute velocity metrics including\n    commit frequency, code changes, and productivity trends.\n\n    Args:\n        commits: List of commit dictionaries with keys:\n            - date: Commit timestamp\n            - additions: Lines added\n            - deletions: Lines deleted\n        start_date: Start of measurement period\n        end_date: End of measurement period. Defaults to current time.\n\n    Returns:\n        Dictionary containing:\n            - total_commits: Number of commits\n            - total_changes: Sum of additions and deletions\n            - net_changes: Additions minus deletions\n            - avg_daily_commits: Average commits per day\n            - velocity_score: Normalized velocity metric\n\n    Raises:\n        ValueError: If start_date is after end_date\n        TypeError: If commits is not a list\n\n    Example:\n        &gt;&gt;&gt; commits = [\n        ...     {\"date\": \"2024-01-01\", \"additions\": 100, \"deletions\": 20},\n        ...     {\"date\": \"2024-01-02\", \"additions\": 50, \"deletions\": 10}\n        ... ]\n        &gt;&gt;&gt; result = calculate_velocity(commits, datetime(2024, 1, 1))\n        &gt;&gt;&gt; result[\"total_commits\"]\n        2\n    \"\"\"\n    if not isinstance(commits, list):\n        raise TypeError(\"commits must be a list\")\n\n    if end_date and start_date &gt; end_date:\n        raise ValueError(\"start_date must be before end_date\")\n\n    # Implementation here\n    pass\n</code></pre>"},{"location":"development/code-quality/#error-handling","title":"Error Handling","text":"<p>Handle errors consistently:</p> <ul> <li>Use specific exception types</li> <li>Log errors with context</li> <li>Provide helpful error messages</li> <li>Clean up resources properly</li> <li>Don't catch exceptions silently</li> </ul> <p>Example:</p> <pre><code>import logging\nfrom typing import Optional\n\nlogger = logging.getLogger(__name__)\n\ndef fetch_data(repo_id: str) -&gt; Optional[dict]:\n    \"\"\"Fetch repository data with proper error handling.\"\"\"\n    try:\n        response = api_client.get(f\"/repos/{repo_id}\")\n        response.raise_for_status()\n        return response.json()\n\n    except requests.HTTPError as e:\n        if e.response.status_code == 404:\n            logger.warning(f\"Repository not found: {repo_id}\")\n            return None\n        logger.error(f\"HTTP error fetching repo {repo_id}: {e}\")\n        raise\n\n    except requests.RequestException as e:\n        logger.error(f\"Network error fetching repo {repo_id}: {e}\")\n        raise\n\n    except json.JSONDecodeError as e:\n        logger.error(f\"Invalid JSON response for repo {repo_id}: {e}\")\n        raise\n\n    finally:\n        # Cleanup if needed\n        pass\n</code></pre>"},{"location":"development/code-quality/#automated-quality-gates","title":"Automated Quality Gates","text":""},{"location":"development/code-quality/#quality-metrics-thresholds","title":"Quality Metrics Thresholds","text":"<p>Enforce quality standards:</p> <ul> <li>Code coverage: 80% minimum</li> <li>Complexity: A-B rating required</li> <li>Linting: Zero errors</li> <li>Type coverage: 90% minimum</li> <li>Security: No high/critical issues</li> <li>Duplication: Under 5%</li> </ul>"},{"location":"development/code-quality/#fail-fast-strategy","title":"Fail Fast Strategy","text":"<p>Stop builds on quality issues:</p> <ul> <li>Failed tests block merge</li> <li>Linting errors prevent deployment</li> <li>Security vulnerabilities block release</li> <li>Coverage drops rejected</li> <li>Type errors must be fixed</li> </ul>"},{"location":"development/code-quality/#quality-dashboard","title":"Quality Dashboard","text":"<p>Monitor quality metrics:</p> <ul> <li>Code coverage trends</li> <li>Complexity over time</li> <li>Technical debt tracking</li> <li>Security vulnerability count</li> <li>Test execution time</li> <li>Build success rate</li> </ul> <p>Tools for monitoring:</p> <ul> <li>SonarQube for code quality</li> <li>Codecov for coverage tracking</li> <li>Dependabot for dependency updates</li> <li>GitHub Security for vulnerability alerts</li> </ul>"},{"location":"development/environment-setup/","title":"Development Environment Setup","text":""},{"location":"development/environment-setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Docker (20.10+) and Docker Compose (2.0+)</li> <li>Git (2.30+)</li> <li>Python (3.11+) - for local development</li> <li>Node.js (18+) and npm (9+) - for frontend development</li> <li>Make - for using Makefile commands</li> </ul>"},{"location":"development/environment-setup/#quick-start","title":"Quick Start","text":""},{"location":"development/environment-setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/rcdelacruz/open-source-sei-platform.git\ncd open-source-sei-platform\n</code></pre>"},{"location":"development/environment-setup/#2-create-environment-file","title":"2. Create Environment File","text":"<pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> and configure your API tokens:</p> <ul> <li><code>GITHUB_TOKEN</code> - Your GitHub Personal Access Token</li> <li><code>GITLAB_TOKEN</code> - Your GitLab Access Token (if using GitLab)</li> <li><code>JIRA_API_TOKEN</code> - Your Jira API Token (if using Jira)</li> </ul>"},{"location":"development/environment-setup/#3-start-the-development-environment","title":"3. Start the Development Environment","text":"<p>Using Make (recommended):</p> <pre><code>make dev\n</code></pre> <p>Or using Docker Compose directly:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"development/environment-setup/#4-verify-services-are-running","title":"4. Verify Services are Running","text":"<p>Check service status:</p> <pre><code>docker-compose ps\n</code></pre> <p>All services should show <code>Up</code> or <code>Up (healthy)</code> status.</p>"},{"location":"development/environment-setup/#5-access-the-services","title":"5. Access the Services","text":"<p>Once all services are running, you can access:</p> Service URL Credentials API Documentation http://localhost:8080/docs N/A API Service http://localhost:8080 N/A Frontend (Dev) http://localhost:3002 N/A Metabase (BI) http://localhost:3000 Setup on first access Grafana http://localhost:3001 admin / admin123 Airflow http://localhost:8082 admin / admin123 Kafka UI http://localhost:8083 N/A PgAdmin http://localhost:8084 admin@sei.com / admin123"},{"location":"development/environment-setup/#6-check-api-health","title":"6. Check API Health","text":"<p>Test that the API is responding:</p> <pre><code>curl http://localhost:8080/health\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"api-service\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-09-30T10:00:00.000000\"\n}\n</code></pre> <p>Check readiness (includes database connectivity):</p> <pre><code>curl http://localhost:8080/ready\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"ready\": true,\n  \"checks\": {\n    \"postgres\": \"healthy\",\n    \"timescaledb\": \"healthy\"\n  }\n}\n</code></pre>"},{"location":"development/environment-setup/#service-architecture","title":"Service Architecture","text":"<p>The development environment includes the following services:</p>"},{"location":"development/environment-setup/#core-services","title":"Core Services","text":"<ol> <li> <p>API Service (<code>api-service</code>)</p> <ul> <li>Main REST API built with FastAPI</li> <li>Port: 8080</li> <li>Provides CRUD operations for organizations, teams, repositories, developers</li> <li>Serves analytics endpoints for DORA metrics and team performance</li> </ul> </li> <li> <p>Git Collector (<code>git-collector</code>)</p> <ul> <li>Collects data from GitHub, GitLab, Bitbucket</li> <li>Port: 8000</li> <li>Polls repositories for commits, pull requests, and issues</li> </ul> </li> <li> <p>Jira Collector (<code>jira-collector</code>)</p> <ul> <li>Collects data from Jira and other project management tools</li> <li>Port: 8001</li> <li>Syncs issues, sprints, and project data</li> </ul> </li> <li> <p>Data Processor (<code>data-processor</code>)</p> <ul> <li>Processes raw events from Kafka</li> <li>Transforms and stores data in TimescaleDB</li> <li>Port: 8002</li> </ul> </li> </ol>"},{"location":"development/environment-setup/#data-storage","title":"Data Storage","text":"<ol> <li> <p>TimescaleDB (<code>timescaledb</code>)</p> <ul> <li>Time-series database for metrics and events</li> <li>Port: 5432</li> <li>Database: <code>sei_platform</code></li> <li>User: <code>sei_user</code> / Password: <code>sei_password</code></li> </ul> </li> <li> <p>PostgreSQL (<code>postgresql</code>)</p> <ul> <li>Relational database for metadata</li> <li>Port: 5433 (mapped to avoid conflict)</li> <li>Database: <code>sei_metadata</code></li> <li>User: <code>sei_user</code> / Password: <code>sei_password</code></li> </ul> </li> <li> <p>Redis (<code>redis</code>)</p> <ul> <li>Cache and session storage</li> <li>Port: 6379</li> </ul> </li> <li> <p>Kafka + Zookeeper (<code>kafka</code>, <code>zookeeper</code>)</p> <ul> <li>Event streaming and message queue</li> <li>Kafka Port: 9092, 29092</li> <li>Zookeeper Port: 2181</li> </ul> </li> </ol>"},{"location":"development/environment-setup/#analytics-monitoring","title":"Analytics &amp; Monitoring","text":"<ol> <li> <p>Metabase (<code>metabase</code>)</p> <ul> <li>Self-service BI tool</li> <li>Port: 3000</li> </ul> </li> <li> <p>Prometheus (<code>prometheus</code>)</p> <ul> <li>Metrics collection</li> <li>Port: 9090</li> </ul> </li> <li> <p>Grafana (<code>grafana</code>)</p> <ul> <li>Dashboards and visualization</li> <li>Port: 3001</li> </ul> </li> <li> <p>Apache Airflow (<code>airflow-webserver</code>, <code>airflow-scheduler</code>)</p> <ul> <li>Workflow orchestration</li> <li>Port: 8082</li> </ul> </li> </ol>"},{"location":"development/environment-setup/#development-tools","title":"Development Tools","text":"<ol> <li> <p>Kafka UI (<code>kafka-ui</code>)</p> <ul> <li>Web interface for Kafka</li> <li>Port: 8083</li> </ul> </li> <li> <p>PgAdmin (<code>pgadmin</code>)</p> <ul> <li>PostgreSQL administration</li> <li>Port: 8084</li> </ul> </li> </ol>"},{"location":"development/environment-setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development/environment-setup/#building-services","title":"Building Services","text":"<p>Build all services:</p> <pre><code>make build\n# or\ndocker-compose build\n</code></pre> <p>Build a specific service:</p> <pre><code>docker-compose build api-service\n</code></pre>"},{"location":"development/environment-setup/#viewing-logs","title":"Viewing Logs","text":"<p>View logs from all services:</p> <pre><code>make dev-logs\n# or\ndocker-compose logs -f\n</code></pre> <p>View logs from a specific service:</p> <pre><code>docker-compose logs -f api-service\n</code></pre> <p>View logs from specific service groups:</p> <pre><code>make logs-api          # API service logs\nmake logs-collectors   # Data collector logs\nmake logs-processors   # Data processor logs\n</code></pre>"},{"location":"development/environment-setup/#stopping-services","title":"Stopping Services","text":"<p>Stop all services:</p> <pre><code>make dev-stop\n# or\ndocker-compose down\n</code></pre> <p>Stop and remove volumes (WARNING: This deletes all data):</p> <pre><code>docker-compose down -v\n</code></pre>"},{"location":"development/environment-setup/#restarting-services","title":"Restarting Services","text":"<p>Restart all services:</p> <pre><code>make dev-restart\n# or\ndocker-compose restart\n</code></pre> <p>Restart a specific service:</p> <pre><code>docker-compose restart api-service\n</code></pre>"},{"location":"development/environment-setup/#database-access","title":"Database Access","text":""},{"location":"development/environment-setup/#postgresql-metadata","title":"PostgreSQL (Metadata)","text":"<p>Using psql:</p> <pre><code>docker-compose exec postgresql psql -U sei_user -d sei_metadata\n</code></pre> <p>Using PgAdmin:</p> <ol> <li>Navigate to http://localhost:8084</li> <li>Login with <code>admin@sei.com</code> / <code>admin123</code></li> <li>Add server:<ul> <li>Host: <code>postgresql</code> (or <code>host.docker.internal</code> from host machine)</li> <li>Port: <code>5432</code></li> <li>Database: <code>sei_metadata</code></li> <li>User: <code>sei_user</code></li> <li>Password: <code>sei_password</code></li> </ul> </li> </ol>"},{"location":"development/environment-setup/#timescaledb-time-series-data","title":"TimescaleDB (Time-series Data)","text":"<p>Using psql:</p> <pre><code>docker-compose exec timescaledb psql -U sei_user -d sei_platform\n</code></pre>"},{"location":"development/environment-setup/#redis","title":"Redis","text":"<p>Using redis-cli:</p> <pre><code>docker-compose exec redis redis-cli\n</code></pre>"},{"location":"development/environment-setup/#running-tests","title":"Running Tests","text":"<p>Run all tests:</p> <pre><code>make test\n</code></pre> <p>Run specific test suites:</p> <pre><code>make test-unit          # Unit tests only\nmake test-integration   # Integration tests only\nmake test-e2e          # End-to-end tests\n</code></pre>"},{"location":"development/environment-setup/#code-quality","title":"Code Quality","text":"<p>Run linters:</p> <pre><code>make lint\n</code></pre> <p>Format code:</p> <pre><code>make format\n</code></pre> <p>Run security scans:</p> <pre><code>make security\n</code></pre>"},{"location":"development/environment-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/environment-setup/#services-wont-start","title":"Services won't start","text":"<ol> <li> <p>Check if ports are already in use:</p> <pre><code>lsof -i :8080  # Check API port\nlsof -i :5432  # Check TimescaleDB port\n</code></pre> </li> <li> <p>Check Docker resources (ensure you have enough memory):</p> <pre><code>docker system df\n</code></pre> </li> <li> <p>View service logs for errors:</p> <pre><code>docker-compose logs api-service\n</code></pre> </li> </ol>"},{"location":"development/environment-setup/#database-connection-errors","title":"Database connection errors","text":"<ol> <li> <p>Ensure databases are running:</p> <pre><code>docker-compose ps postgresql timescaledb\n</code></pre> </li> <li> <p>Check database logs:</p> <pre><code>docker-compose logs postgresql\ndocker-compose logs timescaledb\n</code></pre> </li> <li> <p>Test database connectivity:</p> <pre><code>curl http://localhost:8080/ready\n</code></pre> </li> </ol>"},{"location":"development/environment-setup/#port-conflicts","title":"Port conflicts","text":"<p>If you have port conflicts, you can modify the ports in <code>docker-compose.yml</code>. For example, to change the API port from 8080 to 8888:</p> <pre><code>api-service:\n  ports:\n    - \"8888:8080\"  # Change external port\n</code></pre>"},{"location":"development/environment-setup/#clean-slate","title":"Clean slate","text":"<p>To completely reset the environment:</p> <pre><code>make reset\n# or\nmake clean\nmake clean-builds\nmake install\nmake dev\n</code></pre>"},{"location":"development/environment-setup/#next-steps","title":"Next Steps","text":"<p>After setting up the development environment:</p> <ol> <li>Review the API Documentation: http://localhost:8080/docs</li> <li>Set up integrations: Configure GitHub, GitLab, or Jira tokens in <code>.env</code></li> <li>Read the Architecture docs: <code>docs/architecture.md</code></li> <li>Check the Roadmap: <code>docs/ROADMAP.md</code></li> <li>Contributing: Read <code>docs/CONTRIBUTING.md</code></li> </ol>"},{"location":"development/environment-setup/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: <code>docs/</code></li> <li>Issues: https://github.com/rcdelacruz/open-source-sei-platform/issues</li> <li>Discussions: https://github.com/rcdelacruz/open-source-sei-platform/discussions</li> </ul> <p>Happy coding!</p>"},{"location":"development/project-structure/","title":"Project Structure","text":"<p>This document describes the organization and structure of the SEI Platform repository.</p>"},{"location":"development/project-structure/#repository-overview","title":"Repository Overview","text":"<p>The SEI Platform follows a service-oriented architecture with clear separation between data collection, processing, API services, and frontend components.</p> <pre><code>sei-platform/\n\u251c\u2500\u2500 src/                    # Source code\n\u2502   \u251c\u2500\u2500 apis/              # API services\n\u2502   \u251c\u2500\u2500 collectors/        # Data collectors\n\u2502   \u251c\u2500\u2500 processors/        # Data processors\n\u2502   \u251c\u2500\u2500 frontend/          # React frontend\n\u2502   \u2514\u2500\u2500 workflows/         # Airflow DAGs\n\u251c\u2500\u2500 config/                # Configuration files\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 k8s/                   # Kubernetes manifests\n\u251c\u2500\u2500 scripts/               # Utility scripts\n\u2514\u2500\u2500 tests/                 # Test suites\n</code></pre>"},{"location":"development/project-structure/#directory-structure","title":"Directory Structure","text":""},{"location":"development/project-structure/#source-code-src","title":"Source Code (<code>src/</code>)","text":"<p>The <code>src/</code> directory contains all application source code organized by service type.</p>"},{"location":"development/project-structure/#api-services-srcapis","title":"API Services (<code>src/apis/</code>)","text":"<p>RESTful API services built with FastAPI:</p> <ul> <li><code>main.py</code> - FastAPI application entry point</li> <li><code>config.py</code> - Configuration management</li> <li><code>database.py</code> - Database connection handling</li> <li><code>routes/</code> - API endpoint definitions<ul> <li><code>health.py</code> - Health check endpoints</li> <li><code>organizations.py</code> - Organization management</li> <li><code>teams.py</code> - Team management</li> <li><code>developers.py</code> - Developer metrics</li> <li><code>repositories.py</code> - Repository analytics</li> <li><code>analytics.py</code> - Analytics endpoints</li> </ul> </li> <li><code>models/</code> - SQLAlchemy models</li> <li><code>schemas/</code> - Pydantic schemas for validation</li> <li><code>services/</code> - Business logic layer</li> <li><code>Dockerfile</code> - Container image definition</li> <li><code>requirements.txt</code> - Python dependencies</li> </ul>"},{"location":"development/project-structure/#data-collectors-srccollectors","title":"Data Collectors (<code>src/collectors/</code>)","text":"<p>Services that collect data from external sources:</p> <p>Git Collector (<code>src/collectors/git/</code>)</p> <ul> <li><code>main.py</code> - Collector service entry point</li> <li><code>config.py</code> - Git-specific configuration</li> <li><code>routes/</code> - Collector API endpoints<ul> <li><code>health.py</code> - Health check</li> <li><code>collector.py</code> - Collection triggers</li> </ul> </li> <li><code>services/</code> - Git data collection logic</li> <li><code>models/</code> - Data models for Git entities</li> <li><code>Dockerfile</code> - Container image definition</li> </ul> <p>Jira Collector (<code>src/collectors/jira/</code>)</p> <ul> <li><code>main.py</code> - Collector service entry point</li> <li><code>config.py</code> - Jira-specific configuration</li> <li><code>routes/</code> - Collector API endpoints</li> <li><code>services/</code> - Jira data collection logic</li> <li><code>models/</code> - Data models for Jira entities</li> <li><code>Dockerfile</code> - Container image definition</li> </ul>"},{"location":"development/project-structure/#data-processors-srcprocessors","title":"Data Processors (<code>src/processors/</code>)","text":"<p>Services that process and transform collected data:</p> <ul> <li><code>main.py</code> - Processor entry point</li> <li><code>config.py</code> - Processor configuration</li> <li><code>routes/</code> - Processing API endpoints</li> <li><code>processors/</code> - Data processing logic<ul> <li><code>velocity.py</code> - Velocity calculations</li> <li><code>quality.py</code> - Code quality metrics</li> <li><code>collaboration.py</code> - Collaboration metrics</li> <li><code>flow.py</code> - Development flow metrics</li> </ul> </li> <li><code>Dockerfile</code> - Container image definition</li> </ul>"},{"location":"development/project-structure/#frontend-srcfrontend","title":"Frontend (<code>src/frontend/</code>)","text":"<p>React-based web application:</p> <ul> <li><code>public/</code> - Static assets</li> <li><code>src/</code> - React application source<ul> <li><code>components/</code> - Reusable React components</li> <li><code>pages/</code> - Page-level components</li> <li><code>hooks/</code> - Custom React hooks</li> <li><code>services/</code> - API client services</li> <li><code>utils/</code> - Utility functions</li> <li><code>types/</code> - TypeScript type definitions</li> </ul> </li> <li><code>package.json</code> - Node.js dependencies</li> <li><code>tsconfig.json</code> - TypeScript configuration</li> <li><code>Dockerfile.dev</code> - Development container</li> <li><code>Dockerfile.prod</code> - Production container</li> </ul>"},{"location":"development/project-structure/#workflows-srcworkflows","title":"Workflows (<code>src/workflows/</code>)","text":"<p>Apache Airflow DAGs for orchestration:</p> <ul> <li><code>dags/</code> - Airflow DAG definitions<ul> <li><code>data_collection.py</code> - Collection workflows</li> <li><code>data_processing.py</code> - Processing workflows</li> <li><code>data_export.py</code> - Export workflows</li> </ul> </li> <li><code>plugins/</code> - Custom Airflow plugins</li> <li><code>logs/</code> - Airflow execution logs</li> </ul>"},{"location":"development/project-structure/#configuration-config","title":"Configuration (<code>config/</code>)","text":"<p>Environment-specific configuration files:</p> <ul> <li><code>prometheus.yml</code> - Prometheus monitoring configuration</li> <li><code>kong.yml</code> - API gateway configuration</li> <li><code>grafana/</code> - Grafana dashboards and provisioning</li> <li><code>dev.env.example</code> - Development environment template</li> <li><code>prod.env.example</code> - Production environment template</li> </ul>"},{"location":"development/project-structure/#documentation-docs","title":"Documentation (<code>docs/</code>)","text":"<p>Project documentation in Markdown format:</p> <ul> <li><code>getting-started/</code> - Quick start guides</li> <li><code>architecture/</code> - System architecture</li> <li><code>development/</code> - Development guides</li> <li><code>deployment/</code> - Deployment instructions</li> <li><code>api/</code> - API reference documentation</li> <li><code>contributing/</code> - Contribution guidelines</li> </ul>"},{"location":"development/project-structure/#kubernetes-k8s","title":"Kubernetes (<code>k8s/</code>)","text":"<p>Kubernetes deployment manifests:</p> <ul> <li><code>namespace.yaml</code> - Namespace definition</li> <li><code>configmaps/</code> - Configuration maps</li> <li><code>secrets/</code> - Secret definitions</li> <li><code>deployments/</code> - Deployment manifests</li> <li><code>services/</code> - Service definitions</li> <li><code>ingress/</code> - Ingress rules</li> <li><code>staging/</code> - Staging environment</li> <li><code>production/</code> - Production environment</li> </ul>"},{"location":"development/project-structure/#scripts-scripts","title":"Scripts (<code>scripts/</code>)","text":"<p>Utility and automation scripts:</p> <ul> <li><code>init-timescaledb.sql</code> - TimescaleDB initialization</li> <li><code>init-postgresql.sql</code> - PostgreSQL initialization</li> <li><code>backup-databases.sh</code> - Database backup script</li> <li><code>restore-databases.sh</code> - Database restore script</li> <li><code>generate-config.py</code> - Configuration generator</li> <li><code>export-data.py</code> - Data export utility</li> </ul>"},{"location":"development/project-structure/#tests-tests","title":"Tests (<code>tests/</code>)","text":"<p>Comprehensive test suites:</p> <ul> <li><code>unit/</code> - Unit tests</li> <li><code>integration/</code> - Integration tests</li> <li><code>e2e/</code> - End-to-end tests</li> <li><code>load/</code> - Load and performance tests</li> <li><code>fixtures/</code> - Test fixtures and data</li> <li><code>conftest.py</code> - Pytest configuration</li> </ul>"},{"location":"development/project-structure/#file-naming-conventions","title":"File Naming Conventions","text":""},{"location":"development/project-structure/#python-files","title":"Python Files","text":"<p>Follow PEP 8 naming conventions:</p> <ul> <li>Module names: lowercase with underscores (e.g., <code>data_processor.py</code>)</li> <li>Class names: PascalCase (e.g., <code>DataProcessor</code>)</li> <li>Function names: lowercase with underscores (e.g., <code>process_data</code>)</li> <li>Constants: uppercase with underscores (e.g., <code>MAX_RETRIES</code>)</li> </ul>"},{"location":"development/project-structure/#typescriptjavascript-files","title":"TypeScript/JavaScript Files","text":"<p>Follow standard JavaScript conventions:</p> <ul> <li>Component files: PascalCase (e.g., <code>Dashboard.tsx</code>)</li> <li>Utility files: camelCase (e.g., <code>apiClient.ts</code>)</li> <li>Hook files: camelCase with prefix (e.g., <code>useAuth.ts</code>)</li> <li>Type definition files: PascalCase (e.g., <code>User.types.ts</code>)</li> </ul>"},{"location":"development/project-structure/#configuration-files","title":"Configuration Files","text":"<p>Use descriptive names with appropriate extensions:</p> <ul> <li>YAML files: <code>.yml</code> or <code>.yaml</code></li> <li>Environment files: <code>.env</code> or <code>.env.example</code></li> <li>JSON files: <code>.json</code></li> <li>Docker files: <code>Dockerfile</code> or <code>Dockerfile.&lt;env&gt;</code></li> </ul>"},{"location":"development/project-structure/#code-organization-principles","title":"Code Organization Principles","text":""},{"location":"development/project-structure/#separation-of-concerns","title":"Separation of Concerns","text":"<p>Each service maintains clear boundaries:</p> <ul> <li>Collectors: Data ingestion only</li> <li>Processors: Data transformation only</li> <li>APIs: Data access and business logic</li> <li>Frontend: User interface and interaction</li> </ul>"},{"location":"development/project-structure/#dependency-flow","title":"Dependency Flow","text":"<p>Services follow a unidirectional data flow:</p> <pre><code>Collectors \u2192 Kafka \u2192 Processors \u2192 TimescaleDB \u2192 APIs \u2192 Frontend\n</code></pre>"},{"location":"development/project-structure/#configuration-management","title":"Configuration Management","text":"<p>Configuration follows the 12-factor app methodology:</p> <ul> <li>Environment variables for configuration</li> <li>Separate config files per environment</li> <li>No secrets in source code</li> <li>Default values with overrides</li> </ul>"},{"location":"development/project-structure/#module-independence","title":"Module Independence","text":"<p>Each service can be:</p> <ul> <li>Developed independently</li> <li>Tested independently</li> <li>Deployed independently</li> <li>Scaled independently</li> </ul>"},{"location":"development/project-structure/#shared-code","title":"Shared Code","text":"<p>Common code is organized into reusable modules:</p> <ul> <li>Database models shared via packages</li> <li>Utility functions in dedicated modules</li> <li>Schemas defined once, used everywhere</li> <li>Types exported and imported as needed</li> </ul>"},{"location":"development/project-structure/#service-dependencies","title":"Service Dependencies","text":""},{"location":"development/project-structure/#api-service","title":"API Service","text":"<p>Dependencies:</p> <ul> <li>TimescaleDB (primary data store)</li> <li>PostgreSQL (metadata store)</li> <li>Redis (caching layer)</li> </ul>"},{"location":"development/project-structure/#collectors","title":"Collectors","text":"<p>Dependencies:</p> <ul> <li>Kafka (message queue)</li> <li>Redis (state management)</li> <li>External APIs (data sources)</li> </ul>"},{"location":"development/project-structure/#processors","title":"Processors","text":"<p>Dependencies:</p> <ul> <li>Kafka (message consumption)</li> <li>TimescaleDB (data storage)</li> <li>Redis (coordination)</li> </ul>"},{"location":"development/project-structure/#frontend","title":"Frontend","text":"<p>Dependencies:</p> <ul> <li>API Service (data access)</li> <li>WebSocket connection (real-time updates)</li> </ul>"},{"location":"development/project-structure/#development-workflow","title":"Development Workflow","text":""},{"location":"development/project-structure/#adding-new-features","title":"Adding New Features","text":"<p>When adding features, follow this structure:</p> <ol> <li>Create feature branch from master</li> <li>Add code in appropriate service directory</li> <li>Add tests in corresponding test directory</li> <li>Update documentation in docs directory</li> <li>Update configuration if needed</li> <li>Submit pull request for review</li> </ol>"},{"location":"development/project-structure/#adding-new-services","title":"Adding New Services","text":"<p>For new services:</p> <ol> <li>Create service directory under <code>src/</code></li> <li>Add Dockerfile for containerization</li> <li>Add to docker-compose.yml for local development</li> <li>Create Kubernetes manifests in <code>k8s/</code></li> <li>Add Makefile targets for common operations</li> <li>Document service in architecture docs</li> </ol>"},{"location":"development/project-structure/#modifying-existing-services","title":"Modifying Existing Services","text":"<p>When modifying services:</p> <ol> <li>Update source code in service directory</li> <li>Update tests to match changes</li> <li>Update schemas if data models change</li> <li>Update API documentation if endpoints change</li> <li>Update migrations if database changes</li> <li>Update dependencies if required</li> </ol>"},{"location":"development/project-structure/#best-practices","title":"Best Practices","text":""},{"location":"development/project-structure/#keep-services-focused","title":"Keep Services Focused","text":"<p>Each service should have a single, well-defined responsibility:</p> <ul> <li>Avoid mixing concerns across service boundaries</li> <li>Use message queues for inter-service communication</li> <li>Maintain clear API contracts</li> </ul>"},{"location":"development/project-structure/#maintain-clean-boundaries","title":"Maintain Clean Boundaries","text":"<p>Organize code to maintain clear separation:</p> <ul> <li>Business logic in service layer</li> <li>Data access in repository layer</li> <li>Validation in schema layer</li> <li>Routing in route layer</li> </ul>"},{"location":"development/project-structure/#use-consistent-structure","title":"Use Consistent Structure","text":"<p>Follow established patterns:</p> <ul> <li>All services use similar directory structure</li> <li>Common patterns for error handling</li> <li>Consistent logging and monitoring</li> <li>Shared coding standards</li> </ul>"},{"location":"development/project-structure/#document-as-you-go","title":"Document As You Go","text":"<p>Keep documentation synchronized:</p> <ul> <li>Update docs when changing features</li> <li>Add comments for complex logic</li> <li>Maintain API documentation</li> <li>Document configuration options</li> </ul>"},{"location":"development/running-services/","title":"Running Services","text":"<p>This guide explains how to run SEI Platform services locally for development and debugging.</p>"},{"location":"development/running-services/#prerequisites","title":"Prerequisites","text":"<p>Before running services, ensure you have:</p> <ul> <li>Docker and Docker Compose installed</li> <li>Make utility installed</li> <li>Python 3.9+ installed</li> <li>Node.js 16+ installed</li> <li>At least 8GB RAM available</li> <li>Ports 3000-3002, 5432-5433, 6379, 8000-8001, 8080-8084, 9090, 9092 available</li> </ul>"},{"location":"development/running-services/#quick-start","title":"Quick Start","text":"<p>Start all services with a single command:</p> <pre><code>make dev\n</code></pre> <p>This command will:</p> <ul> <li>Build all Docker images</li> <li>Start all services in containers</li> <li>Initialize databases</li> <li>Wait for services to be ready</li> <li>Display service URLs</li> </ul> <p>Services will be available at:</p> <ul> <li>Frontend: http://localhost:3002</li> <li>API: http://localhost:8080</li> <li>Metabase: http://localhost:3000</li> <li>Grafana: http://localhost:3001</li> <li>Airflow: http://localhost:8082</li> <li>Kafka UI: http://localhost:8083</li> <li>PgAdmin: http://localhost:8084</li> </ul>"},{"location":"development/running-services/#running-individual-services","title":"Running Individual Services","text":""},{"location":"development/running-services/#api-service","title":"API Service","text":"<p>Run the API service standalone:</p> <pre><code># Using Docker Compose\ndocker-compose up api-service\n\n# Without Docker (requires databases running)\ncd src/apis\npip install -r requirements.txt\nuvicorn main:app --reload --host 0.0.0.0 --port 8080\n</code></pre> <p>The API will be available at http://localhost:8080 with interactive documentation at http://localhost:8080/docs.</p>"},{"location":"development/running-services/#git-collector","title":"Git Collector","text":"<p>Run the Git collector service:</p> <pre><code># Using Docker Compose\ndocker-compose up git-collector\n\n# Without Docker\ncd src/collectors/git\npip install -r requirements.txt\npython main.py\n</code></pre>"},{"location":"development/running-services/#jira-collector","title":"Jira Collector","text":"<p>Run the Jira collector service:</p> <pre><code># Using Docker Compose\ndocker-compose up jira-collector\n\n# Without Docker\ncd src/collectors/jira\npip install -r requirements.txt\npython main.py\n</code></pre>"},{"location":"development/running-services/#data-processor","title":"Data Processor","text":"<p>Run the data processor service:</p> <pre><code># Using Docker Compose\ndocker-compose up data-processor\n\n# Without Docker\ncd src/processors\npip install -r requirements.txt\npython main.py\n</code></pre>"},{"location":"development/running-services/#frontend-development-server","title":"Frontend Development Server","text":"<p>Run the frontend in development mode:</p> <pre><code># Using Docker Compose\ndocker-compose up frontend-dev\n\n# Without Docker\ncd src/frontend\nnpm install\nnpm start\n</code></pre> <p>The development server will be available at http://localhost:3002 with hot module reloading enabled.</p>"},{"location":"development/running-services/#running-infrastructure-services","title":"Running Infrastructure Services","text":""},{"location":"development/running-services/#database-services","title":"Database Services","text":"<p>Start only the database services:</p> <pre><code># TimescaleDB (primary data store)\ndocker-compose up -d timescaledb\n\n# PostgreSQL (metadata store)\ndocker-compose up -d postgresql\n</code></pre> <p>Connect to databases:</p> <pre><code># TimescaleDB\npsql -h localhost -p 5432 -U sei_user -d sei_platform\n\n# PostgreSQL\npsql -h localhost -p 5433 -U sei_user -d sei_metadata\n</code></pre>"},{"location":"development/running-services/#message-queue","title":"Message Queue","text":"<p>Start Kafka and Zookeeper:</p> <pre><code>docker-compose up -d zookeeper kafka\n</code></pre> <p>Verify Kafka is running:</p> <pre><code># Using Kafka UI\nopen http://localhost:8083\n\n# Using command line\ndocker exec sei-kafka kafka-topics --list --bootstrap-server localhost:9092\n</code></pre>"},{"location":"development/running-services/#cache-service","title":"Cache Service","text":"<p>Start Redis:</p> <pre><code>docker-compose up -d redis\n</code></pre> <p>Connect to Redis:</p> <pre><code># Using redis-cli\ndocker exec -it sei-redis redis-cli\n\n# Using make target\nmake shell-redis\n</code></pre>"},{"location":"development/running-services/#service-dependencies","title":"Service Dependencies","text":"<p>Services must be started in the correct order to satisfy dependencies:</p> <ol> <li> <p>Infrastructure Services</p> <ul> <li>Zookeeper</li> <li>Kafka</li> <li>Redis</li> <li>TimescaleDB</li> <li>PostgreSQL</li> </ul> </li> <li> <p>Collection Services</p> <ul> <li>Git Collector (requires Kafka, Redis)</li> <li>Jira Collector (requires Kafka, Redis)</li> </ul> </li> <li> <p>Processing Services</p> <ul> <li>Data Processor (requires Kafka, TimescaleDB, Redis)</li> </ul> </li> <li> <p>API Services</p> <ul> <li>API Service (requires TimescaleDB, PostgreSQL, Redis)</li> </ul> </li> <li> <p>Frontend Services</p> <ul> <li>Frontend (requires API Service)</li> </ul> </li> </ol> <p>Docker Compose handles these dependencies automatically through the <code>depends_on</code> configuration.</p>"},{"location":"development/running-services/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/running-services/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file from the example:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit the <code>.env</code> file to configure:</p> <ul> <li>Database connection strings</li> <li>API keys for external services</li> <li>Service-specific settings</li> <li>Feature flags</li> </ul> <p>Common environment variables:</p> <ul> <li><code>KAFKA_BROKERS</code> - Kafka broker addresses</li> <li><code>REDIS_URL</code> - Redis connection URL</li> <li><code>TIMESCALE_URL</code> - TimescaleDB connection URL</li> <li><code>POSTGRES_URL</code> - PostgreSQL connection URL</li> <li><code>LOG_LEVEL</code> - Logging level (DEBUG, INFO, WARNING, ERROR)</li> <li><code>GITHUB_TOKEN</code> - GitHub API token for Git collector</li> <li><code>JIRA_URL</code> - Jira instance URL</li> <li><code>JIRA_TOKEN</code> - Jira API token</li> </ul>"},{"location":"development/running-services/#configuration-files","title":"Configuration Files","text":"<p>Services use configuration files in the <code>config/</code> directory:</p> <ul> <li><code>config/prometheus.yml</code> - Prometheus monitoring</li> <li><code>config/kong.yml</code> - API gateway routing</li> <li><code>config/grafana/</code> - Grafana dashboards</li> </ul> <p>Override configuration by:</p> <ul> <li>Setting environment variables</li> <li>Mounting custom config files as volumes</li> <li>Using Docker Compose override files</li> </ul>"},{"location":"development/running-services/#development-vs-production","title":"Development vs Production","text":"<p>Use different configuration for environments:</p> <pre><code># Development\nmake config-dev\n\n# Production\nmake config-prod\n</code></pre>"},{"location":"development/running-services/#hot-reloading-and-development-mode","title":"Hot Reloading and Development Mode","text":""},{"location":"development/running-services/#python-services","title":"Python Services","text":"<p>Python services use uvicorn with the <code>--reload</code> flag for automatic reloading:</p> <pre><code># In main.py\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8080, reload=True)\n</code></pre> <p>Changes to Python files will automatically restart the service.</p>"},{"location":"development/running-services/#frontend-development","title":"Frontend Development","text":"<p>The frontend uses Create React App's development server with hot module replacement:</p> <pre><code>npm start\n</code></pre> <p>Changes to React components will update in the browser without full page reload.</p>"},{"location":"development/running-services/#volume-mounts","title":"Volume Mounts","text":"<p>Docker Compose mounts source code as volumes for hot reloading:</p> <pre><code>volumes:\n  - ./src/apis:/app\n  - ./src/frontend:/app\n</code></pre> <p>This allows editing files on the host with changes reflected in containers.</p>"},{"location":"development/running-services/#debugging-services","title":"Debugging Services","text":""},{"location":"development/running-services/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code># Set environment variable\nexport LOG_LEVEL=DEBUG\n\n# Or in .env file\nLOG_LEVEL=DEBUG\n</code></pre>"},{"location":"development/running-services/#viewing-logs","title":"Viewing Logs","text":"<p>View logs for all services:</p> <pre><code># Using make\nmake dev-logs\n\n# Using docker-compose\ndocker-compose logs -f\n</code></pre> <p>View logs for specific services:</p> <pre><code># API service\nmake logs-api\n\n# Collectors\nmake logs-collectors\n\n# Processors\nmake logs-processors\n\n# Specific service\ndocker-compose logs -f api-service\n</code></pre>"},{"location":"development/running-services/#interactive-debugging","title":"Interactive Debugging","text":"<p>Attach to running containers:</p> <pre><code># API service shell\nmake shell-api\n\n# Database shell\nmake shell-db\n\n# Redis shell\nmake shell-redis\n\n# Any container\ndocker exec -it &lt;container-name&gt; /bin/bash\n</code></pre>"},{"location":"development/running-services/#remote-debugging","title":"Remote Debugging","text":"<p>For Python services using debugpy:</p> <ol> <li>Add debugpy to requirements</li> <li>Configure debugpy in code</li> <li>Expose debug port in docker-compose</li> <li>Connect from IDE</li> </ol> <p>Example configuration:</p> <pre><code>import debugpy\ndebugpy.listen((\"0.0.0.0\", 5678))\ndebugpy.wait_for_client()\n</code></pre>"},{"location":"development/running-services/#health-checks","title":"Health Checks","text":"<p>Check service health:</p> <pre><code># API service\ncurl http://localhost:8080/health\n\n# Git collector\ncurl http://localhost:8081/health\n\n# All services\nmake status\n</code></pre>"},{"location":"development/running-services/#common-operations","title":"Common Operations","text":""},{"location":"development/running-services/#restart-services","title":"Restart Services","text":"<p>Restart all services:</p> <pre><code>make dev-restart\n</code></pre> <p>Restart specific service:</p> <pre><code>docker-compose restart api-service\n</code></pre>"},{"location":"development/running-services/#stop-services","title":"Stop Services","text":"<p>Stop all services:</p> <pre><code>make dev-stop\n</code></pre> <p>Stop specific service:</p> <pre><code>docker-compose stop api-service\n</code></pre>"},{"location":"development/running-services/#rebuild-services","title":"Rebuild Services","text":"<p>Rebuild after dependency changes:</p> <pre><code># Rebuild all\ndocker-compose build\n\n# Rebuild specific service\ndocker-compose build api-service\n\n# Force rebuild without cache\ndocker-compose build --no-cache\n</code></pre>"},{"location":"development/running-services/#clean-environment","title":"Clean Environment","text":"<p>Remove all containers, volumes, and images:</p> <pre><code>make clean\n</code></pre> <p>Remove build artifacts:</p> <pre><code>make clean-builds\n</code></pre>"},{"location":"development/running-services/#performance-optimization","title":"Performance Optimization","text":""},{"location":"development/running-services/#resource-limits","title":"Resource Limits","text":"<p>Configure resource limits in docker-compose.yml:</p> <pre><code>services:\n  api-service:\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n</code></pre>"},{"location":"development/running-services/#database-tuning","title":"Database Tuning","text":"<p>Optimize database settings for development:</p> <ul> <li>Reduce shared_buffers for local development</li> <li>Disable fsync for faster writes (dev only)</li> <li>Increase work_mem for complex queries</li> </ul>"},{"location":"development/running-services/#parallel-startup","title":"Parallel Startup","text":"<p>Start independent services in parallel:</p> <pre><code>docker-compose up -d timescaledb postgresql redis &amp;\ndocker-compose up -d zookeeper kafka &amp;\nwait\ndocker-compose up -d git-collector jira-collector data-processor\n</code></pre>"},{"location":"development/running-services/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/running-services/#port-conflicts","title":"Port Conflicts","text":"<p>If ports are in use:</p> <pre><code># Check what's using a port\nlsof -i :8080\n\n# Kill process using port\nkill -9 &lt;PID&gt;\n\n# Or change port in docker-compose.yml\n</code></pre>"},{"location":"development/running-services/#database-connection-issues","title":"Database Connection Issues","text":"<p>If services can't connect to databases:</p> <ol> <li>Verify databases are running</li> <li>Check connection strings in .env</li> <li>Wait for databases to be ready</li> <li>Check network connectivity</li> </ol> <pre><code># Test database connection\ndocker exec sei-timescaledb pg_isready -U sei_user\n\n# Check logs\ndocker-compose logs timescaledb\n</code></pre>"},{"location":"development/running-services/#memory-issues","title":"Memory Issues","text":"<p>If services crash due to memory:</p> <ol> <li>Increase Docker memory limit</li> <li>Reduce number of running services</li> <li>Add swap space</li> <li>Optimize container resource usage</li> </ol>"},{"location":"development/running-services/#service-wont-start","title":"Service Won't Start","text":"<p>If a service fails to start:</p> <ol> <li>Check service logs</li> <li>Verify dependencies are running</li> <li>Check environment variables</li> <li>Rebuild the container</li> <li>Remove volumes and restart</li> </ol> <pre><code># Remove volumes\ndocker-compose down -v\n\n# Rebuild and restart\ndocker-compose up --build\n</code></pre>"},{"location":"development/running-services/#network-issues","title":"Network Issues","text":"<p>If services can't communicate:</p> <pre><code># Check Docker network\ndocker network ls\ndocker network inspect sei-network\n\n# Verify service connectivity\ndocker exec api-service ping timescaledb\n</code></pre>"},{"location":"development/running-services/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"development/running-services/#custom-docker-compose","title":"Custom Docker Compose","text":"<p>Create a docker-compose override:</p> <pre><code># docker-compose.override.yml\nversion: '3.8'\n\nservices:\n  api-service:\n    environment:\n      LOG_LEVEL: DEBUG\n    ports:\n      - \"8080:8080\"\n</code></pre>"},{"location":"development/running-services/#service-scaling","title":"Service Scaling","text":"<p>Scale services horizontally:</p> <pre><code># Scale API service to 3 instances\ndocker-compose up --scale api-service=3\n</code></pre>"},{"location":"development/running-services/#development-tools","title":"Development Tools","text":"<p>Additional development tools:</p> <pre><code># Jupyter notebook for data analysis\nmake jupyter\n\n# PostgreSQL admin interface\nopen http://localhost:8084\n</code></pre>"},{"location":"development/running-services/#best-practices","title":"Best Practices","text":""},{"location":"development/running-services/#local-development","title":"Local Development","text":"<p>For efficient local development:</p> <ul> <li>Run only services you're working on</li> <li>Use volume mounts for hot reloading</li> <li>Enable debug logging for your service</li> <li>Use health checks to verify services</li> <li>Keep databases running to avoid restart delays</li> </ul>"},{"location":"development/running-services/#resource-management","title":"Resource Management","text":"<p>To conserve resources:</p> <ul> <li>Stop unused services</li> <li>Use <code>docker-compose down -v</code> to clean volumes</li> <li>Prune unused images and containers regularly</li> <li>Monitor resource usage with <code>docker stats</code></li> </ul>"},{"location":"development/running-services/#configuration-management","title":"Configuration Management","text":"<p>For managing configuration:</p> <ul> <li>Use .env files for local overrides</li> <li>Never commit secrets to version control</li> <li>Document required environment variables</li> <li>Provide sensible defaults</li> <li>Use separate configs for dev/staging/prod</li> </ul>"},{"location":"development/testing/","title":"Testing","text":"<p>This guide covers the testing strategy, frameworks, and practices for the SEI Platform.</p>"},{"location":"development/testing/#testing-philosophy","title":"Testing Philosophy","text":"<p>The SEI Platform follows a comprehensive testing approach:</p> <ul> <li>Write tests before or alongside production code</li> <li>Maintain high test coverage (target 80%+)</li> <li>Favor integration tests for business logic</li> <li>Use unit tests for complex algorithms</li> <li>Include end-to-end tests for critical user flows</li> <li>Run tests automatically in CI/CD pipeline</li> </ul>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<p>Tests are organized by type in the <code>tests/</code> directory:</p> <pre><code>tests/\n\u251c\u2500\u2500 unit/              # Unit tests\n\u2502   \u251c\u2500\u2500 apis/         # API service units\n\u2502   \u251c\u2500\u2500 collectors/   # Collector units\n\u2502   \u251c\u2500\u2500 processors/   # Processor units\n\u2502   \u2514\u2500\u2500 frontend/     # Frontend units\n\u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 api/          # API integration tests\n\u2502   \u251c\u2500\u2500 collectors/   # Collector integration tests\n\u2502   \u2514\u2500\u2500 processors/   # Processor integration tests\n\u251c\u2500\u2500 e2e/              # End-to-end tests\n\u2502   \u251c\u2500\u2500 specs/        # Test specifications\n\u2502   \u2514\u2500\u2500 fixtures/     # Test data\n\u251c\u2500\u2500 load/             # Load and performance tests\n\u2502   \u2514\u2500\u2500 locustfile.py\n\u251c\u2500\u2500 fixtures/         # Shared test fixtures\n\u2514\u2500\u2500 conftest.py       # Pytest configuration\n</code></pre>"},{"location":"development/testing/#testing-frameworks","title":"Testing Frameworks","text":""},{"location":"development/testing/#python-tests","title":"Python Tests","text":"<p>Python services use pytest with additional plugins:</p> <ul> <li><code>pytest</code> - Test framework</li> <li><code>pytest-cov</code> - Coverage reporting</li> <li><code>pytest-asyncio</code> - Async test support</li> <li><code>factory-boy</code> - Test data factories</li> <li><code>freezegun</code> - Time mocking</li> </ul> <p>Install test dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"development/testing/#frontend-tests","title":"Frontend Tests","text":"<p>Frontend uses Jest and React Testing Library:</p> <ul> <li><code>jest</code> - Test runner</li> <li><code>@testing-library/react</code> - React component testing</li> <li><code>@testing-library/user-event</code> - User interaction simulation</li> <li><code>@testing-library/jest-dom</code> - DOM matchers</li> </ul> <p>Install frontend test dependencies:</p> <pre><code>cd src/frontend\nnpm install\n</code></pre>"},{"location":"development/testing/#end-to-end-tests","title":"End-to-End Tests","text":"<p>E2E tests use Playwright or Cypress:</p> <ul> <li>Cross-browser testing</li> <li>Visual regression testing</li> <li>Network mocking</li> <li>Screenshot comparison</li> </ul>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#all-tests","title":"All Tests","text":"<p>Run all test suites:</p> <pre><code>make test\n</code></pre> <p>This runs:</p> <ul> <li>Python unit tests</li> <li>Python integration tests</li> <li>Frontend tests</li> <li>Coverage reports</li> </ul>"},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<p>Run only unit tests:</p> <pre><code># All unit tests\nmake test-unit\n\n# Python unit tests\npytest tests/unit/ -v\n\n# Frontend unit tests\ncd src/frontend &amp;&amp; npm test\n</code></pre>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<p>Run integration tests:</p> <pre><code># All integration tests\nmake test-integration\n\n# Specific integration test\npytest tests/integration/api/test_analytics.py -v\n</code></pre>"},{"location":"development/testing/#end-to-end-tests_1","title":"End-to-End Tests","text":"<p>Run E2E tests:</p> <pre><code># All E2E tests\nmake test-e2e\n\n# Specific E2E test\ncd tests/e2e &amp;&amp; npm test -- specs/dashboard.spec.ts\n</code></pre>"},{"location":"development/testing/#load-tests","title":"Load Tests","text":"<p>Run load and performance tests:</p> <pre><code># Using make\nmake test-load\n\n# Using locust directly\ncd tests/load\nlocust -f locustfile.py --headless -u 100 -r 10 -t 300s\n</code></pre>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":"<p>Generate coverage reports:</p> <pre><code># Python coverage\npytest --cov=src --cov-report=html --cov-report=term\n\n# View HTML report\nopen htmlcov/index.html\n\n# Frontend coverage\ncd src/frontend &amp;&amp; npm test -- --coverage\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#unit-test-example","title":"Unit Test Example","text":"<p>Python unit test using pytest:</p> <pre><code># tests/unit/processors/test_velocity.py\nimport pytest\nfrom src.processors.processors.velocity import calculate_velocity\n\ndef test_calculate_velocity_with_valid_data():\n    \"\"\"Test velocity calculation with valid data.\"\"\"\n    commits = [\n        {\"date\": \"2024-01-01\", \"additions\": 100, \"deletions\": 20},\n        {\"date\": \"2024-01-02\", \"additions\": 150, \"deletions\": 30},\n    ]\n\n    result = calculate_velocity(commits)\n\n    assert result[\"total_commits\"] == 2\n    assert result[\"total_changes\"] == 300\n    assert result[\"net_changes\"] == 200\n\ndef test_calculate_velocity_with_empty_data():\n    \"\"\"Test velocity calculation with empty data.\"\"\"\n    commits = []\n\n    result = calculate_velocity(commits)\n\n    assert result[\"total_commits\"] == 0\n    assert result[\"total_changes\"] == 0\n\n@pytest.mark.parametrize(\"commits,expected\", [\n    ([{\"date\": \"2024-01-01\", \"additions\": 10, \"deletions\": 5}], 15),\n    ([{\"date\": \"2024-01-01\", \"additions\": 100, \"deletions\": 50}], 150),\n])\ndef test_calculate_velocity_parametrized(commits, expected):\n    \"\"\"Test velocity calculation with various inputs.\"\"\"\n    result = calculate_velocity(commits)\n    assert result[\"total_changes\"] == expected\n</code></pre>"},{"location":"development/testing/#integration-test-example","title":"Integration Test Example","text":"<p>Integration test with database:</p> <pre><code># tests/integration/api/test_developers.py\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom src.apis.main import app\nfrom src.apis.database import get_db\n\n@pytest.fixture\ndef client():\n    \"\"\"Create test client.\"\"\"\n    return TestClient(app)\n\n@pytest.fixture\ndef db_session():\n    \"\"\"Create test database session.\"\"\"\n    # Setup test database\n    session = create_test_session()\n    yield session\n    # Teardown\n    session.close()\n\ndef test_get_developers(client, db_session):\n    \"\"\"Test getting list of developers.\"\"\"\n    # Arrange - seed test data\n    create_test_developer(db_session, name=\"John Doe\")\n    create_test_developer(db_session, name=\"Jane Smith\")\n\n    # Act\n    response = client.get(\"/api/v1/developers\")\n\n    # Assert\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data) == 2\n    assert data[0][\"name\"] == \"John Doe\"\n\ndef test_get_developer_metrics(client, db_session):\n    \"\"\"Test getting developer metrics.\"\"\"\n    # Arrange\n    developer = create_test_developer(db_session, name=\"John Doe\")\n    create_test_commits(db_session, developer_id=developer.id, count=10)\n\n    # Act\n    response = client.get(f\"/api/v1/developers/{developer.id}/metrics\")\n\n    # Assert\n    assert response.status_code == 200\n    metrics = response.json()\n    assert metrics[\"total_commits\"] == 10\n    assert \"velocity\" in metrics\n</code></pre>"},{"location":"development/testing/#frontend-test-example","title":"Frontend Test Example","text":"<p>React component test:</p> <pre><code>// tests/unit/frontend/components/Dashboard.test.tsx\nimport { render, screen, waitFor } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\nimport Dashboard from '@/components/Dashboard';\nimport { mockApiClient } from '../mocks/apiClient';\n\ndescribe('Dashboard Component', () =&gt; {\n  beforeEach(() =&gt; {\n    // Setup mocks\n    mockApiClient.getMetrics.mockResolvedValue({\n      velocity: 100,\n      quality: 85,\n    });\n  });\n\n  test('renders dashboard with metrics', async () =&gt; {\n    render(&lt;Dashboard /&gt;);\n\n    expect(screen.getByText('Loading...')).toBeInTheDocument();\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText('Velocity: 100')).toBeInTheDocument();\n      expect(screen.getByText('Quality: 85')).toBeInTheDocument();\n    });\n  });\n\n  test('refreshes data on button click', async () =&gt; {\n    const user = userEvent.setup();\n    render(&lt;Dashboard /&gt;);\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText('Velocity: 100')).toBeInTheDocument();\n    });\n\n    const refreshButton = screen.getByRole('button', { name: /refresh/i });\n    await user.click(refreshButton);\n\n    expect(mockApiClient.getMetrics).toHaveBeenCalledTimes(2);\n  });\n\n  test('displays error message on API failure', async () =&gt; {\n    mockApiClient.getMetrics.mockRejectedValue(new Error('API Error'));\n\n    render(&lt;Dashboard /&gt;);\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText(/error loading metrics/i)).toBeInTheDocument();\n    });\n  });\n});\n</code></pre>"},{"location":"development/testing/#e2e-test-example","title":"E2E Test Example","text":"<p>End-to-end test using Playwright:</p> <pre><code>// tests/e2e/specs/dashboard.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Dashboard Flow', () =&gt; {\n  test.beforeEach(async ({ page }) =&gt; {\n    await page.goto('http://localhost:3002');\n  });\n\n  test('should display dashboard with metrics', async ({ page }) =&gt; {\n    // Wait for dashboard to load\n    await page.waitForSelector('[data-testid=\"dashboard\"]');\n\n    // Verify metrics are displayed\n    const velocity = await page.textContent('[data-testid=\"velocity-metric\"]');\n    expect(velocity).toBeTruthy();\n\n    const quality = await page.textContent('[data-testid=\"quality-metric\"]');\n    expect(quality).toBeTruthy();\n  });\n\n  test('should navigate to team details', async ({ page }) =&gt; {\n    // Click on team\n    await page.click('[data-testid=\"team-link\"]');\n\n    // Verify navigation\n    await expect(page).toHaveURL(/.*\\/teams\\/\\d+/);\n\n    // Verify team details are displayed\n    await expect(page.locator('h1')).toContainText('Team Details');\n  });\n\n  test('should filter metrics by date range', async ({ page }) =&gt; {\n    // Select date range\n    await page.fill('[data-testid=\"start-date\"]', '2024-01-01');\n    await page.fill('[data-testid=\"end-date\"]', '2024-01-31');\n    await page.click('[data-testid=\"apply-filter\"]');\n\n    // Wait for metrics to update\n    await page.waitForResponse(resp =&gt;\n      resp.url().includes('/api/v1/metrics') &amp;&amp; resp.status() === 200\n    );\n\n    // Verify filtered data\n    const dateRange = await page.textContent('[data-testid=\"date-range\"]');\n    expect(dateRange).toContain('Jan 1 - Jan 31');\n  });\n});\n</code></pre>"},{"location":"development/testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"development/testing/#python-fixtures","title":"Python Fixtures","text":"<p>Create reusable test fixtures:</p> <pre><code># tests/conftest.py\nimport pytest\nfrom datetime import datetime\nfrom src.apis.database import Base, engine\n\n@pytest.fixture(scope=\"session\")\ndef test_db():\n    \"\"\"Create test database.\"\"\"\n    Base.metadata.create_all(bind=engine)\n    yield\n    Base.metadata.drop_all(bind=engine)\n\n@pytest.fixture\ndef db_session(test_db):\n    \"\"\"Create database session for test.\"\"\"\n    from sqlalchemy.orm import sessionmaker\n    Session = sessionmaker(bind=engine)\n    session = Session()\n    yield session\n    session.rollback()\n    session.close()\n\n@pytest.fixture\ndef sample_developer():\n    \"\"\"Create sample developer data.\"\"\"\n    return {\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\",\n        \"team_id\": 1,\n    }\n\n@pytest.fixture\ndef sample_commits():\n    \"\"\"Create sample commit data.\"\"\"\n    return [\n        {\n            \"sha\": \"abc123\",\n            \"message\": \"Fix bug\",\n            \"author\": \"John Doe\",\n            \"date\": datetime(2024, 1, 1),\n            \"additions\": 10,\n            \"deletions\": 5,\n        },\n        {\n            \"sha\": \"def456\",\n            \"message\": \"Add feature\",\n            \"author\": \"John Doe\",\n            \"date\": datetime(2024, 1, 2),\n            \"additions\": 50,\n            \"deletions\": 10,\n        },\n    ]\n</code></pre>"},{"location":"development/testing/#frontend-fixtures","title":"Frontend Fixtures","text":"<p>Mock API responses:</p> <pre><code>// tests/unit/frontend/mocks/apiClient.ts\nexport const mockApiClient = {\n  getMetrics: jest.fn(),\n  getDevelopers: jest.fn(),\n  getTeams: jest.fn(),\n};\n\nexport const mockMetrics = {\n  velocity: 100,\n  quality: 85,\n  collaboration: 92,\n  flow: 78,\n};\n\nexport const mockDevelopers = [\n  { id: 1, name: 'John Doe', email: 'john@example.com' },\n  { id: 2, name: 'Jane Smith', email: 'jane@example.com' },\n];\n</code></pre>"},{"location":"development/testing/#test-data-factories","title":"Test Data Factories","text":"<p>Use factory-boy for generating test data:</p> <pre><code># tests/factories.py\nimport factory\nfrom datetime import datetime\nfrom src.apis.models import Developer, Team, Commit\n\nclass TeamFactory(factory.Factory):\n    class Meta:\n        model = Team\n\n    id = factory.Sequence(lambda n: n)\n    name = factory.Faker('company')\n    created_at = factory.LazyFunction(datetime.utcnow)\n\nclass DeveloperFactory(factory.Factory):\n    class Meta:\n        model = Developer\n\n    id = factory.Sequence(lambda n: n)\n    name = factory.Faker('name')\n    email = factory.Faker('email')\n    team = factory.SubFactory(TeamFactory)\n    created_at = factory.LazyFunction(datetime.utcnow)\n\nclass CommitFactory(factory.Factory):\n    class Meta:\n        model = Commit\n\n    sha = factory.Faker('sha1')\n    message = factory.Faker('sentence')\n    author = factory.SubFactory(DeveloperFactory)\n    date = factory.Faker('date_time_this_year')\n    additions = factory.Faker('random_int', min=1, max=100)\n    deletions = factory.Faker('random_int', min=1, max=50)\n\n# Usage in tests\ndef test_developer_with_commits():\n    developer = DeveloperFactory()\n    commits = CommitFactory.create_batch(5, author=developer)\n    assert len(commits) == 5\n</code></pre>"},{"location":"development/testing/#mocking-and-stubbing","title":"Mocking and Stubbing","text":""},{"location":"development/testing/#mocking-external-services","title":"Mocking External Services","text":"<p>Mock external API calls:</p> <pre><code># tests/unit/collectors/test_git_collector.py\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom src.collectors.git.services.collector import GitCollector\n\n@patch('src.collectors.git.services.collector.requests.get')\ndef test_fetch_commits(mock_get):\n    \"\"\"Test fetching commits from GitHub API.\"\"\"\n    # Arrange\n    mock_response = Mock()\n    mock_response.json.return_value = [\n        {\"sha\": \"abc123\", \"message\": \"Test commit\"}\n    ]\n    mock_response.status_code = 200\n    mock_get.return_value = mock_response\n\n    collector = GitCollector()\n\n    # Act\n    commits = collector.fetch_commits(\"owner/repo\")\n\n    # Assert\n    assert len(commits) == 1\n    assert commits[0][\"sha\"] == \"abc123\"\n    mock_get.assert_called_once()\n\n@patch('src.collectors.git.services.collector.kafka_producer')\ndef test_send_to_kafka(mock_producer):\n    \"\"\"Test sending data to Kafka.\"\"\"\n    collector = GitCollector()\n\n    collector.send_to_kafka({\"data\": \"test\"})\n\n    mock_producer.send.assert_called_once_with(\n        \"commits\",\n        {\"data\": \"test\"}\n    )\n</code></pre>"},{"location":"development/testing/#database-mocking","title":"Database Mocking","text":"<p>Use in-memory SQLite for tests:</p> <pre><code># tests/conftest.py\nimport pytest\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom src.apis.database import Base\n\n@pytest.fixture(scope=\"function\")\ndef test_db():\n    \"\"\"Create in-memory test database.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    Base.metadata.create_all(engine)\n\n    Session = sessionmaker(bind=engine)\n    session = Session()\n\n    yield session\n\n    session.close()\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#arrange-act-assert-pattern","title":"Arrange-Act-Assert Pattern","text":"<p>Structure tests clearly:</p> <pre><code>def test_calculate_metrics():\n    # Arrange - set up test data\n    commits = create_test_commits(count=10)\n\n    # Act - execute the function\n    metrics = calculate_metrics(commits)\n\n    # Assert - verify results\n    assert metrics[\"count\"] == 10\n    assert metrics[\"velocity\"] &gt; 0\n</code></pre>"},{"location":"development/testing/#test-isolation","title":"Test Isolation","text":"<p>Ensure tests are independent:</p> <ul> <li>Use fixtures for setup and teardown</li> <li>Avoid shared state between tests</li> <li>Reset databases between tests</li> <li>Clear caches and mocks</li> <li>Don't rely on test execution order</li> </ul>"},{"location":"development/testing/#descriptive-test-names","title":"Descriptive Test Names","text":"<p>Use clear, descriptive test names:</p> <pre><code># Good\ndef test_calculate_velocity_returns_zero_for_empty_commits():\n    pass\n\n# Bad\ndef test_velocity():\n    pass\n</code></pre>"},{"location":"development/testing/#test-edge-cases","title":"Test Edge Cases","text":"<p>Cover boundary conditions:</p> <pre><code>def test_calculate_average():\n    # Normal case\n    assert calculate_average([1, 2, 3]) == 2\n\n    # Edge cases\n    assert calculate_average([]) == 0\n    assert calculate_average([1]) == 1\n    assert calculate_average([0, 0, 0]) == 0\n\n    # Error cases\n    with pytest.raises(TypeError):\n        calculate_average(None)\n</code></pre>"},{"location":"development/testing/#avoid-test-duplication","title":"Avoid Test Duplication","text":"<p>Use parametrized tests:</p> <pre><code>@pytest.mark.parametrize(\"input,expected\", [\n    ([], 0),\n    ([1], 1),\n    ([1, 2, 3], 6),\n    ([0, 0, 0], 0),\n])\ndef test_sum_values(input, expected):\n    assert sum_values(input) == expected\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#running-tests-in-ci","title":"Running Tests in CI","text":"<p>Tests run automatically on pull requests:</p> <pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Run tests\n        run: pytest --cov=src --cov-report=xml\n      - name: Upload coverage\n        uses: codecov/codecov-action@v2\n</code></pre>"},{"location":"development/testing/#test-coverage-requirements","title":"Test Coverage Requirements","text":"<p>Enforce minimum coverage:</p> <pre><code># pytest.ini\n[pytest]\naddopts = --cov=src --cov-report=term --cov-fail-under=80\n</code></pre>"},{"location":"development/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Run tests before commits:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: pytest\n        name: pytest\n        entry: pytest\n        language: system\n        pass_filenames: false\n        always_run: true\n</code></pre>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#run-specific-tests","title":"Run Specific Tests","text":"<p>Run individual tests:</p> <pre><code># Single test file\npytest tests/unit/processors/test_velocity.py\n\n# Single test function\npytest tests/unit/processors/test_velocity.py::test_calculate_velocity\n\n# Tests matching pattern\npytest -k \"velocity\"\n</code></pre>"},{"location":"development/testing/#verbose-output","title":"Verbose Output","text":"<p>Get detailed test output:</p> <pre><code># Verbose mode\npytest -v\n\n# Show print statements\npytest -s\n\n# Show local variables on failure\npytest -l\n</code></pre>"},{"location":"development/testing/#debug-failed-tests","title":"Debug Failed Tests","text":"<p>Use pytest debugging:</p> <pre><code># Drop into debugger on failure\npytest --pdb\n\n# Drop into debugger at start of test\npytest --trace\n</code></pre>"},{"location":"development/testing/#test-performance","title":"Test Performance","text":"<p>Profile slow tests:</p> <pre><code># Show slowest tests\npytest --durations=10\n\n# Profile test execution\npytest --profile\n</code></pre>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Configure the SEI Platform to integrate with your development tools.</p>"},{"location":"getting-started/configuration/#configuration-overview","title":"Configuration Overview","text":"<p>The platform uses environment variables for configuration. All settings are defined in the <code>.env</code> file.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"getting-started/configuration/#application-settings","title":"Application Settings","text":"<pre><code># Environment\nENVIRONMENT=development          # development, staging, production\nLOG_LEVEL=INFO                  # DEBUG, INFO, WARNING, ERROR\nDEBUG=true                      # Enable debug mode\n\n# API Configuration\nAPI_RATE_LIMIT=1000            # Requests per window\nJWT_SECRET=your_secret_here    # Change in production\nJWT_EXPIRATION=3600            # Token expiration in seconds\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":"<pre><code># TimescaleDB (Time-series data)\nTIMESCALE_URL=postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\n\n# PostgreSQL (Metadata)\nPOSTGRES_URL=postgresql://sei_user:sei_password@postgresql:5432/sei_metadata\n\n# Redis (Cache)\nREDIS_URL=redis://redis:6379\n</code></pre>"},{"location":"getting-started/configuration/#message-queue-configuration","title":"Message Queue Configuration","text":"<pre><code># Kafka\nKAFKA_BROKERS=kafka:9092\nKAFKA_TOPIC_PREFIX=sei_\n</code></pre>"},{"location":"getting-started/configuration/#integration-credentials","title":"Integration Credentials","text":""},{"location":"getting-started/configuration/#github","title":"GitHub","text":"<pre><code>GITHUB_TOKEN=ghp_your_token_here\n</code></pre> <p>Required Scopes: - <code>repo</code> - Access repository data - <code>read:org</code> - Read organization data - <code>read:user</code> - Read user profile data</p> <p>How to Generate: 1. Go to GitHub Settings \u2192 Developer settings \u2192 Personal access tokens 2. Click \"Generate new token (classic)\" 3. Select required scopes 4. Generate token and copy</p>"},{"location":"getting-started/configuration/#gitlab","title":"GitLab","text":"<pre><code>GITLAB_TOKEN=glpat_your_token_here\nGITLAB_API_URL=https://gitlab.com/api/v4\n</code></pre> <p>Required Scopes: - <code>api</code> - Full API access - <code>read_api</code> - Read-only API access (alternative)</p> <p>How to Generate: 1. Go to GitLab Settings \u2192 Access Tokens 2. Name your token 3. Select <code>api</code> scope 4. Create token and copy</p>"},{"location":"getting-started/configuration/#jira","title":"Jira","text":"<pre><code>JIRA_API_TOKEN=your_jira_token_here\nJIRA_BASE_URL=https://your-domain.atlassian.net\nJIRA_USERNAME=your.email@company.com\n</code></pre> <p>How to Generate: 1. Go to Jira Account Settings \u2192 Security \u2192 API tokens 2. Click \"Create API token\" 3. Name your token 4. Copy the token</p>"},{"location":"getting-started/configuration/#slack","title":"Slack","text":"<pre><code>SLACK_BOT_TOKEN=xoxb-your-token-here\n</code></pre> <p>How to Generate: 1. Go to Slack API 2. Create new app or select existing 3. Go to OAuth &amp; Permissions 4. Install app to workspace 5. Copy Bot User OAuth Token</p>"},{"location":"getting-started/configuration/#security-configuration","title":"Security Configuration","text":"<pre><code># Encryption\nENCRYPTION_KEY=your_encryption_key_here\n\n# CORS\nCORS_ORIGINS=[\"*\"]  # Restrict in production\n\n# API Security\nAPI_RATE_LIMIT=1000\n</code></pre>"},{"location":"getting-started/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":"<pre><code># Prometheus\nPROMETHEUS_URL=http://prometheus:9090\n\n# Grafana\nGRAFANA_URL=http://grafana:3000\n</code></pre>"},{"location":"getting-started/configuration/#email-configuration-optional","title":"Email Configuration (Optional)","text":"<pre><code>EMAIL_SMTP_HOST=smtp.gmail.com\nEMAIL_SMTP_PORT=587\nEMAIL_USERNAME=your_email@gmail.com\nEMAIL_PASSWORD=your_app_password\n</code></pre>"},{"location":"getting-started/configuration/#feature-flags","title":"Feature Flags","text":"<p>Enable or disable specific features:</p> <pre><code>ENABLE_ML_FEATURES=true\nENABLE_REAL_TIME_PROCESSING=true\nENABLE_PREDICTIVE_ANALYTICS=false\n</code></pre>"},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"getting-started/configuration/#development-configuration","title":"Development Configuration","text":"<p>Located at <code>config/dev.env.example</code>:</p> <pre><code># Development-specific settings\nDEBUG=true\nLOG_LEVEL=DEBUG\nENVIRONMENT=development\n</code></pre>"},{"location":"getting-started/configuration/#production-configuration","title":"Production Configuration","text":"<p>Located at <code>config/production.env.example</code>:</p> <pre><code># Production-specific settings\nDEBUG=false\nLOG_LEVEL=INFO\nENVIRONMENT=production\n</code></pre>"},{"location":"getting-started/configuration/#service-specific-configuration","title":"Service-Specific Configuration","text":""},{"location":"getting-started/configuration/#api-service","title":"API Service","text":"<p>Configuration in <code>src/apis/config.py</code>:</p> <pre><code>class Settings(BaseSettings):\n    environment: str = \"development\"\n    log_level: str = \"INFO\"\n    debug: bool = True\n\n    # Security\n    jwt_secret: str = \"your_jwt_secret_here\"\n    jwt_algorithm: str = \"HS256\"\n    jwt_expiration: int = 3600\n\n    # Database\n    postgres_url: str\n    timescale_url: str\n    redis_url: str\n</code></pre>"},{"location":"getting-started/configuration/#git-collector","title":"Git Collector","text":"<p>Configuration in <code>src/collectors/git/config.py</code>:</p> <pre><code>class Settings(BaseSettings):\n    # GitHub API\n    github_token: str = \"\"\n    github_api_url: str = \"https://api.github.com\"\n\n    # GitLab API\n    gitlab_token: str = \"\"\n    gitlab_api_url: str = \"https://gitlab.com/api/v4\"\n\n    # Rate Limiting\n    rate_limit_requests: int = 5000\n    rate_limit_window: int = 3600\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration_1","title":"Database Configuration","text":""},{"location":"getting-started/configuration/#postgresql","title":"PostgreSQL","text":"<p>Connection string format: <pre><code>postgresql://user:password@host:port/database\n</code></pre></p> <p>Default: <pre><code>postgresql://sei_user:sei_password@postgresql:5432/sei_metadata\n</code></pre></p>"},{"location":"getting-started/configuration/#timescaledb","title":"TimescaleDB","text":"<p>Connection string format: <pre><code>postgresql://user:password@host:port/database\n</code></pre></p> <p>Default: <pre><code>postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\n</code></pre></p>"},{"location":"getting-started/configuration/#redis","title":"Redis","text":"<p>Connection string format: <pre><code>redis://host:port\n</code></pre></p> <p>Default: <pre><code>redis://redis:6379\n</code></pre></p>"},{"location":"getting-started/configuration/#kafka-configuration","title":"Kafka Configuration","text":"<pre><code># Brokers\nKAFKA_BROKERS=kafka:9092\n\n# Topics\nKAFKA_TOPIC_PREFIX=sei_\n\n# Consumer Groups\nKAFKA_CONSUMER_GROUP=data-processor-group\n</code></pre>"},{"location":"getting-started/configuration/#testing-configuration","title":"Testing Configuration","text":"<p>Create a separate <code>.env.test</code> file for testing:</p> <pre><code>ENVIRONMENT=test\nLOG_LEVEL=DEBUG\nPOSTGRES_URL=postgresql://test_user:test_pass@localhost:5432/test_db\nTIMESCALE_URL=postgresql://test_user:test_pass@localhost:5432/test_timescale\n</code></pre>"},{"location":"getting-started/configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"getting-started/configuration/#security","title":"Security","text":"<ol> <li>Never commit <code>.env</code> files to version control</li> <li>Use strong passwords for all services</li> <li>Rotate tokens regularly</li> <li>Use different credentials for each environment</li> <li>Encrypt sensitive data at rest</li> </ol>"},{"location":"getting-started/configuration/#development","title":"Development","text":"<ol> <li>Use <code>.env.example</code> as a template</li> <li>Document all environment variables</li> <li>Provide sensible defaults</li> <li>Validate configuration on startup</li> </ol>"},{"location":"getting-started/configuration/#production","title":"Production","text":"<ol> <li>Use secrets management (AWS Secrets Manager, HashiCorp Vault)</li> <li>Enable SSL/TLS for all connections</li> <li>Restrict CORS origins</li> <li>Enable rate limiting</li> <li>Use strong JWT secrets</li> </ol>"},{"location":"getting-started/configuration/#validation","title":"Validation","text":"<p>Verify configuration:</p> <pre><code># Check API configuration\ncurl http://localhost:8080/health\n\n# Check database connectivity\ncurl http://localhost:8080/ready\n\n# View current configuration (be careful with sensitive data)\ndocker-compose exec api-service env | grep -v PASSWORD\n</code></pre>"},{"location":"getting-started/configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/configuration/#invalid-configuration","title":"Invalid Configuration","text":"<p>If services fail to start, check logs:</p> <pre><code>docker-compose logs api-service\n</code></pre> <p>Common issues:</p> <ul> <li>Missing required environment variables</li> <li>Invalid database connection strings</li> <li>Incorrect API tokens</li> <li>Port conflicts</li> </ul>"},{"location":"getting-started/configuration/#database-connection-issues","title":"Database Connection Issues","text":"<p>Verify connection strings:</p> <pre><code># Test PostgreSQL\ndocker-compose exec postgresql psql -U sei_user -d sei_metadata -c \"SELECT 1\"\n\n# Test TimescaleDB\ndocker-compose exec timescaledb psql -U sei_user -d sei_platform -c \"SELECT 1\"\n</code></pre>"},{"location":"getting-started/configuration/#api-token-issues","title":"API Token Issues","text":"<p>Test tokens manually:</p> <pre><code># GitHub\ncurl -H \"Authorization: token YOUR_TOKEN\" https://api.github.com/user\n\n# GitLab\ncurl -H \"PRIVATE-TOKEN: YOUR_TOKEN\" https://gitlab.com/api/v4/user\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup</li> <li>Running Services</li> <li>API Reference</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Detailed installation instructions for the SEI Platform.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>CPU: 4 cores</li> <li>RAM: 8 GB</li> <li>Storage: 50 GB</li> <li>OS: Linux, macOS, or Windows with WSL2</li> </ul>"},{"location":"getting-started/installation/#recommended-requirements","title":"Recommended Requirements","text":"<ul> <li>CPU: 8+ cores</li> <li>RAM: 16+ GB</li> <li>Storage: 100+ GB SSD</li> <li>OS: Linux (Ubuntu 20.04+, CentOS 8+)</li> </ul>"},{"location":"getting-started/installation/#software-dependencies","title":"Software Dependencies","text":"<ul> <li>Docker 20.10 or higher</li> <li>Docker Compose 2.0 or higher</li> <li>Git 2.30 or higher</li> <li>Python 3.11 or higher (for local development)</li> <li>Node.js 18 or higher (for frontend development)</li> </ul>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting-started/installation/#method-1-docker-compose-recommended","title":"Method 1: Docker Compose (Recommended)","text":"<p>This is the fastest way to get started. All services run in containers.</p>"},{"location":"getting-started/installation/#step-1-install-docker","title":"Step 1: Install Docker","text":"<p>Ubuntu/Debian: <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\nsudo usermod -aG docker $USER\n</code></pre></p> <p>macOS: Download and install Docker Desktop</p> <p>Windows: Download and install Docker Desktop for Windows</p>"},{"location":"getting-started/installation/#step-2-clone-repository","title":"Step 2: Clone Repository","text":"<pre><code>git clone https://github.com/rcdelacruz/open-source-sei-platform.git\ncd open-source-sei-platform\n</code></pre>"},{"location":"getting-started/installation/#step-3-configure-environment","title":"Step 3: Configure Environment","text":"<pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> to configure:</p> <pre><code># Database Configuration\nTIMESCALE_URL=postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\nPOSTGRES_URL=postgresql://sei_user:sei_password@postgresql:5432/sei_metadata\n\n# API Keys (optional for initial setup)\nGITHUB_TOKEN=your_github_token_here\nGITLAB_TOKEN=your_gitlab_token_here\nJIRA_API_TOKEN=your_jira_token_here\nJIRA_BASE_URL=https://your-domain.atlassian.net\n</code></pre>"},{"location":"getting-started/installation/#step-4-start-services","title":"Step 4: Start Services","text":"<p>Using Make: <pre><code>make dev\n</code></pre></p> <p>Or using Docker Compose directly: <pre><code>docker-compose up -d\n</code></pre></p>"},{"location":"getting-started/installation/#step-5-verify-installation","title":"Step 5: Verify Installation","text":"<p>Check service status: <pre><code>docker-compose ps\n</code></pre></p> <p>All services should show \"Up\" or \"Up (healthy)\".</p> <p>Test API: <pre><code>curl http://localhost:8080/health\n</code></pre></p>"},{"location":"getting-started/installation/#method-2-kubernetes-production","title":"Method 2: Kubernetes (Production)","text":"<p>For production deployments, use Kubernetes.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (v1.24+)</li> <li>kubectl configured</li> <li>Helm 3 installed</li> </ul>"},{"location":"getting-started/installation/#step-1-create-namespace","title":"Step 1: Create Namespace","text":"<pre><code>kubectl create namespace sei-platform\n</code></pre>"},{"location":"getting-started/installation/#step-2-deploy-services","title":"Step 2: Deploy Services","text":"<pre><code>kubectl apply -f k8s/namespace.yaml\nkubectl apply -f k8s/\n</code></pre>"},{"location":"getting-started/installation/#step-3-verify-deployment","title":"Step 3: Verify Deployment","text":"<pre><code>kubectl get pods -n sei-platform\nkubectl get services -n sei-platform\n</code></pre>"},{"location":"getting-started/installation/#method-3-local-development","title":"Method 3: Local Development","text":"<p>For active development on services.</p>"},{"location":"getting-started/installation/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Node.js 18+</li> <li>PostgreSQL 14+</li> <li>TimescaleDB 2.11+</li> <li>Redis 7+</li> <li>Apache Kafka 3.5+</li> </ul>"},{"location":"getting-started/installation/#step-1-install-python-dependencies","title":"Step 1: Install Python Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#step-2-install-frontend-dependencies","title":"Step 2: Install Frontend Dependencies","text":"<pre><code>cd src/frontend\nnpm install\n</code></pre>"},{"location":"getting-started/installation/#step-3-start-databases","title":"Step 3: Start Databases","text":"<pre><code># Start PostgreSQL, TimescaleDB, Redis, Kafka\ndocker-compose up -d postgresql timescaledb redis kafka zookeeper\n</code></pre>"},{"location":"getting-started/installation/#step-4-run-services","title":"Step 4: Run Services","text":"<p>In separate terminals:</p> <pre><code># API Service\ncd src/apis\nuvicorn main:app --reload --port 8080\n\n# Git Collector\ncd src/collectors/git\nuvicorn main:app --reload --port 8000\n\n# Jira Collector\ncd src/collectors/jira\nuvicorn main:app --reload --port 8001\n\n# Data Processor\ncd src/processors\nuvicorn main:app --reload --port 8002\n\n# Frontend\ncd src/frontend\nnpm start\n</code></pre>"},{"location":"getting-started/installation/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"getting-started/installation/#database-setup","title":"Database Setup","text":"<p>Initialize databases:</p> <pre><code># Run migrations\nmake db-migrate\n\n# Seed with sample data\nmake db-seed\n</code></pre>"},{"location":"getting-started/installation/#configure-integrations","title":"Configure Integrations","text":""},{"location":"getting-started/installation/#github-integration","title":"GitHub Integration","text":"<ol> <li> <p>Generate a Personal Access Token:</p> <ul> <li>Go to GitHub Settings \u2192 Developer settings \u2192 Personal access tokens</li> <li>Generate new token with <code>repo</code> and <code>read:org</code> scopes</li> </ul> </li> <li> <p>Add to <code>.env</code>:    <pre><code>GITHUB_TOKEN=ghp_your_token_here\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#gitlab-integration","title":"GitLab Integration","text":"<ol> <li> <p>Generate an Access Token:</p> <ul> <li>Go to GitLab Settings \u2192 Access Tokens</li> <li>Create token with <code>api</code> scope</li> </ul> </li> <li> <p>Add to <code>.env</code>:    <pre><code>GITLAB_TOKEN=glpat_your_token_here\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#jira-integration","title":"Jira Integration","text":"<ol> <li> <p>Generate an API Token:</p> <ul> <li>Go to Jira Account Settings \u2192 Security \u2192 API tokens</li> <li>Create token</li> </ul> </li> <li> <p>Add to <code>.env</code>:    <pre><code>JIRA_API_TOKEN=your_token_here\nJIRA_BASE_URL=https://your-domain.atlassian.net\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#access-services","title":"Access Services","text":"<p>After installation, access:</p> Service URL Default Credentials API Docs http://localhost:8080/docs None Frontend http://localhost:3002 None Metabase http://localhost:3000 Setup wizard Grafana http://localhost:3001 admin / admin123 Airflow http://localhost:8082 admin / admin123"},{"location":"getting-started/installation/#verification","title":"Verification","text":""},{"location":"getting-started/installation/#health-checks","title":"Health Checks","text":"<p>Check API health: <pre><code>curl http://localhost:8080/health\n</code></pre></p> <p>Check readiness: <pre><code>curl http://localhost:8080/ready\n</code></pre></p>"},{"location":"getting-started/installation/#service-logs","title":"Service Logs","text":"<p>View logs: <pre><code># All services\ndocker-compose logs -f\n\n# Specific service\ndocker-compose logs -f api-service\n</code></pre></p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#port-conflicts","title":"Port Conflicts","text":"<p>If ports are already in use, modify <code>docker-compose.yml</code>:</p> <pre><code>services:\n  api-service:\n    ports:\n      - \"8888:8080\"  # Change external port\n</code></pre>"},{"location":"getting-started/installation/#memory-issues","title":"Memory Issues","text":"<p>Increase Docker memory allocation:</p> <ul> <li>Docker Desktop: Settings \u2192 Resources \u2192 Memory (16GB recommended)</li> </ul>"},{"location":"getting-started/installation/#database-connection-errors","title":"Database Connection Errors","text":"<p>Ensure databases are running: <pre><code>docker-compose ps postgresql timescaledb\n</code></pre></p> <p>Check logs: <pre><code>docker-compose logs postgresql timescaledb\n</code></pre></p>"},{"location":"getting-started/installation/#build-failures","title":"Build Failures","text":"<p>Clean and rebuild: <pre><code>docker-compose down -v\ndocker-compose build --no-cache\ndocker-compose up -d\n</code></pre></p>"},{"location":"getting-started/installation/#uninstallation","title":"Uninstallation","text":""},{"location":"getting-started/installation/#remove-containers","title":"Remove Containers","text":"<pre><code>docker-compose down\n</code></pre>"},{"location":"getting-started/installation/#remove-containers-and-volumes","title":"Remove Containers and Volumes","text":"<p>Warning: This deletes all data.</p> <pre><code>docker-compose down -v\n</code></pre>"},{"location":"getting-started/installation/#remove-images","title":"Remove Images","text":"<pre><code>docker-compose down --rmi all\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide</li> <li>Development Setup</li> <li>Architecture Overview</li> <li>API Reference</li> </ul>"},{"location":"getting-started/overview/","title":"Overview","text":""},{"location":"getting-started/overview/#what-is-sei-platform","title":"What is SEI Platform?","text":"<p>The Software Engineering Intelligence (SEI) Platform is an open-source solution designed to provide comprehensive insights into software development operations, team performance, and engineering excellence.</p>"},{"location":"getting-started/overview/#purpose","title":"Purpose","text":"<p>Modern software teams need data-driven insights to:</p> <ul> <li>Measure and improve engineering productivity</li> <li>Track team performance objectively</li> <li>Identify bottlenecks in the development process</li> <li>Make informed decisions about resource allocation</li> <li>Demonstrate the impact of engineering investments</li> </ul> <p>The SEI Platform addresses these needs by collecting, processing, and analyzing data from your existing development tools.</p>"},{"location":"getting-started/overview/#key-capabilities","title":"Key Capabilities","text":""},{"location":"getting-started/overview/#data-collection","title":"Data Collection","text":"<p>Automated collection from multiple sources:</p> <ul> <li>Version control systems (GitHub, GitLab, Bitbucket)</li> <li>Project management tools (Jira, Azure Boards, Linear)</li> <li>CI/CD pipelines (Jenkins, GitHub Actions, GitLab CI)</li> <li>Communication platforms (Slack, Microsoft Teams)</li> <li>Security scanning tools (Snyk, SonarQube)</li> </ul>"},{"location":"getting-started/overview/#analytics","title":"Analytics","text":"<p>Comprehensive analytics across multiple dimensions:</p> <ul> <li>DORA Metrics: Industry-standard DevOps performance indicators</li> <li>Team Velocity: Sprint-over-sprint performance tracking</li> <li>Code Quality: Technical debt and quality trends</li> <li>Developer Productivity: Individual and team contributions</li> <li>Predictive Insights: ML-powered forecasting and risk detection</li> </ul>"},{"location":"getting-started/overview/#visualization","title":"Visualization","text":"<p>Multiple dashboard views for different roles:</p> <ul> <li>Executive dashboards for strategic decision-making</li> <li>Manager views for team performance and resource planning</li> <li>Developer portals for personal productivity insights</li> <li>Product manager views for delivery tracking</li> </ul>"},{"location":"getting-started/overview/#architecture-principles","title":"Architecture Principles","text":"<p>The platform is built on these core principles:</p>"},{"location":"getting-started/overview/#scalability","title":"Scalability","text":"<ul> <li>Microservices architecture for independent scaling</li> <li>Event-driven processing with Apache Kafka</li> <li>Time-series optimized storage with TimescaleDB</li> <li>Horizontal scaling capabilities</li> </ul>"},{"location":"getting-started/overview/#flexibility","title":"Flexibility","text":"<ul> <li>Plugin-based integration system</li> <li>Custom metrics framework</li> <li>Configurable dashboards</li> <li>API-first design</li> </ul>"},{"location":"getting-started/overview/#security","title":"Security","text":"<ul> <li>Role-based access control (RBAC)</li> <li>Data encryption at rest and in transit</li> <li>Audit logging</li> <li>Compliance-ready architecture</li> </ul>"},{"location":"getting-started/overview/#maintainability","title":"Maintainability","text":"<ul> <li>Comprehensive test coverage</li> <li>Clear separation of concerns</li> <li>Extensive documentation</li> <li>Standard tooling and practices</li> </ul>"},{"location":"getting-started/overview/#use-cases","title":"Use Cases","text":""},{"location":"getting-started/overview/#engineering-leadership","title":"Engineering Leadership","text":"<ul> <li>Track DORA metrics to assess DevOps maturity</li> <li>Measure team performance and identify improvement areas</li> <li>Justify engineering investments with data</li> <li>Plan capacity and resources effectively</li> </ul>"},{"location":"getting-started/overview/#engineering-managers","title":"Engineering Managers","text":"<ul> <li>Monitor team velocity and burndown</li> <li>Identify blockers and bottlenecks</li> <li>Track code review efficiency</li> <li>Balance workload across team members</li> </ul>"},{"location":"getting-started/overview/#individual-contributors","title":"Individual Contributors","text":"<ul> <li>View personal productivity metrics</li> <li>Track code quality trends</li> <li>Monitor review response times</li> <li>Understand contribution patterns</li> </ul>"},{"location":"getting-started/overview/#product-managers","title":"Product Managers","text":"<ul> <li>Track feature delivery timelines</li> <li>Understand engineering velocity</li> <li>Identify technical health issues</li> <li>Plan releases based on team capacity</li> </ul>"},{"location":"getting-started/overview/#comparison-with-commercial-solutions","title":"Comparison with Commercial Solutions","text":"<p>The SEI Platform provides comparable capabilities to commercial solutions like LinearB, Swarmia, and Logilica, with these advantages:</p> <p>Cost Savings</p> <ul> <li>No per-seat licensing fees</li> <li>Predictable infrastructure costs</li> <li>No vendor lock-in</li> </ul> <p>Customization</p> <ul> <li>Full source code access</li> <li>Custom integrations</li> <li>Tailored analytics</li> <li>Branded deployments</li> </ul> <p>Data Privacy</p> <ul> <li>On-premises or private cloud deployment</li> <li>Complete data ownership</li> <li>No third-party data sharing</li> <li>Compliance with internal policies</li> </ul> <p>Community-Driven</p> <ul> <li>Open-source development model</li> <li>Community contributions</li> <li>Transparent roadmap</li> <li>Collaborative improvements</li> </ul>"},{"location":"getting-started/overview/#technology-foundation","title":"Technology Foundation","text":"<p>Built on proven, enterprise-grade technologies:</p> <ul> <li>FastAPI: Modern, fast Python web framework</li> <li>Apache Kafka: Distributed event streaming</li> <li>TimescaleDB: Time-series database</li> <li>PostgreSQL: Relational database</li> <li>React/Vue.js: Modern frontend frameworks</li> <li>Docker/Kubernetes: Container orchestration</li> <li>Apache Airflow: Workflow management</li> </ul>"},{"location":"getting-started/overview/#getting-started","title":"Getting Started","text":"<p>Ready to start? Follow these guides:</p> <ol> <li>Quick Start - Get up and running in 5 minutes</li> <li>Installation - Detailed installation instructions</li> <li>Configuration - Configure integrations and settings</li> <li>Architecture - Understand the system design</li> </ol>"},{"location":"getting-started/overview/#community-and-support","title":"Community and Support","text":"<ul> <li>Source Code: GitHub Repository</li> <li>Documentation: This site</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get the SEI Platform up and running in under 5 minutes.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed:</p> <ul> <li>Docker (20.10+)</li> <li>Docker Compose (2.0+)</li> <li>Git (2.30+)</li> </ul>"},{"location":"getting-started/quick-start/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/quick-start/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/rcdelacruz/open-source-sei-platform.git\ncd open-source-sei-platform\n</code></pre>"},{"location":"getting-started/quick-start/#2-configure-environment","title":"2. Configure Environment","text":"<pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> to add your API tokens (optional for initial setup):</p> <pre><code>GITHUB_TOKEN=your_github_token_here\nJIRA_API_TOKEN=your_jira_token_here\n</code></pre>"},{"location":"getting-started/quick-start/#3-start-the-platform","title":"3. Start the Platform","text":"<pre><code>make dev\n</code></pre> <p>Or using Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"getting-started/quick-start/#4-verify-installation","title":"4. Verify Installation","text":"<p>Check that all services are running:</p> <pre><code>docker-compose ps\n</code></pre> <p>Test the API:</p> <pre><code>curl http://localhost:8080/health\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"api-service\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-09-30T10:00:00.000000\"\n}\n</code></pre>"},{"location":"getting-started/quick-start/#access-the-services","title":"Access the Services","text":"<p>Once running, access the following services:</p> Service URL Credentials API Documentation http://localhost:8080/docs None API Service http://localhost:8080 None Frontend http://localhost:3002 None Metabase http://localhost:3000 Setup required Grafana http://localhost:3001 admin / admin123 Airflow http://localhost:8082 admin / admin123"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ol> <li>Explore the API: Visit http://localhost:8080/docs to see all available endpoints</li> <li>Configure Integrations: Add your GitHub, GitLab, or Jira credentials</li> <li>Review Architecture: Learn about the system design in the Architecture section</li> <li>Start Development: Follow the Development Guide</li> </ol>"},{"location":"getting-started/quick-start/#stopping-the-platform","title":"Stopping the Platform","text":"<p>To stop all services:</p> <pre><code>make dev-stop\n</code></pre> <p>Or:</p> <pre><code>docker-compose down\n</code></pre>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#port-conflicts","title":"Port Conflicts","text":"<p>If you encounter port conflicts, modify the port mappings in <code>docker-compose.yml</code>:</p> <pre><code>services:\n  api-service:\n    ports:\n      - \"8888:8080\"  # Change 8080 to 8888\n</code></pre>"},{"location":"getting-started/quick-start/#services-not-starting","title":"Services Not Starting","text":"<p>Check service logs:</p> <pre><code>docker-compose logs api-service\n</code></pre>"},{"location":"getting-started/quick-start/#database-connection-issues","title":"Database Connection Issues","text":"<p>Verify databases are running:</p> <pre><code>docker-compose ps postgresql timescaledb\n</code></pre> <p>Check the readiness endpoint:</p> <pre><code>curl http://localhost:8080/ready\n</code></pre>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Review the Full Installation Guide</li> <li>Check the Development Setup Guide</li> <li>Report issues on GitHub</li> </ul>"},{"location":"progress/completed-sprints/","title":"Completed Sprints","text":"<p>This document tracks all completed sprints with their deliverables, metrics, and lessons learned.</p>"},{"location":"progress/completed-sprints/#sprint-11-development-environment-setup","title":"Sprint 1.1: Development Environment Setup","text":"<p>Duration: Week 1 (September 23-30, 2025)</p> <p>Phase: Phase 1 - Foundation</p> <p>Status: Completed</p>"},{"location":"progress/completed-sprints/#goals","title":"Goals","text":"<p>Establish complete development environment with all core infrastructure components and service scaffolds.</p>"},{"location":"progress/completed-sprints/#deliverables","title":"Deliverables","text":"<p>Infrastructure Components:</p> <ul> <li>TimescaleDB for time-series metrics</li> <li>PostgreSQL for metadata storage</li> <li>Redis for caching</li> <li>Apache Kafka + Zookeeper for event streaming</li> <li>Prometheus + Grafana for monitoring</li> <li>Metabase for business intelligence</li> <li>Apache Airflow for workflow orchestration</li> <li>Kong API Gateway</li> <li>Kafka UI and PgAdmin management tools</li> </ul> <p>Application Services:</p> <ul> <li>API Service (FastAPI) with 12 endpoint scaffolds</li> <li>Git Collector service with GitHub/GitLab integration stubs</li> <li>Jira Collector service with API client framework</li> <li>Data Processor service with Kafka consumer setup</li> </ul> <p>Development Tools:</p> <ul> <li>Docker Compose configuration with 15+ services</li> <li>Makefile with 40+ automation commands</li> <li>Environment variable management</li> <li>Health check implementation for all services</li> </ul> <p>Documentation:</p> <ul> <li>Project README with quick start guide</li> <li>Architecture overview documentation</li> <li>API endpoint documentation</li> <li>Development setup guide</li> <li>Contributing guidelines</li> <li>Code of conduct</li> </ul> <p>Configuration Files:</p> <ul> <li>Docker Compose for development</li> <li>Docker Compose for production</li> <li>Kubernetes namespace configuration</li> <li>GitHub issue templates</li> <li>License and contributing docs</li> </ul>"},{"location":"progress/completed-sprints/#metrics","title":"Metrics","text":"Metric Target Actual Status Services Deployed 4 4 Achieved Infrastructure Components 10+ 15 Exceeded API Endpoints Scaffolded 10 12 Exceeded Documentation Pages 20 25+ Exceeded Docker Images Building 4 4 Achieved Services Starting Successfully 100% 100% Achieved"},{"location":"progress/completed-sprints/#achievements","title":"Achievements","text":"<p>Technical:</p> <ul> <li>All services build without errors</li> <li>Complete Docker Compose stack runs successfully</li> <li>Health checks functional for all services</li> <li>API documentation auto-generated via FastAPI</li> <li>Database connectivity verified</li> <li>Message queue operational</li> </ul> <p>Process:</p> <ul> <li>Development workflow established</li> <li>Automation via Makefile</li> <li>Clear project structure</li> <li>Comprehensive documentation</li> </ul>"},{"location":"progress/completed-sprints/#challenges","title":"Challenges","text":"<p>1. Docker Compose Service Dependencies:</p> <ul> <li>Problem: Services starting before dependencies ready</li> <li>Solution: Implemented health checks and depends_on conditions</li> <li>Lesson: Always use health checks for service orchestration</li> </ul> <p>2. TimescaleDB Configuration:</p> <ul> <li>Problem: Extension not loading automatically</li> <li>Solution: Created init script for extension setup</li> <li>Lesson: Database initialization scripts critical for automation</li> </ul> <p>3. Port Conflicts:</p> <ul> <li>Problem: Default ports conflicting with existing services</li> <li>Solution: Mapped to alternative host ports in docker-compose.yml</li> <li>Lesson: Document all port mappings clearly</li> </ul>"},{"location":"progress/completed-sprints/#team-feedback","title":"Team Feedback","text":"<p>What Went Well:</p> <ul> <li>Clear project structure made onboarding easy</li> <li>Automation with Makefile saved significant time</li> <li>Documentation helped new contributors</li> <li>Services integrated smoothly</li> </ul> <p>What Could Be Improved:</p> <ul> <li>Add more inline code comments</li> <li>Create video walkthrough for setup</li> <li>Improve error messages in services</li> <li>Add troubleshooting guide</li> </ul>"},{"location":"progress/completed-sprints/#lessons-learned","title":"Lessons Learned","text":"<ol> <li>Start with automation early: Makefile saved hours of repetitive commands</li> <li>Health checks are essential: Prevented race conditions in service startup</li> <li>Documentation is code: Good docs enabled faster development</li> <li>Test in clean environment: Caught several setup issues early</li> </ol>"},{"location":"progress/completed-sprints/#next-steps","title":"Next Steps","text":"<p>Outcomes feeding into Sprint 1.2:</p> <ul> <li>Database models need ORM implementation</li> <li>API endpoints need business logic</li> <li>Collectors need actual data fetching</li> <li>Processor needs event handling logic</li> </ul>"},{"location":"progress/completed-sprints/#sprint-retrospective","title":"Sprint Retrospective","text":"<p>Continue Doing:</p> <ul> <li>Comprehensive documentation</li> <li>Automation with Makefile</li> <li>Health check implementation</li> <li>Regular testing</li> </ul> <p>Start Doing:</p> <ul> <li>Unit testing from day one</li> <li>Performance benchmarking</li> <li>Security scanning</li> <li>Code review process</li> </ul> <p>Stop Doing:</p> <ul> <li>Manual configuration steps</li> <li>Skipping documentation updates</li> <li>Deferring error handling</li> </ul>"},{"location":"progress/completed-sprints/#future-sprints","title":"Future Sprints","text":""},{"location":"progress/completed-sprints/#sprint-12-data-models-database-layer","title":"Sprint 1.2: Data Models &amp; Database Layer","text":"<p>Planned: Week 2 (October 1-7, 2025)</p> <p>Status: In Progress</p> <p>Goals:</p> <ul> <li>Implement SQLAlchemy ORM models</li> <li>Create Alembic migration system</li> <li>Build repository pattern for data access</li> <li>Seed database with test data</li> <li>Achieve 80%+ test coverage</li> </ul> <p>Planned Deliverables:</p> <ul> <li>Complete ORM model layer</li> <li>Database migration scripts</li> <li>Repository pattern implementation</li> <li>Unit tests for all models</li> <li>Integration tests for database operations</li> </ul>"},{"location":"progress/completed-sprints/#sprint-13-basic-api-layer","title":"Sprint 1.3: Basic API Layer","text":"<p>Planned: Week 3 (October 8-14, 2025)</p> <p>Status: Planned</p> <p>Goals:</p> <ul> <li>Implement CRUD operations for all entities</li> <li>Add request validation</li> <li>Implement error handling</li> <li>Create API integration tests</li> <li>Document all endpoints</li> </ul> <p>Planned Deliverables:</p> <ul> <li>Functional CRUD endpoints</li> <li>Request/response validation</li> <li>Error handling middleware</li> <li>API integration test suite</li> <li>OpenAPI spec completion</li> </ul>"},{"location":"progress/completed-sprints/#sprint-14-git-data-collector-mvp","title":"Sprint 1.4: Git Data Collector MVP","text":"<p>Planned: Week 4 (October 15-21, 2025)</p> <p>Status: Planned</p> <p>Goals:</p> <ul> <li>Implement GitHub API integration</li> <li>Add data transformation logic</li> <li>Implement Kafka producer</li> <li>Create collector tests</li> <li>Handle rate limiting</li> </ul> <p>Planned Deliverables:</p> <ul> <li>Working GitHub collector</li> <li>Rate limiting implementation</li> <li>Data validation layer</li> <li>Collector unit tests</li> <li>Error handling and retries</li> </ul>"},{"location":"progress/completed-sprints/#sprint-template","title":"Sprint Template","text":"<p>For future sprint documentation:</p> <pre><code>## Sprint X.Y: [Sprint Name]\n\n**Duration**: [Dates]\n**Phase**: [Phase Name]\n**Status**: [Planned/In Progress/Completed]\n\n### Goals\n[Primary objectives]\n\n### Deliverables\n[What was built/delivered]\n\n### Metrics\n| Metric | Target | Actual | Status |\n|--------|--------|--------|--------|\n| ...    | ...    | ...    | ...    |\n\n### Achievements\n[Key accomplishments]\n\n### Challenges\n[Problems faced and solutions]\n\n### Team Feedback\n[Retrospective feedback]\n\n### Lessons Learned\n[Key takeaways]\n\n### Next Steps\n[Follow-up actions]\n</code></pre>"},{"location":"progress/completed-sprints/#resources","title":"Resources","text":"<ul> <li>Current Status</li> <li>Upcoming Work</li> <li>Contributing Guidelines</li> </ul>"},{"location":"progress/current-status/","title":"Current Status","text":""},{"location":"progress/current-status/#project-information","title":"Project Information","text":"<p>Version: 0.1.0 Phase: 1 - Foundation &amp; Core Infrastructure Sprint: 1.1 Complete Last Updated: September 30, 2025</p>"},{"location":"progress/current-status/#implementation-progress","title":"Implementation Progress","text":""},{"location":"progress/current-status/#phase-1-foundation-core-infrastructure","title":"Phase 1: Foundation &amp; Core Infrastructure","text":"Sprint Status Progress Completion Date 1.1: Development Environment Setup Complete 100% 2025-09-30 1.2: Data Models &amp; Database Layer Planned 0% Target: 2025-10-07 1.3: Basic API Layer Planned 0% Target: 2025-10-14 1.4: Git Data Collector - MVP Planned 0% Target: 2025-10-21"},{"location":"progress/current-status/#sprint-11-accomplishments","title":"Sprint 1.1 Accomplishments","text":""},{"location":"progress/current-status/#services-implemented","title":"Services Implemented","text":"<p>Four fully functional microservices:</p> <ol> <li>API Service (Port 8080) - FastAPI REST API</li> <li>Git Collector (Port 8000) - GitHub/GitLab integration</li> <li>Jira Collector (Port 8001) - Project management integration</li> <li>Data Processor (Port 8002) - Event processing</li> </ol>"},{"location":"progress/current-status/#infrastructure-deployed","title":"Infrastructure Deployed","text":"<p>Complete development stack with 15+ services:</p> <ul> <li>TimescaleDB - Time-series database</li> <li>PostgreSQL - Metadata storage</li> <li>Redis - Caching layer</li> <li>Apache Kafka + Zookeeper - Event streaming</li> <li>Metabase - Business intelligence</li> <li>Grafana + Prometheus - Monitoring</li> <li>Apache Airflow - Workflow orchestration</li> <li>Kafka UI &amp; PgAdmin - Admin tools</li> </ul>"},{"location":"progress/current-status/#api-endpoints","title":"API Endpoints","text":"<p>12 endpoint scaffolds created:</p> <ul> <li>Organizations CRUD operations</li> <li>Teams management</li> <li>Repositories tracking</li> <li>Developers management</li> <li>DORA metrics analytics</li> <li>Team performance analytics</li> </ul>"},{"location":"progress/current-status/#documentation","title":"Documentation","text":"<p>Comprehensive documentation created:</p> <ul> <li>Development setup guide</li> <li>Architecture overview</li> <li>API reference documentation</li> <li>Configuration guide</li> <li>Installation instructions</li> </ul>"},{"location":"progress/current-status/#key-metrics","title":"Key Metrics","text":"Metric Current Target (Phase 1) Services Implemented 4/4 4/4 API Endpoints 12 (scaffolded) 20+ (functional) Test Coverage 0% 80%+ Documentation Pages 25+ 30+ Docker Images 4/4 building 4/4 tested"},{"location":"progress/current-status/#current-capabilities","title":"Current Capabilities","text":""},{"location":"progress/current-status/#operational","title":"Operational","text":"<ul> <li>All services build successfully</li> <li>Docker Compose stack runs without errors</li> <li>Health checks functional across services</li> <li>Database connectivity verified</li> <li>API documentation auto-generated</li> </ul>"},{"location":"progress/current-status/#in-development","title":"In Development","text":"<ul> <li>Database ORM models</li> <li>Repository pattern implementation</li> <li>CRUD operations</li> <li>Data collection logic</li> <li>Analytics calculations</li> </ul>"},{"location":"progress/current-status/#planned","title":"Planned","text":"<ul> <li>Frontend React application</li> <li>Real-time WebSocket updates</li> <li>ML-based predictions</li> <li>Multi-tenant support</li> <li>Advanced security features</li> </ul>"},{"location":"progress/current-status/#technical-debt","title":"Technical Debt","text":"<p>None currently. Project just started.</p>"},{"location":"progress/current-status/#known-issues","title":"Known Issues","text":"<p>None blocking. Minor issues:</p> <ul> <li>TimescaleDB shows authentication warnings (cosmetic)</li> <li>Docker Compose version warning (cosmetic)</li> </ul>"},{"location":"progress/current-status/#next-sprint-goals","title":"Next Sprint Goals","text":""},{"location":"progress/current-status/#sprint-12-data-models-database-layer","title":"Sprint 1.2: Data Models &amp; Database Layer","text":"<p>Planned for Week 2 (Target: October 7, 2025):</p> <ol> <li>Create SQLAlchemy ORM models</li> <li>Implement Alembic migrations</li> <li>Build repository pattern</li> <li>Create database seed scripts</li> <li>Achieve 80%+ test coverage</li> </ol>"},{"location":"progress/current-status/#success-criteria","title":"Success Criteria","text":"<ul> <li>All database models created and tested</li> <li>Alembic migrations functional</li> <li>CRUD operations working via repository pattern</li> <li>Database seeded with test data</li> <li>Comprehensive unit test coverage</li> </ul>"},{"location":"progress/current-status/#development-activity","title":"Development Activity","text":""},{"location":"progress/current-status/#files-created","title":"Files Created","text":"<p>40+ files totaling 2,500+ lines of code:</p> <ul> <li>4 Dockerfiles with health checks</li> <li>17 API service files</li> <li>7 Git collector files</li> <li>7 Jira collector files</li> <li>6 Data processor files</li> <li>5+ documentation files</li> </ul>"},{"location":"progress/current-status/#configuration","title":"Configuration","text":"<ul> <li>MkDocs documentation site configured</li> <li>Docker Compose with 15+ services</li> <li>Environment variable management</li> <li>Development workflow automation (Makefile)</li> </ul>"},{"location":"progress/current-status/#resource-links","title":"Resource Links","text":"<ul> <li>Source Code</li> <li>API Documentation</li> <li>Contributing Guidelines</li> </ul>"},{"location":"progress/current-status/#timeline","title":"Timeline","text":""},{"location":"progress/current-status/#completed","title":"Completed","text":"<ul> <li>2025-09-30: Sprint 1.1 Complete - Development Environment Setup</li> </ul>"},{"location":"progress/current-status/#upcoming","title":"Upcoming","text":"<ul> <li>2025-10-07: Sprint 1.2 Target - Data Models &amp; Database Layer</li> <li>2025-10-14: Sprint 1.3 Target - Basic API Layer</li> <li>2025-10-21: Sprint 1.4 Target - Git Data Collector MVP</li> </ul>"},{"location":"progress/current-status/#get-involved","title":"Get Involved","text":"<p>Ready to contribute? See:</p> <ul> <li>Development Setup</li> <li>Contributing Guidelines</li> <li>Architecture Overview</li> </ul>"},{"location":"progress/upcoming-work/","title":"Upcoming Work","text":"<p>This document outlines planned work for upcoming sprints and future phases of the SEI Platform.</p>"},{"location":"progress/upcoming-work/#current-sprint-12-data-models-database-layer","title":"Current Sprint: 1.2 - Data Models &amp; Database Layer","text":"<p>Duration: Week 2 (October 1-7, 2025)</p> <p>Status: In Progress</p>"},{"location":"progress/upcoming-work/#primary-objectives","title":"Primary Objectives","text":"<ol> <li>Implement comprehensive ORM models using SQLAlchemy</li> <li>Create Alembic migration system for schema versioning</li> <li>Build repository pattern for clean data access</li> <li>Seed database with realistic test data</li> <li>Establish 80%+ test coverage for data layer</li> </ol>"},{"location":"progress/upcoming-work/#detailed-tasks","title":"Detailed Tasks","text":"<p>Database Models:</p> <ul> <li> Organization model with relationships</li> <li> Team model with member associations</li> <li> Repository model with statistics</li> <li> Developer model with activity tracking</li> <li> Commit model with metadata</li> <li> Pull Request model with review data</li> <li> Deployment model with DORA metrics</li> <li> Incident model for failure tracking</li> <li> Metric model for analytics storage</li> </ul> <p>Alembic Migrations:</p> <ul> <li> Initialize Alembic configuration</li> <li> Create initial migration script</li> <li> Add TimescaleDB hypertable setup</li> <li> Create indexes for performance</li> <li> Add constraints and foreign keys</li> <li> Document migration process</li> </ul> <p>Repository Pattern:</p> <ul> <li> Base repository with common CRUD operations</li> <li> Organization repository</li> <li> Team repository</li> <li> Developer repository</li> <li> Metrics repository</li> <li> Transaction management</li> <li> Error handling</li> </ul> <p>Testing:</p> <ul> <li> Unit tests for all models</li> <li> Repository pattern tests</li> <li> Migration tests</li> <li> Integration tests with database</li> <li> Performance benchmarks</li> </ul> <p>Documentation:</p> <ul> <li> Database schema documentation</li> <li> Model relationship diagrams</li> <li> Repository pattern guide</li> <li> Migration guide</li> </ul>"},{"location":"progress/upcoming-work/#success-criteria","title":"Success Criteria","text":"<ul> <li>All models created with proper relationships</li> <li>Migrations run successfully</li> <li>Repository pattern functional for all entities</li> <li>80%+ test coverage achieved</li> <li>Database can be seeded with test data</li> <li>Documentation complete</li> </ul>"},{"location":"progress/upcoming-work/#risks-and-mitigation","title":"Risks and Mitigation","text":"<p>Risk: TimescaleDB specific features may require custom migration logic</p> <ul> <li>Mitigation: Research TimescaleDB best practices early</li> <li>Mitigation: Create helper functions for hypertable setup</li> </ul> <p>Risk: Complex relationships may impact query performance</p> <ul> <li>Mitigation: Implement eager loading where needed</li> <li>Mitigation: Add database indexes strategically</li> </ul>"},{"location":"progress/upcoming-work/#next-sprint-13-basic-api-layer","title":"Next Sprint: 1.3 - Basic API Layer","text":"<p>Duration: Week 3 (October 8-14, 2025)</p> <p>Status: Planned</p>"},{"location":"progress/upcoming-work/#primary-objectives_1","title":"Primary Objectives","text":"<ol> <li>Implement functional CRUD operations for all entities</li> <li>Add comprehensive request/response validation</li> <li>Implement robust error handling</li> <li>Create integration test suite</li> <li>Complete API documentation</li> </ol>"},{"location":"progress/upcoming-work/#planned-tasks","title":"Planned Tasks","text":"<p>API Implementation:</p> <ul> <li> Organization CRUD endpoints</li> <li> Team management endpoints</li> <li> Repository management endpoints</li> <li> Developer profile endpoints</li> <li> Metrics query endpoints</li> <li> Search and filter functionality</li> <li> Pagination implementation</li> <li> Sorting capabilities</li> </ul> <p>Validation &amp; Security:</p> <ul> <li> Pydantic models for request validation</li> <li> Response serialization</li> <li> Input sanitization</li> <li> API key authentication</li> <li> Rate limiting per endpoint</li> <li> CORS configuration</li> </ul> <p>Error Handling:</p> <ul> <li> Custom exception classes</li> <li> Error response formatting</li> <li> Logging integration</li> <li> HTTP status code mapping</li> <li> Validation error messages</li> </ul> <p>Testing:</p> <ul> <li> Integration tests for all endpoints</li> <li> Authentication tests</li> <li> Error handling tests</li> <li> Performance tests</li> <li> Load testing</li> </ul>"},{"location":"progress/upcoming-work/#success-criteria_1","title":"Success Criteria","text":"<ul> <li>All CRUD operations functional</li> <li>Validation prevents invalid requests</li> <li>Errors return meaningful messages</li> <li>90%+ test coverage for API layer</li> <li>API documentation complete and accurate</li> <li>Response times &lt; 200ms for simple queries</li> </ul>"},{"location":"progress/upcoming-work/#sprint-14-git-data-collector-mvp","title":"Sprint 1.4: Git Data Collector MVP","text":"<p>Duration: Week 4 (October 15-21, 2025)</p> <p>Status: Planned</p>"},{"location":"progress/upcoming-work/#primary-objectives_2","title":"Primary Objectives","text":"<ol> <li>Implement GitHub API integration</li> <li>Transform and validate collected data</li> <li>Publish events to Kafka</li> <li>Handle rate limiting gracefully</li> <li>Achieve comprehensive test coverage</li> </ol>"},{"location":"progress/upcoming-work/#planned-tasks_1","title":"Planned Tasks","text":"<p>GitHub Integration:</p> <ul> <li> GitHub API client with authentication</li> <li> Repository data collection</li> <li> Commit history fetching</li> <li> Pull request data collection</li> <li> Webhook handler for real-time events</li> <li> Rate limit handling</li> <li> Retry logic with exponential backoff</li> </ul> <p>Data Processing:</p> <ul> <li> Data transformation layer</li> <li> Validation logic</li> <li> Deduplication handling</li> <li> Incremental collection strategy</li> <li> Error recovery</li> </ul> <p>Kafka Integration:</p> <ul> <li> Kafka producer configuration</li> <li> Event serialization</li> <li> Topic management</li> <li> Delivery confirmation</li> <li> Dead letter queue setup</li> </ul> <p>Testing:</p> <ul> <li> Unit tests for all components</li> <li> Integration tests with GitHub API</li> <li> Kafka producer tests</li> <li> Rate limiting tests</li> <li> Error scenario testing</li> </ul>"},{"location":"progress/upcoming-work/#success-criteria_2","title":"Success Criteria","text":"<ul> <li>Successfully collect data from GitHub</li> <li>Transform data to internal format</li> <li>Publish events to Kafka reliably</li> <li>Handle rate limits without failures</li> <li>85%+ test coverage</li> <li>Process 1000+ repositories without errors</li> </ul>"},{"location":"progress/upcoming-work/#phase-1-remaining-work","title":"Phase 1 Remaining Work","text":""},{"location":"progress/upcoming-work/#month-2-data-collection-framework-weeks-5-8","title":"Month 2: Data Collection Framework (Weeks 5-8)","text":"<p>GitLab Integration:</p> <ul> <li>GitLab API collector service</li> <li>Data transformation for GitLab</li> <li>Testing with GitLab repositories</li> </ul> <p>Jira Integration:</p> <ul> <li>Jira API collector implementation</li> <li>Issue and epic data collection</li> <li>Sprint and milestone tracking</li> <li>Integration with development data</li> </ul> <p>Webhook Handling:</p> <ul> <li>Real-time event processing</li> <li>Webhook security</li> <li>Event deduplication</li> <li>Scalability testing</li> </ul>"},{"location":"progress/upcoming-work/#month-3-basic-analytics-pipeline-weeks-9-12","title":"Month 3: Basic Analytics Pipeline (Weeks 9-12)","text":"<p>Data Processing:</p> <ul> <li>Apache Spark job implementation</li> <li>DORA metrics calculation</li> <li>Team velocity tracking</li> <li>Data quality monitoring</li> </ul> <p>Frontend Foundation:</p> <ul> <li>React dashboard framework</li> <li>Authentication UI</li> <li>Basic metrics visualization</li> <li>Responsive design</li> </ul> <p>Phase 1 Completion:</p> <ul> <li>System integration testing</li> <li>Performance optimization</li> <li>Documentation completion</li> <li>Phase 1 review and retrospective</li> </ul>"},{"location":"progress/upcoming-work/#phase-2-preview-core-features-months-4-6","title":"Phase 2 Preview: Core Features (Months 4-6)","text":""},{"location":"progress/upcoming-work/#planned-highlights","title":"Planned Highlights","text":"<p>DORA Metrics Engine:</p> <ul> <li>Deployment frequency calculation</li> <li>Lead time for changes tracking</li> <li>Change failure rate monitoring</li> <li>Mean time to recovery</li> </ul> <p>Team Performance Analytics:</p> <ul> <li>Velocity trend analysis</li> <li>Burndown/burnup charts</li> <li>Cycle time breakdown</li> <li>Bottleneck identification</li> </ul> <p>Advanced Integrations:</p> <ul> <li>Jenkins, GitHub Actions, GitLab CI</li> <li>Slack and Microsoft Teams</li> <li>Build and deployment tracking</li> </ul> <p>Real-time Processing:</p> <ul> <li>Streaming analytics</li> <li>Live dashboards</li> <li>Anomaly detection</li> <li>Automated alerting</li> </ul>"},{"location":"progress/upcoming-work/#long-term-roadmap-highlights","title":"Long-term Roadmap Highlights","text":""},{"location":"progress/upcoming-work/#phase-3-advanced-analytics-months-7-9","title":"Phase 3: Advanced Analytics (Months 7-9)","text":"<ul> <li>Machine learning pipeline</li> <li>Predictive analytics models</li> <li>Custom metrics framework</li> <li>Mobile applications</li> </ul>"},{"location":"progress/upcoming-work/#phase-4-enterprise-features-months-10-12","title":"Phase 4: Enterprise Features (Months 10-12)","text":"<ul> <li>Multi-tenant architecture</li> <li>Enterprise security</li> <li>Performance optimization at scale</li> <li>Complete documentation</li> </ul>"},{"location":"progress/upcoming-work/#how-to-contribute","title":"How to Contribute","text":""},{"location":"progress/upcoming-work/#pick-up-tasks","title":"Pick Up Tasks","text":"<ol> <li>Review upcoming sprint tasks</li> <li>Check GitHub issues tagged with sprint number</li> <li>Comment on issue to claim task</li> <li>Create PR following guidelines</li> </ol>"},{"location":"progress/upcoming-work/#propose-new-work","title":"Propose New Work","text":"<ol> <li>Check if aligned with current phase</li> <li>Create feature proposal issue</li> <li>Discuss with maintainers</li> <li>Get approval before starting</li> </ol>"},{"location":"progress/upcoming-work/#stay-updated","title":"Stay Updated","text":"<ul> <li>Watch this document for updates</li> <li>Join sprint planning meetings</li> <li>Subscribe to GitHub notifications</li> <li>Check Discord #development channel</li> </ul>"},{"location":"progress/upcoming-work/#resources","title":"Resources","text":"<ul> <li>Current Status</li> <li>Completed Sprints</li> <li>Contributing Guidelines</li> <li>GitHub Issues</li> </ul>"},{"location":"progress/upcoming-work/#questions","title":"Questions?","text":"<ul> <li>Ask in GitHub Discussions</li> <li>Join Discord #development channel</li> <li>Email dev@sei-platform.org</li> </ul> <p>Last Updated: October 1, 2025</p> <p>Next Update: Weekly on Mondays</p>"},{"location":"services/api-service/","title":"API Service","text":"<p>The API Service is the main REST API layer of the SEI platform. It provides endpoints for accessing all platform data, metrics, and analytics. The service acts as the primary interface for frontend applications and external integrations.</p>"},{"location":"services/api-service/#overview","title":"Overview","text":"<p>The service is built using FastAPI and provides a comprehensive REST API for the SEI platform. It connects to both TimescaleDB for time-series data and PostgreSQL for metadata storage.</p>"},{"location":"services/api-service/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Serve REST API endpoints for all resources</li> <li>Query and aggregate metrics data</li> <li>Manage organizations, teams, and users</li> <li>Provide authentication and authorization</li> <li>Handle data validation and transformation</li> <li>Serve real-time updates via WebSockets</li> </ul>"},{"location":"services/api-service/#architecture","title":"Architecture","text":""},{"location":"services/api-service/#service-components","title":"Service Components","text":"<p>Main Application (<code>main.py</code>)</p> <ul> <li>FastAPI application with CORS middleware</li> <li>Structured logging using structlog</li> <li>Database connection management</li> <li>Route registration and lifecycle management</li> </ul> <p>Routes</p> <ul> <li><code>/health</code> - Service health check</li> <li><code>/api/v1/organizations</code> - Organization management</li> <li><code>/api/v1/teams</code> - Team management</li> <li><code>/api/v1/repositories</code> - Repository information</li> <li><code>/api/v1/developers</code> - Developer metrics</li> <li><code>/api/v1/analytics</code> - Analytics and metrics</li> </ul> <p>Database (<code>database.py</code>)</p> <ul> <li>SQLAlchemy ORM configuration</li> <li>Database connection pooling</li> <li>Session management</li> <li>Model base classes</li> </ul> <p>Configuration (<code>config.py</code>)</p> <ul> <li>Environment-based configuration</li> <li>Database connection settings</li> <li>CORS configuration</li> <li>Security settings</li> </ul>"},{"location":"services/api-service/#data-flow","title":"Data Flow","text":"<pre><code>Frontend/Clients \u2192 API Service \u2192 TimescaleDB (metrics)\n                                \u2192 PostgreSQL (metadata)\n                                \u2192 Redis (cache)\n</code></pre>"},{"location":"services/api-service/#configuration","title":"Configuration","text":""},{"location":"services/api-service/#environment-variables","title":"Environment Variables","text":"Variable Description Required Default <code>TIMESCALE_URL</code> TimescaleDB connection URL Yes - <code>POSTGRES_URL</code> PostgreSQL connection URL Yes - <code>REDIS_URL</code> Redis connection URL Yes <code>redis://redis:6379</code> <code>LOG_LEVEL</code> Logging level No <code>INFO</code> <code>CORS_ORIGINS</code> Allowed CORS origins No <code>*</code> <code>DEBUG</code> Enable debug mode No <code>false</code> <code>SECRET_KEY</code> JWT secret key Yes - <code>ACCESS_TOKEN_EXPIRE_MINUTES</code> Token expiration No <code>30</code>"},{"location":"services/api-service/#docker-configuration","title":"Docker Configuration","text":"<p>The service is configured in <code>docker-compose.yml</code>:</p> <pre><code>api-service:\n  build:\n    context: ./src/apis\n    dockerfile: Dockerfile\n  container_name: sei-api-service\n  depends_on:\n    - timescaledb\n    - postgresql\n    - redis\n  environment:\n    TIMESCALE_URL: postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\n    POSTGRES_URL: postgresql://sei_user:sei_password@postgresql:5432/sei_metadata\n    REDIS_URL: redis://redis:6379\n    LOG_LEVEL: INFO\n  ports:\n    - \"8080:8080\"\n</code></pre>"},{"location":"services/api-service/#development","title":"Development","text":""},{"location":"services/api-service/#local-setup","title":"Local Setup","text":"<ol> <li> <p>Navigate to the service directory:</p> <pre><code>cd src/apis\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the service:</p> <pre><code>python main.py\n</code></pre> </li> </ol> <p>The service will start on <code>http://localhost:8080</code>.</p>"},{"location":"services/api-service/#running-with-docker","title":"Running with Docker","text":"<pre><code>docker-compose up api-service\n</code></pre>"},{"location":"services/api-service/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/apis/\n</code></pre>"},{"location":"services/api-service/#api-documentation","title":"API Documentation","text":"<p>Once running, visit:</p> <ul> <li>Swagger UI: <code>http://localhost:8080/docs</code></li> <li>ReDoc: <code>http://localhost:8080/redoc</code></li> <li>OpenAPI JSON: <code>http://localhost:8080/openapi.json</code></li> </ul>"},{"location":"services/api-service/#api-endpoints","title":"API Endpoints","text":""},{"location":"services/api-service/#root-endpoint","title":"Root Endpoint","text":"<p>GET /</p> <p>Returns API information and available endpoints.</p> <p>Response</p> <pre><code>{\n  \"service\": \"SEI Platform API\",\n  \"version\": \"0.1.0\",\n  \"status\": \"operational\",\n  \"docs\": \"/docs\",\n  \"health\": \"/health\"\n}\n</code></pre>"},{"location":"services/api-service/#health-check","title":"Health Check","text":"<p>GET /health</p> <p>Returns service health status and dependency connectivity.</p> <p>Response</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"dependencies\": {\n    \"timescaledb\": \"connected\",\n    \"postgresql\": \"connected\",\n    \"redis\": \"connected\"\n  }\n}\n</code></pre>"},{"location":"services/api-service/#organizations-api","title":"Organizations API","text":"<p>GET /api/v1/organizations</p> <p>List all organizations with pagination.</p> <p>Query Parameters</p> <ul> <li><code>skip</code> (integer, optional): Number of records to skip. Default: <code>0</code></li> <li><code>limit</code> (integer, optional): Maximum records to return. Default: <code>100</code></li> </ul> <p>Response</p> <pre><code>{\n  \"total\": 50,\n  \"items\": [\n    {\n      \"id\": \"org-123\",\n      \"name\": \"Acme Corporation\",\n      \"created_at\": \"2025-01-01T00:00:00Z\",\n      \"updated_at\": \"2025-10-01T12:00:00Z\"\n    }\n  ]\n}\n</code></pre> <p>POST /api/v1/organizations</p> <p>Create a new organization.</p> <p>Request Body</p> <pre><code>{\n  \"name\": \"New Organization\",\n  \"description\": \"Organization description\",\n  \"settings\": {\n    \"timezone\": \"UTC\",\n    \"default_language\": \"en\"\n  }\n}\n</code></pre> <p>GET /api/v1/organizations/{organization_id}</p> <p>Get organization details by ID.</p> <p>PUT /api/v1/organizations/{organization_id}</p> <p>Update an organization.</p> <p>DELETE /api/v1/organizations/{organization_id}</p> <p>Delete an organization.</p>"},{"location":"services/api-service/#teams-api","title":"Teams API","text":"<p>GET /api/v1/teams</p> <p>List all teams with filtering and pagination.</p> <p>Query Parameters</p> <ul> <li><code>organization_id</code> (string, optional): Filter by organization</li> <li><code>skip</code> (integer, optional): Number of records to skip. Default: <code>0</code></li> <li><code>limit</code> (integer, optional): Maximum records to return. Default: <code>100</code></li> </ul> <p>Response</p> <pre><code>{\n  \"total\": 25,\n  \"items\": [\n    {\n      \"id\": \"team-456\",\n      \"name\": \"Platform Team\",\n      \"organization_id\": \"org-123\",\n      \"members_count\": 8,\n      \"created_at\": \"2025-01-15T00:00:00Z\"\n    }\n  ]\n}\n</code></pre> <p>POST /api/v1/teams</p> <p>Create a new team.</p> <p>GET /api/v1/teams/{team_id}</p> <p>Get team details including members and metrics.</p> <p>PUT /api/v1/teams/{team_id}</p> <p>Update team information.</p> <p>DELETE /api/v1/teams/{team_id}</p> <p>Delete a team.</p>"},{"location":"services/api-service/#repositories-api","title":"Repositories API","text":"<p>GET /api/v1/repositories</p> <p>List repositories with filtering.</p> <p>Query Parameters</p> <ul> <li><code>team_id</code> (string, optional): Filter by team</li> <li><code>organization_id</code> (string, optional): Filter by organization</li> <li><code>skip</code> (integer, optional): Number of records to skip. Default: <code>0</code></li> <li><code>limit</code> (integer, optional): Maximum records to return. Default: <code>100</code></li> </ul> <p>Response</p> <pre><code>{\n  \"total\": 150,\n  \"items\": [\n    {\n      \"id\": \"repo-789\",\n      \"name\": \"backend-api\",\n      \"url\": \"https://github.com/org/backend-api\",\n      \"language\": \"Python\",\n      \"team_id\": \"team-456\",\n      \"last_commit\": \"2025-10-01T10:30:00Z\",\n      \"commit_count\": 1250\n    }\n  ]\n}\n</code></pre> <p>POST /api/v1/repositories</p> <p>Register a new repository.</p> <p>GET /api/v1/repositories/{repository_id}</p> <p>Get repository details and statistics.</p> <p>GET /api/v1/repositories/{repository_id}/commits</p> <p>Get commit history for a repository.</p> <p>GET /api/v1/repositories/{repository_id}/pull-requests</p> <p>Get pull requests for a repository.</p>"},{"location":"services/api-service/#developers-api","title":"Developers API","text":"<p>GET /api/v1/developers</p> <p>List developers with metrics.</p> <p>Query Parameters</p> <ul> <li><code>team_id</code> (string, optional): Filter by team</li> <li><code>skip</code> (integer, optional): Number of records to skip. Default: <code>0</code></li> <li><code>limit</code> (integer, optional): Maximum records to return. Default: <code>100</code></li> </ul> <p>Response</p> <pre><code>{\n  \"total\": 75,\n  \"items\": [\n    {\n      \"id\": \"dev-101\",\n      \"name\": \"John Doe\",\n      \"email\": \"john@example.com\",\n      \"team_id\": \"team-456\",\n      \"metrics\": {\n        \"commits_last_30d\": 45,\n        \"prs_opened\": 12,\n        \"prs_reviewed\": 25,\n        \"lines_added\": 2500,\n        \"lines_deleted\": 800\n      }\n    }\n  ]\n}\n</code></pre> <p>GET /api/v1/developers/{developer_id}</p> <p>Get developer details and comprehensive metrics.</p> <p>GET /api/v1/developers/{developer_id}/activity</p> <p>Get developer activity timeline.</p>"},{"location":"services/api-service/#analytics-api","title":"Analytics API","text":"<p>GET /api/v1/analytics/dora-metrics</p> <p>Get DORA metrics for specified time range.</p> <p>Query Parameters</p> <ul> <li><code>team_id</code> (string, optional): Filter by team</li> <li><code>repository_id</code> (string, optional): Filter by repository</li> <li><code>start_date</code> (string, required): Start date (ISO 8601)</li> <li><code>end_date</code> (string, required): End date (ISO 8601)</li> <li><code>granularity</code> (string, optional): <code>daily</code>, <code>weekly</code>, <code>monthly</code>. Default: <code>daily</code></li> </ul> <p>Response</p> <pre><code>{\n  \"deployment_frequency\": {\n    \"value\": 15.2,\n    \"unit\": \"per_week\",\n    \"trend\": \"increasing\"\n  },\n  \"lead_time_for_changes\": {\n    \"median_hours\": 4.5,\n    \"p90_hours\": 12.0,\n    \"trend\": \"decreasing\"\n  },\n  \"change_failure_rate\": {\n    \"percentage\": 5.2,\n    \"trend\": \"stable\"\n  },\n  \"time_to_restore\": {\n    \"median_hours\": 2.0,\n    \"p90_hours\": 6.5,\n    \"trend\": \"decreasing\"\n  }\n}\n</code></pre> <p>GET /api/v1/analytics/velocity</p> <p>Get team velocity metrics.</p> <p>Query Parameters</p> <ul> <li><code>team_id</code> (string, required): Team identifier</li> <li><code>sprint_count</code> (integer, optional): Number of sprints. Default: <code>6</code></li> </ul> <p>Response</p> <pre><code>{\n  \"sprints\": [\n    {\n      \"sprint_id\": \"sprint-10\",\n      \"name\": \"Sprint 10\",\n      \"start_date\": \"2025-09-15\",\n      \"end_date\": \"2025-09-29\",\n      \"planned_points\": 50,\n      \"completed_points\": 48,\n      \"velocity\": 48,\n      \"completion_rate\": 0.96\n    }\n  ],\n  \"average_velocity\": 46.5,\n  \"trend\": \"stable\"\n}\n</code></pre> <p>GET /api/v1/analytics/code-quality</p> <p>Get code quality metrics.</p> <p>Query Parameters</p> <ul> <li><code>repository_id</code> (string, optional): Filter by repository</li> <li><code>team_id</code> (string, optional): Filter by team</li> <li><code>start_date</code> (string, required): Start date</li> <li><code>end_date</code> (string, required): End date</li> </ul> <p>Response</p> <pre><code>{\n  \"test_coverage\": 85.5,\n  \"code_smells\": 23,\n  \"technical_debt_hours\": 45.5,\n  \"security_issues\": 2,\n  \"bugs\": 8,\n  \"vulnerabilities\": 1\n}\n</code></pre> <p>GET /api/v1/analytics/cycle-time</p> <p>Get cycle time breakdown.</p> <p>Query Parameters</p> <ul> <li><code>team_id</code> (string, optional): Filter by team</li> <li><code>start_date</code> (string, required): Start date</li> <li><code>end_date</code> (string, required): End date</li> </ul> <p>Response</p> <pre><code>{\n  \"total_cycle_time_hours\": 72.5,\n  \"breakdown\": {\n    \"coding_hours\": 24.0,\n    \"review_hours\": 18.5,\n    \"testing_hours\": 16.0,\n    \"deployment_hours\": 14.0\n  },\n  \"percentiles\": {\n    \"p50\": 65.0,\n    \"p75\": 85.0,\n    \"p90\": 120.0\n  }\n}\n</code></pre>"},{"location":"services/api-service/#database-models","title":"Database Models","text":""},{"location":"services/api-service/#sqlalchemy-models","title":"SQLAlchemy Models","text":"<p>Organization</p> <pre><code>class Organization(Base):\n    __tablename__ = \"organizations\"\n\n    id = Column(String, primary_key=True)\n    name = Column(String, nullable=False)\n    description = Column(Text)\n    settings = Column(JSON)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, onupdate=datetime.utcnow)\n</code></pre> <p>Team</p> <pre><code>class Team(Base):\n    __tablename__ = \"teams\"\n\n    id = Column(String, primary_key=True)\n    name = Column(String, nullable=False)\n    organization_id = Column(String, ForeignKey(\"organizations.id\"))\n    description = Column(Text)\n    created_at = Column(DateTime, default=datetime.utcnow)\n</code></pre> <p>Repository</p> <pre><code>class Repository(Base):\n    __tablename__ = \"repositories\"\n\n    id = Column(String, primary_key=True)\n    name = Column(String, nullable=False)\n    url = Column(String, unique=True)\n    team_id = Column(String, ForeignKey(\"teams.id\"))\n    language = Column(String)\n    created_at = Column(DateTime, default=datetime.utcnow)\n</code></pre>"},{"location":"services/api-service/#authentication","title":"Authentication","text":""},{"location":"services/api-service/#jwt-authentication","title":"JWT Authentication","text":"<p>The API uses JWT tokens for authentication.</p> <p>POST /api/v1/auth/login</p> <p>Login and receive JWT token.</p> <p>Request Body</p> <pre><code>{\n  \"username\": \"user@example.com\",\n  \"password\": \"secure_password\"\n}\n</code></pre> <p>Response</p> <pre><code>{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 1800\n}\n</code></pre> <p>Using the Token</p> <p>Include the token in the Authorization header:</p> <pre><code>Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\n</code></pre>"},{"location":"services/api-service/#caching-strategy","title":"Caching Strategy","text":""},{"location":"services/api-service/#redis-caching","title":"Redis Caching","text":"<p>The API uses Redis for caching frequently accessed data:</p> <ul> <li>Organization and team information</li> <li>Repository metadata</li> <li>User profiles</li> <li>Recent metrics queries</li> </ul>"},{"location":"services/api-service/#cache-keys","title":"Cache Keys","text":"<ul> <li><code>api:org:{organization_id}</code> - Organization cache</li> <li><code>api:team:{team_id}</code> - Team cache</li> <li><code>api:repo:{repository_id}</code> - Repository cache</li> <li><code>api:metrics:{query_hash}</code> - Metrics query cache</li> </ul>"},{"location":"services/api-service/#cache-ttl","title":"Cache TTL","text":"<ul> <li>Organizations: 1 hour</li> <li>Teams: 30 minutes</li> <li>Repositories: 15 minutes</li> <li>Metrics: 5 minutes</li> </ul>"},{"location":"services/api-service/#monitoring","title":"Monitoring","text":""},{"location":"services/api-service/#health-checks","title":"Health Checks","text":"<p>The service provides comprehensive health checks:</p> <ul> <li>Database connectivity</li> <li>Redis connectivity</li> <li>API responsiveness</li> <li>Dependency status</li> </ul>"},{"location":"services/api-service/#metrics","title":"Metrics","text":"<p>Prometheus metrics are exposed at <code>/metrics</code>:</p> <ul> <li><code>api_requests_total</code> - Total API requests</li> <li><code>api_requests_duration_seconds</code> - Request duration</li> <li><code>api_requests_failed_total</code> - Failed requests</li> <li><code>api_active_connections</code> - Active connections</li> <li><code>api_database_queries_total</code> - Database queries</li> </ul>"},{"location":"services/api-service/#logging","title":"Logging","text":"<p>Structured JSON logging includes:</p> <ul> <li>Request/response logging</li> <li>Database query logging</li> <li>Error tracking</li> <li>Performance metrics</li> <li>Security events</li> </ul>"},{"location":"services/api-service/#error-handling","title":"Error Handling","text":""},{"location":"services/api-service/#http-status-codes","title":"HTTP Status Codes","text":"<ul> <li><code>200</code> - Success</li> <li><code>201</code> - Created</li> <li><code>400</code> - Bad Request</li> <li><code>401</code> - Unauthorized</li> <li><code>403</code> - Forbidden</li> <li><code>404</code> - Not Found</li> <li><code>422</code> - Validation Error</li> <li><code>500</code> - Internal Server Error</li> </ul>"},{"location":"services/api-service/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request parameters\",\n    \"details\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Invalid email format\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"services/api-service/#security","title":"Security","text":""},{"location":"services/api-service/#cors-configuration","title":"CORS Configuration","text":"<p>CORS is configured to allow specific origins:</p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.cors_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n</code></pre>"},{"location":"services/api-service/#rate-limiting","title":"Rate Limiting","text":"<p>Rate limiting is implemented per API key:</p> <ul> <li>1000 requests per hour for authenticated users</li> <li>100 requests per hour for unauthenticated users</li> </ul>"},{"location":"services/api-service/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<ul> <li>SQLAlchemy ORM with parameterized queries</li> <li>Input validation using Pydantic models</li> <li>Query sanitization</li> </ul>"},{"location":"services/api-service/#data-privacy","title":"Data Privacy","text":"<ul> <li>Sensitive data filtering</li> <li>PII handling compliance</li> <li>Audit logging</li> <li>Data encryption at rest</li> </ul>"},{"location":"services/api-service/#performance","title":"Performance","text":""},{"location":"services/api-service/#query-optimization","title":"Query Optimization","text":"<ul> <li>Database connection pooling</li> <li>Query result caching</li> <li>Lazy loading of relationships</li> <li>Pagination for large datasets</li> </ul>"},{"location":"services/api-service/#resource-requirements","title":"Resource Requirements","text":"<p>Development</p> <ul> <li>CPU: 1 core</li> <li>Memory: 1 GB</li> <li>Storage: Minimal</li> </ul> <p>Production</p> <ul> <li>CPU: 4-8 cores</li> <li>Memory: 4-8 GB</li> <li>Storage: 10 GB</li> </ul>"},{"location":"services/api-service/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/api-service/#common-issues","title":"Common Issues","text":"<p>Database Connection Errors</p> <ul> <li>Verify database URLs in environment variables</li> <li>Check database service status</li> <li>Review connection pool settings</li> <li>Monitor active connections</li> </ul> <p>Slow API Responses</p> <ul> <li>Enable query logging</li> <li>Check database indexes</li> <li>Review cache hit rates</li> <li>Monitor resource usage</li> </ul> <p>Authentication Failures</p> <ul> <li>Verify JWT secret key</li> <li>Check token expiration</li> <li>Review CORS settings</li> <li>Validate credentials</li> </ul>"},{"location":"services/api-service/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code>DEBUG=true LOG_LEVEL=DEBUG docker-compose up api-service\n</code></pre>"},{"location":"services/api-service/#query-profiling","title":"Query Profiling","text":"<p>Enable SQL query logging:</p> <pre><code>SQLALCHEMY_ECHO=true python main.py\n</code></pre>"},{"location":"services/api-service/#api-versioning","title":"API Versioning","text":"<p>The API uses URL-based versioning:</p> <ul> <li>Current version: <code>/api/v1/*</code></li> <li>Future versions: <code>/api/v2/*</code></li> </ul> <p>Deprecated endpoints will be maintained for 6 months with deprecation warnings.</p>"},{"location":"services/api-service/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>GraphQL API support</li> <li>WebSocket subscriptions for real-time updates</li> <li>Advanced filtering and search capabilities</li> <li>Bulk operation endpoints</li> <li>Data export functionality</li> <li>Custom report generation</li> <li>API analytics dashboard</li> <li>Enhanced caching strategies</li> </ul>"},{"location":"services/data-processor/","title":"Data Processor Service","text":"<p>The Data Processor Service is responsible for consuming data from Kafka topics, transforming and enriching it, and storing it in TimescaleDB for analytics and reporting. It acts as the central data processing engine in the SEI platform.</p>"},{"location":"services/data-processor/#overview","title":"Overview","text":"<p>The service is built using FastAPI and runs as a microservice in the SEI platform architecture. It processes streaming data from collector services and prepares it for analysis.</p>"},{"location":"services/data-processor/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Consume messages from Kafka topics</li> <li>Transform and normalize data</li> <li>Enrich data with additional context</li> <li>Calculate derived metrics and aggregations</li> <li>Store processed data in TimescaleDB</li> <li>Maintain data quality and consistency</li> </ul>"},{"location":"services/data-processor/#architecture","title":"Architecture","text":""},{"location":"services/data-processor/#service-components","title":"Service Components","text":"<p>Main Application (<code>main.py</code>)</p> <ul> <li>FastAPI application with CORS middleware</li> <li>Structured logging using structlog</li> <li>Health check endpoints</li> <li>Kafka consumer initialization</li> </ul> <p>Routes</p> <ul> <li><code>/health</code> - Service health check</li> </ul> <p>Configuration (<code>config.py</code>)</p> <ul> <li>Environment-based configuration</li> <li>Kafka consumer settings</li> <li>TimescaleDB connection settings</li> <li>Redis cache configuration</li> </ul>"},{"location":"services/data-processor/#data-flow","title":"Data Flow","text":"<pre><code>Kafka Topics \u2192 Data Processor \u2192 TimescaleDB\n                    \u2193              \u2193\n                Redis Cache    PostgreSQL\n</code></pre>"},{"location":"services/data-processor/#configuration","title":"Configuration","text":""},{"location":"services/data-processor/#environment-variables","title":"Environment Variables","text":"Variable Description Required Default <code>KAFKA_BROKERS</code> Kafka broker endpoints Yes <code>kafka:9092</code> <code>TIMESCALE_URL</code> TimescaleDB connection URL Yes - <code>REDIS_URL</code> Redis connection URL Yes <code>redis://redis:6379</code> <code>LOG_LEVEL</code> Logging level No <code>INFO</code> <code>CONSUMER_GROUP_ID</code> Kafka consumer group ID No <code>data-processor-group</code> <code>BATCH_SIZE</code> Processing batch size No <code>100</code> <code>BATCH_TIMEOUT_MS</code> Batch timeout in milliseconds No <code>5000</code>"},{"location":"services/data-processor/#docker-configuration","title":"Docker Configuration","text":"<p>The service is configured in <code>docker-compose.yml</code>:</p> <pre><code>data-processor:\n  build:\n    context: ./src/processors\n    dockerfile: Dockerfile\n  container_name: sei-data-processor\n  depends_on:\n    - kafka\n    - timescaledb\n    - redis\n  environment:\n    KAFKA_BROKERS: kafka:9092\n    TIMESCALE_URL: postgresql://sei_user:sei_password@timescaledb:5432/sei_platform\n    REDIS_URL: redis://redis:6379\n    LOG_LEVEL: INFO\n</code></pre>"},{"location":"services/data-processor/#development","title":"Development","text":""},{"location":"services/data-processor/#local-setup","title":"Local Setup","text":"<ol> <li> <p>Navigate to the service directory:</p> <pre><code>cd src/processors\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the service:</p> <pre><code>python main.py\n</code></pre> </li> </ol> <p>The service will start on <code>http://localhost:8002</code>.</p>"},{"location":"services/data-processor/#running-with-docker","title":"Running with Docker","text":"<pre><code>docker-compose up data-processor\n</code></pre>"},{"location":"services/data-processor/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/processors/\n</code></pre>"},{"location":"services/data-processor/#data-processing","title":"Data Processing","text":""},{"location":"services/data-processor/#kafka-topics-consumed","title":"Kafka Topics Consumed","text":"<p><code>git.commits</code></p> <ul> <li>Processes commit data from Git repositories</li> <li>Extracts author information and file changes</li> <li>Calculates code metrics (lines added/deleted)</li> <li>Links commits to pull requests</li> </ul> <p><code>git.pull_requests</code></p> <ul> <li>Processes pull request data</li> <li>Calculates review time and cycle time</li> <li>Tracks approval workflows</li> <li>Identifies merge conflicts</li> </ul> <p><code>git.repositories</code></p> <ul> <li>Updates repository metadata</li> <li>Tracks repository health metrics</li> <li>Monitors activity trends</li> </ul> <p><code>jira.issues</code></p> <ul> <li>Processes issue data from Jira</li> <li>Calculates issue lifecycle metrics</li> <li>Tracks workflow transitions</li> <li>Links issues to commits</li> </ul> <p><code>jira.sprints</code></p> <ul> <li>Processes sprint data</li> <li>Calculates sprint velocity</li> <li>Tracks completion rates</li> <li>Analyzes sprint patterns</li> </ul>"},{"location":"services/data-processor/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li> <p>Message Consumption</p> <ul> <li>Read messages from Kafka topics</li> <li>Deserialize JSON payloads</li> <li>Validate message schemas</li> </ul> </li> <li> <p>Data Transformation</p> <ul> <li>Normalize data formats</li> <li>Convert timestamps to UTC</li> <li>Extract relevant fields</li> <li>Handle missing values</li> </ul> </li> <li> <p>Data Enrichment</p> <ul> <li>Add contextual information</li> <li>Link related entities</li> <li>Calculate derived fields</li> <li>Apply business rules</li> </ul> </li> <li> <p>Metric Calculation</p> <ul> <li>Compute DORA metrics</li> <li>Calculate cycle times</li> <li>Aggregate team metrics</li> <li>Generate time-series data</li> </ul> </li> <li> <p>Data Storage</p> <ul> <li>Write to TimescaleDB hypertables</li> <li>Update materialized views</li> <li>Cache frequently accessed data</li> <li>Maintain data consistency</li> </ul> </li> </ol>"},{"location":"services/data-processor/#data-transformation","title":"Data Transformation","text":""},{"location":"services/data-processor/#git-commit-processing","title":"Git Commit Processing","text":"<p>Input from Kafka:</p> <pre><code>{\n  \"event_type\": \"commit_created\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"source\": \"github\",\n  \"repository_id\": \"repo-123\",\n  \"data\": {\n    \"sha\": \"abc123\",\n    \"author\": \"user@example.com\",\n    \"message\": \"Fix bug in authentication\",\n    \"files_changed\": 3,\n    \"additions\": 45,\n    \"deletions\": 12\n  }\n}\n</code></pre> <p>Transformed and stored:</p> <pre><code>INSERT INTO commits (\n  sha, repository_id, author_email, message,\n  files_changed, additions, deletions, committed_at\n) VALUES (\n  'abc123', 'repo-123', 'user@example.com',\n  'Fix bug in authentication', 3, 45, 12,\n  '2025-10-01T12:00:00Z'\n);\n</code></pre>"},{"location":"services/data-processor/#jira-issue-processing","title":"Jira Issue Processing","text":"<p>Input from Kafka:</p> <pre><code>{\n  \"event_type\": \"issue_updated\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"source\": \"jira\",\n  \"project_key\": \"PROJ\",\n  \"data\": {\n    \"key\": \"PROJ-123\",\n    \"status\": \"Done\",\n    \"assignee\": \"john@example.com\",\n    \"story_points\": 5,\n    \"created\": \"2025-09-25T10:00:00Z\",\n    \"resolved\": \"2025-10-01T12:00:00Z\"\n  }\n}\n</code></pre> <p>Transformed and stored with calculated metrics:</p> <pre><code>INSERT INTO issues (\n  issue_key, project_key, status, assignee,\n  story_points, created_at, resolved_at, cycle_time_days\n) VALUES (\n  'PROJ-123', 'PROJ', 'Done', 'john@example.com',\n  5, '2025-09-25T10:00:00Z', '2025-10-01T12:00:00Z', 6.08\n);\n</code></pre>"},{"location":"services/data-processor/#metric-calculations","title":"Metric Calculations","text":""},{"location":"services/data-processor/#dora-metrics","title":"DORA Metrics","text":"<p>Deployment Frequency</p> <ul> <li>Count of deployments per time period</li> <li>Aggregated by repository and team</li> <li>Calculated daily, weekly, monthly</li> </ul> <p>Lead Time for Changes</p> <ul> <li>Time from commit to production deployment</li> <li>Tracked per commit and aggregated</li> <li>Percentile calculations (p50, p90, p95)</li> </ul> <p>Change Failure Rate</p> <ul> <li>Percentage of deployments causing failures</li> <li>Tracked per repository</li> <li>Rolling window calculations</li> </ul> <p>Time to Restore Service</p> <ul> <li>Time from incident detection to resolution</li> <li>Linked to issue tracking systems</li> <li>Mean and median calculations</li> </ul>"},{"location":"services/data-processor/#cycle-time-metrics","title":"Cycle Time Metrics","text":"<p>Code Review Time</p> <ul> <li>Time from PR creation to approval</li> <li>Excludes author time</li> <li>Tracked by team and repository</li> </ul> <p>Issue Cycle Time</p> <ul> <li>Time from issue creation to resolution</li> <li>Broken down by workflow stages</li> <li>Analyzed by issue type</li> </ul> <p>Sprint Velocity</p> <ul> <li>Story points completed per sprint</li> <li>Trend analysis over time</li> <li>Team capacity planning</li> </ul>"},{"location":"services/data-processor/#timescaledb-integration","title":"TimescaleDB Integration","text":""},{"location":"services/data-processor/#hypertables","title":"Hypertables","text":"<p><code>commits</code></p> <ul> <li>Partitioned by <code>committed_at</code></li> <li>Retention: 2 years</li> <li>Compression after 90 days</li> </ul> <p><code>pull_requests</code></p> <ul> <li>Partitioned by <code>created_at</code></li> <li>Retention: 2 years</li> <li>Compression after 90 days</li> </ul> <p><code>issues</code></p> <ul> <li>Partitioned by <code>created_at</code></li> <li>Retention: 5 years</li> <li>Compression after 180 days</li> </ul> <p><code>metrics_daily</code></p> <ul> <li>Partitioned by <code>metric_date</code></li> <li>Pre-aggregated daily metrics</li> <li>Continuous aggregates</li> </ul>"},{"location":"services/data-processor/#continuous-aggregates","title":"Continuous Aggregates","text":"<p><code>commits_daily_stats</code></p> <pre><code>CREATE MATERIALIZED VIEW commits_daily_stats\nWITH (timescaledb.continuous) AS\nSELECT\n  time_bucket('1 day', committed_at) AS day,\n  repository_id,\n  COUNT(*) AS commit_count,\n  SUM(additions) AS total_additions,\n  SUM(deletions) AS total_deletions\nFROM commits\nGROUP BY day, repository_id;\n</code></pre> <p><code>pull_requests_weekly_metrics</code></p> <pre><code>CREATE MATERIALIZED VIEW pull_requests_weekly_metrics\nWITH (timescaledb.continuous) AS\nSELECT\n  time_bucket('1 week', created_at) AS week,\n  repository_id,\n  COUNT(*) AS pr_count,\n  AVG(review_time_hours) AS avg_review_time,\n  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY review_time_hours) AS median_review_time\nFROM pull_requests\nGROUP BY week, repository_id;\n</code></pre>"},{"location":"services/data-processor/#redis-caching","title":"Redis Caching","text":"<p>The service uses Redis for:</p> <ul> <li>Deduplication: Track processed message IDs</li> <li>State Management: Store processing checkpoints</li> <li>Lookup Cache: Cache frequently accessed reference data</li> <li>Rate Limiting: Control processing rates</li> </ul>"},{"location":"services/data-processor/#cache-keys","title":"Cache Keys","text":"<ul> <li><code>processor:dedupe:{message_id}</code> - Deduplication tracking</li> <li><code>processor:checkpoint:{topic}:{partition}</code> - Kafka offset checkpoints</li> <li><code>processor:cache:repo:{repository_id}</code> - Repository metadata</li> <li><code>processor:cache:user:{user_id}</code> - User information</li> </ul>"},{"location":"services/data-processor/#monitoring","title":"Monitoring","text":""},{"location":"services/data-processor/#health-checks","title":"Health Checks","text":"<p>The service exposes a <code>/health</code> endpoint that returns:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"kafka_connected\": true,\n  \"timescale_connected\": true,\n  \"redis_connected\": true\n}\n</code></pre>"},{"location":"services/data-processor/#metrics","title":"Metrics","text":"<p>Metrics are exposed for Prometheus scraping at <code>/metrics</code> (when enabled):</p> <ul> <li><code>processor_messages_consumed_total</code> - Total messages consumed</li> <li><code>processor_messages_processed_total</code> - Successfully processed messages</li> <li><code>processor_messages_failed_total</code> - Failed message processing</li> <li><code>processor_processing_duration_seconds</code> - Message processing time</li> <li><code>processor_batch_size</code> - Current batch size</li> <li><code>processor_lag</code> - Consumer lag per topic</li> </ul>"},{"location":"services/data-processor/#logging","title":"Logging","text":"<p>Structured JSON logging is configured for:</p> <ul> <li>Message consumption events</li> <li>Processing pipeline stages</li> <li>Database operations</li> <li>Error conditions</li> <li>Performance metrics</li> </ul>"},{"location":"services/data-processor/#error-handling","title":"Error Handling","text":""},{"location":"services/data-processor/#processing-errors","title":"Processing Errors","text":"<p>Schema Validation Failures</p> <ul> <li>Log validation errors</li> <li>Send to dead letter queue</li> <li>Alert on high failure rates</li> </ul> <p>Database Errors</p> <ul> <li>Retry with exponential backoff</li> <li>Use transaction rollback</li> <li>Maintain data consistency</li> </ul> <p>Network Errors</p> <ul> <li>Automatic reconnection</li> <li>Circuit breaker pattern</li> <li>Graceful degradation</li> </ul>"},{"location":"services/data-processor/#recovery-mechanisms","title":"Recovery Mechanisms","text":"<ul> <li>Kafka offset management for replay</li> <li>Dead letter queue for failed messages</li> <li>Checkpoint mechanism for state recovery</li> <li>Transaction-based processing</li> </ul>"},{"location":"services/data-processor/#performance","title":"Performance","text":""},{"location":"services/data-processor/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Batch processing for efficiency</li> <li>Connection pooling for databases</li> <li>Parallel processing of independent messages</li> <li>Async I/O for network operations</li> <li>Pre-compiled SQL statements</li> <li>Bulk insert operations</li> </ul>"},{"location":"services/data-processor/#batch-processing","title":"Batch Processing","text":"<p>Messages are processed in batches for efficiency:</p> <pre><code>batch = []\nfor message in consumer:\n    batch.append(message)\n    if len(batch) &gt;= BATCH_SIZE or timeout_reached():\n        process_batch(batch)\n        batch = []\n</code></pre>"},{"location":"services/data-processor/#resource-requirements","title":"Resource Requirements","text":"<p>Development</p> <ul> <li>CPU: 1 core</li> <li>Memory: 1 GB</li> <li>Storage: Minimal (logs only)</li> </ul> <p>Production</p> <ul> <li>CPU: 4-8 cores</li> <li>Memory: 8-16 GB</li> <li>Storage: 20 GB (logs and local cache)</li> </ul>"},{"location":"services/data-processor/#kafka-consumer-configuration","title":"Kafka Consumer Configuration","text":""},{"location":"services/data-processor/#consumer-settings","title":"Consumer Settings","text":"<pre><code>consumer_config = {\n    'bootstrap.servers': 'kafka:9092',\n    'group.id': 'data-processor-group',\n    'auto.offset.reset': 'earliest',\n    'enable.auto.commit': False,\n    'max.poll.records': 100,\n    'session.timeout.ms': 30000,\n    'heartbeat.interval.ms': 10000\n}\n</code></pre>"},{"location":"services/data-processor/#topic-subscription","title":"Topic Subscription","text":"<pre><code>topics = [\n    'git.commits',\n    'git.pull_requests',\n    'git.repositories',\n    'jira.issues',\n    'jira.sprints'\n]\nconsumer.subscribe(topics)\n</code></pre>"},{"location":"services/data-processor/#data-quality","title":"Data Quality","text":""},{"location":"services/data-processor/#validation-rules","title":"Validation Rules","text":"<ul> <li>Required fields presence check</li> <li>Data type validation</li> <li>Range and format validation</li> <li>Referential integrity checks</li> <li>Duplicate detection</li> </ul>"},{"location":"services/data-processor/#data-cleansing","title":"Data Cleansing","text":"<ul> <li>Timestamp normalization</li> <li>Email address standardization</li> <li>Text encoding fixes</li> <li>Null value handling</li> <li>Outlier detection and handling</li> </ul>"},{"location":"services/data-processor/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/data-processor/#common-issues","title":"Common Issues","text":"<p>High Consumer Lag</p> <ul> <li>Increase batch size</li> <li>Add more processor instances</li> <li>Optimize database operations</li> <li>Review processing logic</li> </ul> <p>Database Connection Errors</p> <ul> <li>Check TimescaleDB connectivity</li> <li>Verify connection pool settings</li> <li>Review database logs</li> <li>Monitor connection count</li> </ul> <p>Memory Issues</p> <ul> <li>Reduce batch size</li> <li>Optimize data structures</li> <li>Enable compression</li> <li>Monitor memory usage</li> </ul> <p>Slow Processing</p> <ul> <li>Profile processing pipeline</li> <li>Optimize SQL queries</li> <li>Review network latency</li> <li>Check resource constraints</li> </ul>"},{"location":"services/data-processor/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code>LOG_LEVEL=DEBUG docker-compose up data-processor\n</code></pre>"},{"location":"services/data-processor/#monitor-consumer-lag","title":"Monitor Consumer Lag","text":"<p>Check Kafka consumer lag:</p> <pre><code>docker exec sei-kafka kafka-consumer-groups --bootstrap-server localhost:9092 --group data-processor-group --describe\n</code></pre>"},{"location":"services/data-processor/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Real-time stream processing with Apache Flink</li> <li>Machine learning model integration</li> <li>Advanced data validation rules</li> <li>Multi-region data replication</li> <li>Enhanced error recovery mechanisms</li> <li>GraphQL subscriptions for real-time updates</li> <li>Time-series forecasting</li> <li>Anomaly detection algorithms</li> </ul>"},{"location":"services/git-collector/","title":"Git Collector Service","text":"<p>The Git Collector Service is responsible for collecting data from Git-based version control systems including GitHub, GitLab, and Bitbucket. It retrieves repository metadata, commit history, pull requests, code reviews, and contributor information.</p>"},{"location":"services/git-collector/#overview","title":"Overview","text":"<p>The service is built using FastAPI and runs as a microservice in the SEI platform architecture. It collects data from Git repositories and publishes it to Apache Kafka for downstream processing.</p>"},{"location":"services/git-collector/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Collect repository metadata and configuration</li> <li>Retrieve commit history and statistics</li> <li>Fetch pull request and merge request data</li> <li>Gather code review information</li> <li>Track contributor activity and metrics</li> <li>Monitor repository health and activity</li> </ul>"},{"location":"services/git-collector/#architecture","title":"Architecture","text":""},{"location":"services/git-collector/#service-components","title":"Service Components","text":"<p>Main Application (<code>main.py</code>)</p> <ul> <li>FastAPI application with CORS middleware</li> <li>Structured logging using structlog</li> <li>Health check endpoints</li> <li>Collection trigger endpoints</li> </ul> <p>Routes</p> <ul> <li><code>/health</code> - Service health check</li> <li><code>/api/v1/collect/trigger</code> - Trigger manual collection</li> <li><code>/api/v1/collect/status/{repository_id}</code> - Get collection status</li> </ul> <p>Configuration (<code>config.py</code>)</p> <ul> <li>Environment-based configuration</li> <li>Kafka broker settings</li> <li>Redis connection settings</li> <li>API credentials management</li> </ul>"},{"location":"services/git-collector/#data-flow","title":"Data Flow","text":"<pre><code>Git APIs \u2192 Git Collector \u2192 Kafka Topics \u2192 Data Processor \u2192 TimescaleDB\n                \u2193\n             Redis Cache\n</code></pre>"},{"location":"services/git-collector/#configuration","title":"Configuration","text":""},{"location":"services/git-collector/#environment-variables","title":"Environment Variables","text":"Variable Description Required Default <code>KAFKA_BROKERS</code> Kafka broker endpoints Yes <code>kafka:9092</code> <code>REDIS_URL</code> Redis connection URL Yes <code>redis://redis:6379</code> <code>LOG_LEVEL</code> Logging level No <code>INFO</code> <code>GITHUB_TOKEN</code> GitHub API token Conditional - <code>GITLAB_TOKEN</code> GitLab API token Conditional - <code>BITBUCKET_TOKEN</code> Bitbucket API token Conditional -"},{"location":"services/git-collector/#docker-configuration","title":"Docker Configuration","text":"<p>The service is configured in <code>docker-compose.yml</code>:</p> <pre><code>git-collector:\n  build:\n    context: ./src/collectors/git\n    dockerfile: Dockerfile\n  container_name: sei-git-collector\n  depends_on:\n    - kafka\n    - redis\n  environment:\n    KAFKA_BROKERS: kafka:9092\n    REDIS_URL: redis://redis:6379\n    LOG_LEVEL: INFO\n  env_file:\n    - .env\n</code></pre>"},{"location":"services/git-collector/#api-reference","title":"API Reference","text":""},{"location":"services/git-collector/#post-apiv1collecttrigger","title":"POST /api/v1/collect/trigger","text":"<p>Manually trigger data collection for a Git repository.</p> <p>Request Body <pre><code>{\n  \"repository_url\": \"https://github.com/owner/repo\",\n  \"full_sync\": false\n}\n</code></pre></p> <p>Response <pre><code>{\n  \"status\": \"queued\",\n  \"message\": \"Collection job has been queued for processing\",\n  \"repository_url\": \"https://github.com/owner/repo\"\n}\n</code></pre></p> <p>Parameters</p> <ul> <li><code>repository_url</code> (string, required): Full URL of the Git repository</li> <li><code>full_sync</code> (boolean, optional): Whether to perform full sync or incremental. Default: <code>false</code></li> </ul>"},{"location":"services/git-collector/#get-apiv1collectstatusrepository_id","title":"GET /api/v1/collect/status/{repository_id}","text":"<p>Get the current collection status for a repository.</p> <p>Path Parameters</p> <ul> <li><code>repository_id</code> (string, required): Unique repository identifier</li> </ul> <p>Response <pre><code>{\n  \"repository_id\": \"repo-123\",\n  \"status\": \"idle\",\n  \"last_sync\": \"2025-10-01T12:00:00Z\",\n  \"next_sync\": \"2025-10-01T13:00:00Z\"\n}\n</code></pre></p> <p>Status Values</p> <ul> <li><code>idle</code> - No collection in progress</li> <li><code>queued</code> - Collection job queued</li> <li><code>running</code> - Collection in progress</li> <li><code>completed</code> - Collection completed successfully</li> <li><code>failed</code> - Collection failed</li> </ul>"},{"location":"services/git-collector/#development","title":"Development","text":""},{"location":"services/git-collector/#local-setup","title":"Local Setup","text":"<ol> <li> <p>Navigate to the service directory: <pre><code>cd src/collectors/git\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Run the service: <pre><code>python main.py\n</code></pre></p> </li> </ol> <p>The service will start on <code>http://localhost:8000</code>.</p>"},{"location":"services/git-collector/#running-with-docker","title":"Running with Docker","text":"<pre><code>docker-compose up git-collector\n</code></pre>"},{"location":"services/git-collector/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/collectors/git/\n</code></pre>"},{"location":"services/git-collector/#data-collection","title":"Data Collection","text":""},{"location":"services/git-collector/#supported-platforms","title":"Supported Platforms","text":"<p>GitHub</p> <ul> <li>Repository metadata</li> <li>Commit history</li> <li>Pull requests and reviews</li> <li>Issues and comments</li> <li>Contributors and teams</li> <li>Branch protection rules</li> <li>Workflow runs (GitHub Actions)</li> </ul> <p>GitLab</p> <ul> <li>Project information</li> <li>Commit history</li> <li>Merge requests and approvals</li> <li>Issues and notes</li> <li>Members and groups</li> <li>Protected branches</li> <li>Pipeline runs</li> </ul> <p>Bitbucket</p> <ul> <li>Repository details</li> <li>Commit history</li> <li>Pull requests and comments</li> <li>Issues and discussions</li> <li>Users and teams</li> <li>Branch restrictions</li> <li>Pipeline executions</li> </ul>"},{"location":"services/git-collector/#collection-strategies","title":"Collection Strategies","text":"<p>Full Sync</p> <ul> <li>Collects all historical data from the repository</li> <li>Used for initial setup or data refresh</li> <li>Resource intensive, runs during off-peak hours</li> </ul> <p>Incremental Sync</p> <ul> <li>Collects only new data since last sync</li> <li>Default collection mode</li> <li>Efficient and quick</li> <li>Runs on a scheduled basis</li> </ul> <p>Webhook-Triggered</p> <ul> <li>Real-time updates from Git platforms</li> <li>Triggered by repository events</li> <li>Low latency, immediate processing</li> </ul>"},{"location":"services/git-collector/#kafka-integration","title":"Kafka Integration","text":""},{"location":"services/git-collector/#published-topics","title":"Published Topics","text":"<p><code>git.commits</code></p> <ul> <li>Individual commit data</li> <li>Author information</li> <li>File changes and statistics</li> </ul> <p><code>git.pull_requests</code></p> <ul> <li>Pull request metadata</li> <li>Review information</li> <li>Merge status and timelines</li> </ul> <p><code>git.repositories</code></p> <ul> <li>Repository metadata</li> <li>Configuration updates</li> <li>Health metrics</li> </ul>"},{"location":"services/git-collector/#message-format","title":"Message Format","text":"<p>All messages published to Kafka follow this structure:</p> <pre><code>{\n  \"event_type\": \"commit_created\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"source\": \"github\",\n  \"repository_id\": \"repo-123\",\n  \"data\": {\n    // Event-specific data\n  }\n}\n</code></pre>"},{"location":"services/git-collector/#redis-caching","title":"Redis Caching","text":"<p>The service uses Redis for:</p> <ul> <li>Rate Limiting: Track API call quotas</li> <li>Deduplication: Prevent duplicate data collection</li> <li>Status Tracking: Store collection job status</li> <li>Token Management: Cache API tokens</li> </ul>"},{"location":"services/git-collector/#cache-keys","title":"Cache Keys","text":"<ul> <li><code>git:ratelimit:{platform}:{repository_id}</code> - Rate limiting counters</li> <li><code>git:status:{repository_id}</code> - Collection status</li> <li><code>git:last_sync:{repository_id}</code> - Last sync timestamp</li> </ul>"},{"location":"services/git-collector/#monitoring","title":"Monitoring","text":""},{"location":"services/git-collector/#health-checks","title":"Health Checks","text":"<p>The service exposes a <code>/health</code> endpoint that returns:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\"\n}\n</code></pre>"},{"location":"services/git-collector/#metrics","title":"Metrics","text":"<p>Metrics are exposed for Prometheus scraping at <code>/metrics</code> (when enabled):</p> <ul> <li><code>git_collector_requests_total</code> - Total API requests made</li> <li><code>git_collector_requests_failed</code> - Failed API requests</li> <li><code>git_collector_collections_total</code> - Total collection jobs</li> <li><code>git_collector_processing_duration_seconds</code> - Processing time</li> </ul>"},{"location":"services/git-collector/#logging","title":"Logging","text":"<p>Structured JSON logging is configured for:</p> <ul> <li>Collection job lifecycle</li> <li>API request/response</li> <li>Error conditions</li> <li>Rate limiting events</li> </ul>"},{"location":"services/git-collector/#error-handling","title":"Error Handling","text":""},{"location":"services/git-collector/#api-errors","title":"API Errors","text":"<ul> <li>Rate Limiting: Automatic backoff and retry</li> <li>Authentication: Token refresh and rotation</li> <li>Network Errors: Exponential retry with jitter</li> <li>Validation Errors: Logged and reported</li> </ul>"},{"location":"services/git-collector/#recovery-mechanisms","title":"Recovery Mechanisms","text":"<ul> <li>Automatic retry for transient failures</li> <li>Dead letter queue for permanent failures</li> <li>Circuit breaker for failing endpoints</li> <li>Graceful degradation on partial failures</li> </ul>"},{"location":"services/git-collector/#security","title":"Security","text":""},{"location":"services/git-collector/#authentication","title":"Authentication","text":"<ul> <li>API tokens stored in environment variables</li> <li>Secrets managed via Docker secrets or Kubernetes secrets</li> <li>Token rotation supported</li> </ul>"},{"location":"services/git-collector/#authorization","title":"Authorization","text":"<ul> <li>Service-to-service authentication</li> <li>Role-based access for manual triggers</li> <li>Audit logging for all operations</li> </ul>"},{"location":"services/git-collector/#data-privacy","title":"Data Privacy","text":"<ul> <li>Sensitive data filtered before storage</li> <li>PII handling compliance</li> <li>Configurable data retention policies</li> </ul>"},{"location":"services/git-collector/#performance","title":"Performance","text":""},{"location":"services/git-collector/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Parallel collection for multiple repositories</li> <li>Batch API requests where supported</li> <li>Connection pooling for HTTP clients</li> <li>Efficient pagination handling</li> </ul>"},{"location":"services/git-collector/#resource-requirements","title":"Resource Requirements","text":"<p>Development</p> <ul> <li>CPU: 0.5 cores</li> <li>Memory: 512 MB</li> <li>Storage: Minimal (logs only)</li> </ul> <p>Production</p> <ul> <li>CPU: 2-4 cores</li> <li>Memory: 2-4 GB</li> <li>Storage: 10 GB (logs and cache)</li> </ul>"},{"location":"services/git-collector/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/git-collector/#common-issues","title":"Common Issues","text":"<p>Collection Not Starting</p> <ul> <li>Check Kafka connectivity</li> <li>Verify Redis connection</li> <li>Validate API tokens</li> <li>Review service logs</li> </ul> <p>Rate Limit Exceeded</p> <ul> <li>Increase rate limit thresholds</li> <li>Reduce collection frequency</li> <li>Add additional API tokens</li> <li>Enable request throttling</li> </ul> <p>Missing Data</p> <ul> <li>Verify repository permissions</li> <li>Check collection status</li> <li>Review Kafka messages</li> <li>Validate data filters</li> </ul>"},{"location":"services/git-collector/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging: <pre><code>LOG_LEVEL=DEBUG docker-compose up git-collector\n</code></pre></p>"},{"location":"services/git-collector/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Support for additional Git platforms (Gitea, Gerrit)</li> <li>Webhooks for real-time collection</li> <li>Advanced filtering and sampling</li> <li>Multi-region deployment support</li> <li>Enhanced caching strategies</li> <li>GraphQL API support</li> </ul>"},{"location":"services/jira-collector/","title":"Jira Collector Service","text":"<p>The Jira Collector Service is responsible for collecting data from Jira and other project management platforms. It retrieves issue data, sprint information, workflow states, and team metrics.</p>"},{"location":"services/jira-collector/#overview","title":"Overview","text":"<p>The service is built using FastAPI and runs as a microservice in the SEI platform architecture. It collects data from Jira projects and publishes it to Apache Kafka for downstream processing.</p>"},{"location":"services/jira-collector/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Collect issue and ticket data</li> <li>Retrieve sprint and board information</li> <li>Track workflow states and transitions</li> <li>Gather team and project metrics</li> <li>Monitor project health and velocity</li> <li>Extract custom field data</li> </ul>"},{"location":"services/jira-collector/#architecture","title":"Architecture","text":""},{"location":"services/jira-collector/#service-components","title":"Service Components","text":"<p>Main Application (<code>main.py</code>)</p> <ul> <li>FastAPI application with CORS middleware</li> <li>Structured logging using structlog</li> <li>Health check endpoints</li> <li>Collection trigger endpoints</li> </ul> <p>Routes</p> <ul> <li><code>/health</code> - Service health check</li> <li><code>/api/v1/collect/trigger</code> - Trigger manual collection</li> <li><code>/api/v1/collect/status/{project_key}</code> - Get collection status</li> </ul> <p>Configuration (<code>config.py</code>)</p> <ul> <li>Environment-based configuration</li> <li>Kafka broker settings</li> <li>Redis connection settings</li> <li>Jira API credentials management</li> </ul>"},{"location":"services/jira-collector/#data-flow","title":"Data Flow","text":"<pre><code>Jira APIs \u2192 Jira Collector \u2192 Kafka Topics \u2192 Data Processor \u2192 TimescaleDB\n                \u2193\n             Redis Cache\n</code></pre>"},{"location":"services/jira-collector/#configuration","title":"Configuration","text":""},{"location":"services/jira-collector/#environment-variables","title":"Environment Variables","text":"Variable Description Required Default <code>KAFKA_BROKERS</code> Kafka broker endpoints Yes <code>kafka:9092</code> <code>REDIS_URL</code> Redis connection URL Yes <code>redis://redis:6379</code> <code>LOG_LEVEL</code> Logging level No <code>INFO</code> <code>JIRA_URL</code> Jira instance URL Yes - <code>JIRA_USERNAME</code> Jira username or email Yes - <code>JIRA_API_TOKEN</code> Jira API token Yes - <code>JIRA_PROJECT_KEYS</code> Comma-separated project keys Yes -"},{"location":"services/jira-collector/#docker-configuration","title":"Docker Configuration","text":"<p>The service is configured in <code>docker-compose.yml</code>:</p> <pre><code>jira-collector:\n  build:\n    context: ./src/collectors/jira\n    dockerfile: Dockerfile\n  container_name: sei-jira-collector\n  depends_on:\n    - kafka\n    - redis\n  environment:\n    KAFKA_BROKERS: kafka:9092\n    REDIS_URL: redis://redis:6379\n    LOG_LEVEL: INFO\n  env_file:\n    - .env\n</code></pre>"},{"location":"services/jira-collector/#api-reference","title":"API Reference","text":""},{"location":"services/jira-collector/#post-apiv1collecttrigger","title":"POST /api/v1/collect/trigger","text":"<p>Manually trigger data collection for a Jira project.</p> <p>Request Body</p> <pre><code>{\n  \"project_key\": \"PROJ\",\n  \"full_sync\": false\n}\n</code></pre> <p>Response</p> <pre><code>{\n  \"status\": \"queued\",\n  \"message\": \"Collection job has been queued for processing\",\n  \"project_key\": \"PROJ\"\n}\n</code></pre> <p>Parameters</p> <ul> <li><code>project_key</code> (string, required): Jira project key</li> <li><code>full_sync</code> (boolean, optional): Whether to perform full sync or incremental. Default: <code>false</code></li> </ul>"},{"location":"services/jira-collector/#get-apiv1collectstatusproject_key","title":"GET /api/v1/collect/status/{project_key}","text":"<p>Get the current collection status for a Jira project.</p> <p>Path Parameters</p> <ul> <li><code>project_key</code> (string, required): Jira project key</li> </ul> <p>Response</p> <pre><code>{\n  \"project_key\": \"PROJ\",\n  \"status\": \"idle\",\n  \"last_sync\": \"2025-10-01T12:00:00Z\",\n  \"next_sync\": \"2025-10-01T13:00:00Z\"\n}\n</code></pre> <p>Status Values</p> <ul> <li><code>idle</code> - No collection in progress</li> <li><code>queued</code> - Collection job queued</li> <li><code>running</code> - Collection in progress</li> <li><code>completed</code> - Collection completed successfully</li> <li><code>failed</code> - Collection failed</li> </ul>"},{"location":"services/jira-collector/#development","title":"Development","text":""},{"location":"services/jira-collector/#local-setup","title":"Local Setup","text":"<ol> <li> <p>Navigate to the service directory:</p> <pre><code>cd src/collectors/jira\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the service:</p> <pre><code>python main.py\n</code></pre> </li> </ol> <p>The service will start on <code>http://localhost:8001</code>.</p>"},{"location":"services/jira-collector/#running-with-docker","title":"Running with Docker","text":"<pre><code>docker-compose up jira-collector\n</code></pre>"},{"location":"services/jira-collector/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/collectors/jira/\n</code></pre>"},{"location":"services/jira-collector/#data-collection","title":"Data Collection","text":""},{"location":"services/jira-collector/#collected-data-types","title":"Collected Data Types","text":"<p>Issues and Tickets</p> <ul> <li>Issue metadata (key, summary, description)</li> <li>Status and workflow information</li> <li>Priority and severity</li> <li>Assignee and reporter</li> <li>Created and updated timestamps</li> <li>Resolution and close dates</li> <li>Labels and components</li> </ul> <p>Sprints and Boards</p> <ul> <li>Sprint metadata and goals</li> <li>Sprint start and end dates</li> <li>Sprint velocity and capacity</li> <li>Board configuration</li> <li>Swimlanes and columns</li> </ul> <p>Workflows</p> <ul> <li>Workflow states and transitions</li> <li>State duration metrics</li> <li>Transition history</li> <li>Custom workflow rules</li> </ul> <p>Custom Fields</p> <ul> <li>Story points</li> <li>Epic links</li> <li>Custom date fields</li> <li>Custom text and number fields</li> </ul> <p>Comments and History</p> <ul> <li>Issue comments</li> <li>Change history</li> <li>Attachment metadata</li> <li>Work logs</li> </ul>"},{"location":"services/jira-collector/#collection-strategies","title":"Collection Strategies","text":"<p>Full Sync</p> <ul> <li>Collects all historical data from the project</li> <li>Used for initial setup or data refresh</li> <li>Includes all issues, sprints, and workflows</li> <li>Resource intensive, scheduled during off-peak hours</li> </ul> <p>Incremental Sync</p> <ul> <li>Collects only updated issues since last sync</li> <li>Default collection mode</li> <li>Uses JQL queries with updated date filters</li> <li>Efficient and quick</li> </ul> <p>Webhook-Triggered</p> <ul> <li>Real-time updates from Jira webhooks</li> <li>Triggered by issue events</li> <li>Low latency, immediate processing</li> <li>Requires webhook configuration in Jira</li> </ul>"},{"location":"services/jira-collector/#kafka-integration","title":"Kafka Integration","text":""},{"location":"services/jira-collector/#published-topics","title":"Published Topics","text":"<p><code>jira.issues</code></p> <ul> <li>Issue creation, updates, and deletions</li> <li>Status transitions</li> <li>Assignment changes</li> </ul> <p><code>jira.sprints</code></p> <ul> <li>Sprint creation and updates</li> <li>Sprint start and completion</li> <li>Velocity metrics</li> </ul> <p><code>jira.workflows</code></p> <ul> <li>Workflow state changes</li> <li>Transition events</li> <li>Cycle time data</li> </ul> <p><code>jira.comments</code></p> <ul> <li>Comment creation and updates</li> <li>Collaboration metrics</li> <li>Communication patterns</li> </ul>"},{"location":"services/jira-collector/#message-format","title":"Message Format","text":"<p>All messages published to Kafka follow this structure:</p> <pre><code>{\n  \"event_type\": \"issue_updated\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\",\n  \"source\": \"jira\",\n  \"project_key\": \"PROJ\",\n  \"data\": {\n    // Event-specific data\n  }\n}\n</code></pre>"},{"location":"services/jira-collector/#redis-caching","title":"Redis Caching","text":"<p>The service uses Redis for:</p> <ul> <li>Rate Limiting: Track API call quotas</li> <li>Deduplication: Prevent duplicate data collection</li> <li>Status Tracking: Store collection job status</li> <li>Field Mapping: Cache custom field configurations</li> </ul>"},{"location":"services/jira-collector/#cache-keys","title":"Cache Keys","text":"<ul> <li><code>jira:ratelimit:{project_key}</code> - Rate limiting counters</li> <li><code>jira:status:{project_key}</code> - Collection status</li> <li><code>jira:last_sync:{project_key}</code> - Last sync timestamp</li> <li><code>jira:fields:{project_key}</code> - Custom field mappings</li> </ul>"},{"location":"services/jira-collector/#monitoring","title":"Monitoring","text":""},{"location":"services/jira-collector/#health-checks","title":"Health Checks","text":"<p>The service exposes a <code>/health</code> endpoint that returns:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.0\",\n  \"timestamp\": \"2025-10-01T12:00:00Z\"\n}\n</code></pre>"},{"location":"services/jira-collector/#metrics","title":"Metrics","text":"<p>Metrics are exposed for Prometheus scraping at <code>/metrics</code> (when enabled):</p> <ul> <li><code>jira_collector_requests_total</code> - Total API requests made</li> <li><code>jira_collector_requests_failed</code> - Failed API requests</li> <li><code>jira_collector_collections_total</code> - Total collection jobs</li> <li><code>jira_collector_issues_collected</code> - Issues collected per job</li> <li><code>jira_collector_processing_duration_seconds</code> - Processing time</li> </ul>"},{"location":"services/jira-collector/#logging","title":"Logging","text":"<p>Structured JSON logging is configured for:</p> <ul> <li>Collection job lifecycle</li> <li>API request/response</li> <li>Error conditions</li> <li>Rate limiting events</li> <li>Data transformation operations</li> </ul>"},{"location":"services/jira-collector/#error-handling","title":"Error Handling","text":""},{"location":"services/jira-collector/#api-errors","title":"API Errors","text":"<ul> <li>Rate Limiting: Automatic backoff and retry with exponential delay</li> <li>Authentication: Token validation and error reporting</li> <li>Network Errors: Retry with exponential backoff</li> <li>Validation Errors: Detailed error logging</li> </ul>"},{"location":"services/jira-collector/#recovery-mechanisms","title":"Recovery Mechanisms","text":"<ul> <li>Automatic retry for transient failures</li> <li>Dead letter queue for permanent failures</li> <li>Checkpoint mechanism for partial collection</li> <li>Graceful degradation on API limitations</li> </ul>"},{"location":"services/jira-collector/#security","title":"Security","text":""},{"location":"services/jira-collector/#authentication","title":"Authentication","text":"<ul> <li>API tokens stored in environment variables</li> <li>Secrets managed via Docker secrets or Kubernetes secrets</li> <li>Support for OAuth 2.0 authentication</li> <li>Token rotation capabilities</li> </ul>"},{"location":"services/jira-collector/#authorization","title":"Authorization","text":"<ul> <li>Project-level access control</li> <li>Service account with minimal permissions</li> <li>Audit logging for all operations</li> <li>Encrypted communication with Jira</li> </ul>"},{"location":"services/jira-collector/#data-privacy","title":"Data Privacy","text":"<ul> <li>Sensitive data filtering</li> <li>PII handling compliance</li> <li>Configurable field exclusions</li> <li>Data retention policies</li> </ul>"},{"location":"services/jira-collector/#performance","title":"Performance","text":""},{"location":"services/jira-collector/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Parallel collection for multiple projects</li> <li>Batch API requests using bulk endpoints</li> <li>Connection pooling for HTTP clients</li> <li>Efficient JQL query construction</li> <li>Field filtering to reduce payload size</li> </ul>"},{"location":"services/jira-collector/#resource-requirements","title":"Resource Requirements","text":"<p>Development</p> <ul> <li>CPU: 0.5 cores</li> <li>Memory: 512 MB</li> <li>Storage: Minimal (logs only)</li> </ul> <p>Production</p> <ul> <li>CPU: 2-4 cores</li> <li>Memory: 2-4 GB</li> <li>Storage: 10 GB (logs and cache)</li> </ul>"},{"location":"services/jira-collector/#jql-query-examples","title":"JQL Query Examples","text":""},{"location":"services/jira-collector/#incremental-sync","title":"Incremental Sync","text":"<pre><code>updated &gt;= -1h ORDER BY updated ASC\n</code></pre>"},{"location":"services/jira-collector/#full-sync","title":"Full Sync","text":"<pre><code>project = PROJ ORDER BY created ASC\n</code></pre>"},{"location":"services/jira-collector/#sprint-issues","title":"Sprint Issues","text":"<pre><code>sprint = 123 AND project = PROJ\n</code></pre>"},{"location":"services/jira-collector/#recently-closed-issues","title":"Recently Closed Issues","text":"<pre><code>status = Done AND resolved &gt;= -7d\n</code></pre>"},{"location":"services/jira-collector/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/jira-collector/#common-issues","title":"Common Issues","text":"<p>Collection Not Starting</p> <ul> <li>Check Kafka connectivity</li> <li>Verify Redis connection</li> <li>Validate Jira credentials</li> <li>Review service logs</li> <li>Confirm project key exists</li> </ul> <p>Rate Limit Exceeded</p> <ul> <li>Increase rate limit thresholds in Jira</li> <li>Reduce collection frequency</li> <li>Implement request throttling</li> <li>Use multiple service accounts</li> </ul> <p>Missing Issues</p> <ul> <li>Verify project permissions</li> <li>Check JQL query syntax</li> <li>Review field mappings</li> <li>Validate custom fields configuration</li> </ul> <p>Authentication Failures</p> <ul> <li>Verify API token validity</li> <li>Check username/email format</li> <li>Confirm Jira instance URL</li> <li>Review security settings in Jira</li> </ul>"},{"location":"services/jira-collector/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code>LOG_LEVEL=DEBUG docker-compose up jira-collector\n</code></pre>"},{"location":"services/jira-collector/#verify-jira-connection","title":"Verify Jira Connection","text":"<p>Test Jira API connectivity:</p> <pre><code>curl -u username:token https://your-domain.atlassian.net/rest/api/3/myself\n</code></pre>"},{"location":"services/jira-collector/#jira-api-versions","title":"Jira API Versions","text":"<p>The service supports multiple Jira API versions:</p> <ul> <li>Jira Cloud REST API v3</li> <li>Jira Server/Data Center REST API v2</li> <li>Agile REST API (for sprints and boards)</li> </ul>"},{"location":"services/jira-collector/#custom-field-mapping","title":"Custom Field Mapping","text":"<p>Custom fields are mapped using field IDs:</p> <pre><code>{\n  \"customfield_10016\": \"story_points\",\n  \"customfield_10018\": \"epic_link\",\n  \"customfield_10019\": \"sprint\"\n}\n</code></pre> <p>Field mappings are cached in Redis and refreshed periodically.</p>"},{"location":"services/jira-collector/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Support for Jira Service Desk data</li> <li>Advanced analytics on issue patterns</li> <li>Predictive issue resolution time</li> <li>Integration with Confluence</li> <li>Support for Azure DevOps Boards</li> <li>Real-time webhook processing</li> <li>Enhanced custom field handling</li> <li>Multi-project bulk operations</li> </ul>"}]}